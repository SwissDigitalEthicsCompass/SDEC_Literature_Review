,Title,Authors,Publisher,DOI,URL,Abstract,Eligibility_Score
0,Synthesis of Digital Medical Student Characteristics,M. Srikong; P. Wannapiroon; P. Nilsook,ieee,10.1109/iSTEM-Ed52129.2021.9625123,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9625123,"The objective of this paper is to study, analyze and synthesize the characteristics of medical students together with digital competencies. It can be concluded that there are 4 characteristics of digital medical students: 1) Digital technology ethics 2) The use of digital technology 3) Creativity, innovation, and digital communication 4) Digital leadership. A compelling visual model is presented that defines the characteristics of medical students needed to become global citizens in the digital era.",0.21621621621621623
1,AI Ethics in Smart Healthcare,S. Pasricha,ieee,10.1109/MCE.2022.3220001,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9940606,"This article reviews the landscape of ethical challenges of integrating artificial intelligence (AI) into smart healthcare products, including medical electronic devices. Differences between traditional ethics in the medical domain and emerging ethical challenges with AI-driven healthcare are presented, particularly as they relate to transparency, bias, privacy, safety, responsibility, justice, and autonomy. Open challenges and recommendations are outlined to enable the integration of ethical principles into the design, validation, clinical trials, deployment, monitoring, repair, and retirement of AI-based smart healthcare products.",0.2
2,The Concept of Ethical Digital Identities,E. Cioroaica; B. Buhnova; F. Jacobi; D. Schneider,ieee,10.1145/3526073.3527586,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9808646,"Dynamic changes within the cyberspace are greatly impacting human lives and our societies. Emerging evidence indicates that without an ethical overlook on technological progress, intelligent solutions created to improve and enhance our lives can easily be turned against humankind. In complex AI-socio-technical ecosystems where humans, AI (Artificial Intelligence) and systems interact without a common language for building trust, this paper introduces a methodological concept of Ethical Digital Identities for supporting the ethical evaluation of intelligent digital assets.",0.19480519480519481
3,Why Do Companies Employ Prohibited Unethical Artificial Intelligence Practices?,M. Méndez-Suárez; M. d. l. M. de Obesso; O. C. Márquez; C. M. Palacios,ieee,10.1109/TEM.2023.3258686,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10084347,"In this article, we investigate the previously unstudied reasons why companies use prohibited artificial intelligence (AI) applications and are punished with large fines under the European General Data Protection Regulation (GDPR). Investigating and understanding why companies engage in such severe AI ethical malpractices is essential to correct them as they seriously jeopardize the future development of AI. Based on a sample of 34 companies, out of which 23 were sanctioned under GDPR due to severe violations of AI ethical principles and using fuzzy-set qualitative comparative analysis, this study demonstrates that to be an AI ethical company and comply with the GDPR regulation, it is necessary to have an AI ethical statement, have a very strong concern for information cybersecurity, and have to be based in a country considered ethical or monitor with care the behavior of the firm in countries with lower ethical standards. As a theoretical contribution, although some authors argue that AI ethical principles are useless, the present research introduces a new theoretical perspective by demonstrating cause–effect relationships between business configurations and AI ethical failures. In addition, the results have an important managerial relevance because they show that lack of an AI ethical statement is the most relevant condition that led to ethical misbehaviors.",0.1941747572815534
4,An Integrated Framework for Ethical and Sustainable Digitalization,I. Wallimann-Helmer; L. Terán; E. Portmann; H. Schübel; J. Pincay,ieee,10.1109/ICEDEG52154.2021.9530972,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9530972,"Dynamically developing digitization initiatives among public institutions and private companies necessitate a balanced approach to digital ethics. Several frameworks and legal regulations have been adopted to clarify and define the various ethical challenges in digital contexts. These initiatives often accentuate one of three components: data security, data governance, or digital strategy. However, an integrated approach is required to meet the current demand for an ethical and sustainable approach to digitalization and address the growing number of challenges occurring in handling data and related peripheral components. This paper develops the concept of an integrated framework to incorporate all relevant aspects of digital ethics by combining three categories of digital contexts: law and regulations, ethics and justice, and environmental sustainability. The core of this integrated framework, the Fribourg sustainable digital ethics framework (FSDEF), consists of two boundary conditions of sustainable development: social thresholds of justice and ecological planetary boundaries. It also incorporates numerous other frameworks and standards, including value-based engineering and IEEE standards.",0.19254658385093168
5,Exploring Approaches to Artificial Intelligence Governance: From Ethics to Policy,D. Kim; Q. Zhu; H. Eldardiry,ieee,10.1109/ETHICS57328.2023.10155067,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155067,"There has been a trend among various stakeholders for AI governance, such as the government, industry, and academia, that advocates for a shift from AI ethics to AI policy. In this paper, we briefly introduce the motivation for such a change and two complementary reports about AI ethics policy development to help AI ethics researchers operationalize abstract AI ethics principles into actionable policy items. We also discuss the implications of the policy approach to AI governance for training the next generation of AI professionals.",0.19047619047619047
6,A Case Study of Privacy Protection Challenges and Risks in AI-Enabled Healthcare App,P. Wang; H. Zare,ieee,10.1109/CAI54212.2023.00132,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10195065,"Artificial intelligence (AI) is increasingly used in healthcare systems and applications (apps) with questions and debates on ethical issues and privacy risks. This research study explores and discusses the ethical challenges, privacy risks, and possible solutions related to protecting user data privacy in AI-enabled healthcare apps. The study is based on the healthcare app named Charlie in one of the fictional case studies designed by Princeton University to elucidate critical thinking and discussions on emerging ethical issues embracing AI.",0.189873417721519
7,Ethical Chatbot Design for Reducing Negative Effects of Biased Data and Unethical Conversations,J. Bang; S. Kim; J. W. Nam; D. -G. Yang,ieee,10.1109/PlatCon53246.2021.9680760,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680760,"AI technology is being introduced into various public and private service domains, transforming existing computing systems or creating new ones. While AI technologies can provide benefits to humans and society, the unexpected consequences (e.g., malfunctions) of AI systems can cause social losses. For this reason, research on ethical design for the development of AI-based systems is becoming important. In this paper, from existing studies on AI ethics, general guidelines such as transparency, explainability, predictability, accountability, fairness, privacy, and control for the ethical design of AI systems are reviewed. And, based on the ethical design guidelines, we discuss ethical design to reduce the negative effects of biased data and unethical dialogues in AI-based conversational chatbots.",0.18421052631578946
8,AI Ethics Impact Assessment based on Requirement Engineering,I. Nitta; K. Ohashi; S. Shiga; S. Onodera,ieee,10.1109/REW56159.2022.00037,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9920150,"This paper proposes a methodology for evaluating the ethical impact of artificial intelligence (AI) systems on people and society based on AI ethics guidelines. The ethical impact of AI has been recognized as a social issue, and countries and organizations have formulated principles and guidelines on AI ethics, and laws and regulations will be enforced in Europe. Because these principles and guidelines are written in terms of philosophy and law, AI service providers, developers, and business users have the challenge of how they should practice the principles and guidelines to their AI systems. To address this challenge, we first analyzed cases of ethical problems caused by AI in the past and assumed that ethical problems could be linked to interactions between components of AI systems and stakeholders related to such systems. On the basis of this assumption, we then developed a methodology to comprehensively extract the ethical risks that an AI system poses. This methodology consists of two approaches. The first approach is to develop an AI ethics model that embodies ethics guidelines as necessary requirements for ethical AI systems and correlates these requirements with interactions. The second approach is an impact assessment process that uses the AI ethics models to extract ethical risks for individual AI systems. In this paper, we discuss the details of this methodology and show the results of an initial validation to verify the above assumption and the ease of the impact assessment process.",0.18410041841004185
9,Ethical Framework Associated with AI,,ieee,10.1002/9781119831808.ch3,https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9823054.pdf&bkn=9820928&pdfType=chapter,"Ethics is a bridge between the innate and the acquired for our social behaviors and our intelligence. The ethics charter promotes the construction of an environmental ethic by introducing fundamental ethical principles that apply to the organization as well as to managers and employees. This charter aims to give all actors involved in artificial intelligence (AI) the ethical, legal and technical foundations useful and necessary for the design, implementation and correct use. The development of AI requires us to invent new knowledge, new know‐how and new ways of living with these new technologies. The chapter focuses on the five stages of ethics, namely ethics of data, ethics of systems, ethics of algorithms, ethics of practice and ethics of decisions. A notable complexity in the health field lies in the direct use by users, without the intervention of health personnel, of certain applications or devices using AI on health data or collecting health data.",0.1830065359477124
10,"Speech Act Theory and Ethics of Speech Processing as Distinct Stages: the ethics of collecting, contextualizing and the releasing of (speech) data",J. Thomas; L. Arya; M. Hussain; S. R. M. Prasanna,ieee,10.1109/ETHICS57328.2023.10154932,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10154932,"Using speech act theory from the Philosophy of Language, this paper attempts to develop an ethical framework for the phenomenon of speech processing. We use the concepts of the illocutionary force and the illocutionary content of a speech act to explain the ethics of speech processing. By emphasizing the different stages involved in speech processing, we explore the distinct ethical issues that arise in relation to each stage. Input, processing, and output are the different ethically relevant stages under which a spoken item or a speech navigates within the range of speech-processing modules. Employing the illocutionary force-content distinction, we specify and characterize the input-related ethical issues, the output-related ethical issues, and the processing-related ethical issues involved in speech processing. Together with illocutionary force-content distinction, we employ the data-information distinction to characterize the stage-wise ethical issues in the phenomenon of speech processing as the ethics of collecting (speech) data, the ethics of contextualizing (speech) data/information, and the ethics of releasing the con-textualized information (processed speech). Immediate ethical issues that arise from the range of speech processing modules are distinguished from distant ethical issues. We also indicate the nature of ethical issues that arise from Speaker Independent speech technologies.",0.18274111675126903
11,The Contestation of Tech Ethics: A Sociotechnical Approach to Technology Ethics in Practice,B. Green,ieee,10.23919/JSC.2021.0018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684741,"This article introduces the special issue “Technology Ethics in Action: Critical and Interdisciplinary Perspectives”. In response to recent controversies about the harms of digital technology, discourses and practices of “tech ethics” have proliferated across the tech industry, academia, civil society, and government. Yet despite the seeming promise of ethics, tech ethics in practice suffers from several significant limitations: tech ethics is vague and toothless, has a myopic focus on individual engineers and technology design, and is subsumed into corporate logics and incentives. These limitations suggest that tech ethics enables corporate “ethics-washing”: embracing the language of ethics to defuse criticism and resist government regulation, without committing to ethical behavior. Given these dynamics, I describe tech ethics as a terrain of contestation where the central debate is not whether ethics is desirable, but what “ethics” entails and who gets to define it. Current approaches to tech ethics are poised to enable technologists and technology companies to label themselves as “ethical” without substantively altering their practices. Thus, those striving for structural improvements in digital technologies must be mindful of the gap between ethics as a mode of normative inquiry and ethics as a practical endeavor. In order to better evaluate the opportunities and limits of tech ethics, I propose a sociotechnical approach that analyzes tech ethics in light of who defines it and what impacts it generates in practice.",0.17699115044247787
12,An Overview of Artificial Intelligence Ethics,C. Huang; Z. Zhang; B. Mao; X. Yao,ieee,10.1109/TAI.2022.3194503,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9844014,"Artificial intelligence (AI) has profoundly changed and will continue to change our lives. AI is being applied in more and more fields and scenarios such as autonomous driving, medical care, media, finance, industrial robots, and internet services. The widespread application of AI and its deep integration with the economy and society have improved efficiency and produced benefits. At the same time, it will inevitably impact the existing social order and raise ethical concerns. Ethical issues, such as privacy leakage, discrimination, unemployment, and security risks, brought about by AI systems have caused great trouble to people. Therefore, AI ethics, which is a field related to the study of ethical issues in AI, has become not only an important research topic in academia, but also an important topic of common concern for individuals, organizations, countries, and society. This article will give a comprehensive overview of this field by summarizing and analyzing the ethical risks and issues raised by AI, ethical guidelines and principles issued by different organizations, approaches for addressing ethical issues in AI, and methods for evaluating the ethics of AI. Additionally, challenges in implementing ethics in AI and some future perspectives are pointed out. We hope our work will provide a systematic and comprehensive overview of AI ethics for researchers and practitioners in this field, especially the beginners of this research discipline.",0.17567567567567569
13,Proposed Model of Work Ethics in Artificial Intelligence and Emerging Digital Technologies,S. H. Aldulaimi; M. M. Abdeldayem; M. Y. Abo Keir; M. Abdelhakim,ieee,10.1109/ICETSIS55481.2022.9888900,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9888900,"The digital revolution witnessed by human civilization and technological development increases the degree of complexity and takes global dimensions, with many challenges and ethical problems. This research deals with digital ethics from a philosophical side, which must be taken into consideration in light of the reign of the digital age in order to solve and avoid emerging ethical problems. The research draws attention to the need to think beyond the facts and theories related to the current standards for the formation of moral awareness. That calls for and emphasizes the need to spread the culture of information and ethics. The findings of this paper led to propose a practical model to imagine the formation of the ethical model in the digital era consisting of several factors.",0.16666666666666666
14,Big Data in Business and Ethical Challenges,N. Zulkarnain; M. Anshari; M. Hamdan; M. Fithriyah,ieee,10.1109/ICIMTech53080.2021.9534963,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534963,"Organizations have been adopting Big Data for various purposes and its presence becomes more significant than ever in any public or private sector. However, this adoption comes with its own challenges. Organizations may face or deal with ethical challenges on how they get and utilized data. Because data appears to be easily accessible, ethical compliance in the use of social media data cannot be overlooked. The goal of this research is to see how the phenomena of big data might make ethical decisions more difficult for organizations. This research was built on recent literature reviews, and the discussion intended to examine the extent Big Data application intercepts business ethics, especially on collecting customer data. Hence, Organizations must have transparent policies on big data applications and good practices to promote an ethical culture.",0.16666666666666666
15,A Quantitative Model for the Assessment of Ethics Risks in Information Technology,G. Rafaiani; G. Barchiesi; L. Ilari; M. Baldi; B. Giovanola,ieee,10.1109/ETHICS57328.2023.10155002,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155002,"The management of sensitive and personal data in the healthcare sector must guarantee the widest respect of patients' fundamental rights. However, some quantitative evaluation framework for assessing the level of ethical compliance of a technology to the most important ethical principles is still missing. In this work, we first provide a model to quantitatively assess constitutive ethics, i.e., the intrinsic ethical compliance of a technology. Secondly, we propose a method for quantitatively assessing circumstantial ethics risks of a technology, when used in some specific context. Our ethics risk assessment model is based on the evaluation of the compliance of the technology to a defined set of controls about some ethical principles and about the robustness of the technological infrastructure underneath. Then, we validate our model by applying it to some recent healthrelated blockchain frameworks, and we compare a qualitative ethical assessment with the quantitative assessment made with the proposed model for constitutive ethics compliance. Through our assessment, we identify some technical choices that achieve the highest ethical scores, such as using a permissioned blockchain, off-chain storage, and encryption of data. Finally, we observe that the principles of privacy and data governance turn out to be the most satisfied ethical principles, contrary to fairness.",0.1625615763546798
16,What Would You do? An Ethical AI Quiz,W. Teo; Z. Teoh; D. A. Arabi; M. Aboushadi; K. Lai; Z. Ng; A. Pant; R. Hoda; C. Tantithamthavorn; B. Turhan,ieee,10.1109/ICSE-Companion58688.2023.00036,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172891,"The resurgence of Artificial Intelligence (AI) has been accompanied by a rise in ethical issues. AI practitioners either face challenges in making ethical choices when designing AI-based systems or are not aware of such challenges in the first place. Increasing the level of awareness and understanding of the perceptions of those who develop AI systems is a critical step toward mitigating ethical issues in AI development. Motivated by these challenges, needs, and the lack of engaging approaches to address these, we developed an interactive, scenario-based ethical AI quiz. It allows AI practitioners, including software engineers who develop AI systems, to self-assess their awareness and perceptions about AI ethics. The experience of taking the quiz, and the feedback it provides, will help AI practitioners understand the gap areas, and improve their overall ethical practice in everyday development scenarios. To demonstrate these expected outcomes and the relevance of our tool, we also share a preliminary user study. The video demo can be found at https://zenodo.org/record/7601169#.Y9xgA-xBxhF.",0.15950920245398773
17,"Bridging Industry, Government, and Academia for Socially Responsible AI: The CSEAI Initiative",P. Rivas; J. Ortiz; D. A. Díaz-Pachón; L. N. Montoya,ieee,10.1109/ETHICS57328.2023.10155071,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155071,"The mission of the Center for Standards and Ethics in Artificial Intelligence (CSEAI) is to promote safe, effective, and ethical AI standards through research, outreach, and education in partnership with industry and government. We briefly discuss CSEAI's workforce development plan, including mentoring undergraduate and graduate students and providing continuing education for industry professionals. The CSEAI aims to facilitate the production of standardized, ethical AI products that are safe for users and promote diversity in the field. By underscoring the importance of socially responsible innovation and ethical standards in AI, we show the CSEAI's aims to protect consumers and increase trust in responsible AI products and services.",0.1509433962264151
18,Imagine a More Ethical AI: Using Stories to Develop Teens' Awareness and Understanding of Artificial Intelligence and its Societal Impacts,S. Forsyth; B. Dalton; E. H. Foster; B. Walsh; J. Smilack; T. Yeh,ieee,10.1109/RESPECT51740.2021.9620549,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9620549,"Artificial intelligence (AI) tools and technologies are increasingly prevalent in society. Many teens interact with AI devices on a daily basis but often have a limited understanding of how AI works, as well as how it impacts society more broadly. It is critical to develop youths' understanding of AI, cultivate ethical awareness, and support diverse youth in pursuing computer science to help ensure future development of more equitable AI technologies. Here, we share our experiences developing and remotely facilitating an interdisciplinary AI ethics program for secondary students designed to increase teens' awareness and understanding of AI and its societal impacts. Students discussed stories with embedded ethical dilemmas, engaged with AI media and simulations, and created digital products to express their stance on an AI ethics issue. Across four iterations in formal and informal settings, we found students to be engaged in AI stories and invested in learning about AI and its societal impacts. Short stories were effective in raising awareness, focusing discussion and supporting students in developing a more nuanced understanding of AI ethics issues, such as fairness, bias and privacy.",0.14917127071823205
19,AI Ethics: Algorithmic Determinism or Self-Determination? The GPDR Approach,M. Milossi; E. Alexandropoulou-Egyptiadou; K. E. Psannis,ieee,10.1109/ACCESS.2021.3072782,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9400809,"Artificial Intelligence (AI) refers to systems designed by humans, interpreting the already collected data and deciding the best action to take, according to the pre-defined parameters, in order to achieve the given goal. Designing, trial and error while using AI, brought ethics to the center of the dialogue between tech giants, enterprises, academic institutions as well as policymakers. Ethical challenges in AI brought ethical AI framework in place in an attempt to regulate people’s lives and interactions, used for the benefit of society, for the human rights’ protection as well as for the respect of individual’s privacy and autonomy. The paper aims to summarize and critically evaluate the basic principles for the use of AI, with emphasis to the General Data Protection Regulation’s (GDPR) approach, concerning data subject’s consent, data protection principles and data subject’s rights in a context of ‘privacy by design’ architecture.",0.14583333333333334
20,"Peer Support Specialists and Service Users’ Perspectives on Privacy, Confidentiality, and Security of Digital Mental Health",M. D. Venegas; J. M. Brooks; A. L. Myers; M. Storm; K. L. Fortuna,ieee,10.1109/MPRV.2022.3141986,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723457,"As the digitalization of mental health systems progresses, the ethical and social debate on the use of these mental health technologies has seldom been explored among end-users. This article explores how service users (e.g., patients and users of mental health services) and peer support specialists understand and perceive issues of privacy, confidentiality, and security of digital mental health interventions. Semi-structured qualitative interviews were conducted among service users (n = 17) and peer support specialists (n = 15) from a convenience sample at an urban community mental health center in the United States. We identified technology ownership and use, lack of technology literacy including limited understanding of privacy, confidentiality, and security as the main barriers to engagement among service users. Peers demonstrated a high level of technology engagement, literacy of digital mental health tools, and a more comprehensive awareness of digital mental health ethics. We recommend peer support specialists as a potential resource to facilitate the ethical engagement of digital mental health interventions for service users. Finally, engaging potential end-users in the development cycle of digital mental health support platforms and increased privacy regulations may lead the field to a better understanding of effective uses of technology for people with mental health conditions. This study contributes to the ongoing debate of digital mental health ethics, data justice, and digital mental health by providing a first-hand experience of digital ethics from end-users’ perspectives.",0.14285714285714285
21,Real World Autonomous IoT Based Data Privacy Protection Using Machine Learning,D. Jagadeesan; S. R; S. S; T. S; A. B,ieee,10.1109/ICONSTEM56934.2023.10142934,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10142934,"Connecting everyday objects to the web (IoT)has rapidly grown what might be anticipated to continue expanding with an estimated By 2025, there will be 75 billion linked gadgets. This increase in IoT devices has led to concerns regarding data privacy and security. Autonomous IoT-based data privacy protection using machine learning (ML) has the potential to address these concerns.This research proposes a real-world application of autonomous IoT-based data privacy protection using ML. The system will use ML algorithms to analyze data and identify potential privacy breaches. It will then autonomously take appropriate actions to protect the data and prevent further breaches.The proposed research will use a mixed-methods approach, including surveys, case studies, and experiments, to collect data from IoT users, privacy experts, and ML researchers. The data collected will be used to evaluate the effectiveness of the proposed system in protecting data privacy and to identify any potential ethical concerns.The expected outcomes of this research are the development of an autonomous IoT-based data privacy protection system using ML, evaluation of its effectiveness in protecting data privacy, and identification of any ethical concerns that may arise.Overall, this research has the potential to contribute to the development of autonomous IoT-based data privacy protection systems that are effective in protecting data privacy while upholding ethical standards. The proposed Ultimately, this strategy might significantly alter the status quo of data privacy is protected in IoT, ensuring that users can confidently use IoT devices without concerns about privacy breaches.",0.13991769547325103
22,Professional Societies as Adopters and Enforcers of AI Soft Law,G. E. Marchant,ieee,10.1109/TTS.2021.3116524,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9557858,"Professional societies that include artificial intelligence (AI) practitioners as members have been active in adopting and communicating codes of ethics for their membership. Such professional codes of ethics likely have an expressive benefit in encouraging society members to give greater consideration to ethical factors, although the relatively few empirical studies on professional society codes of ethics have failed to demonstrate any consistent, practical benefit. In contrast, company codes of ethics have been demonstrated to be effective in some contexts, because the company as employer can create a supportive work environment that values and rewards ethical behavior. This article proposes three potential strategies to increase the effectiveness and credibility of professional society ethical codes as governance tools. First, enforcement of the codes should be broader and more transparent. Second, employers could be enlisted to help enforce the codes adopted by professional societies, given employers’ greater influence in creating a more compliant and ethical workplace culture. Third, AI practitioners could be professionalized, with accompanying licensure, educational, and ethical requirements. There are pros and cons related to each of these three strategies.",0.13966480446927373
23,Focusing on the Ethical Challenges of Data Breaches and Applications,K. Joisten; N. Thiemer; T. Renner; A. Janssen; A. Scheffler,ieee,10.1109/ICAA52185.2022.00018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9763591,"Ethical challenges of the human lifeworld that are caused by data breaches and applications are steadily increasing. Therefore, a new ethical concept must be brought into focus: Technoethics for Emerging Digital Systems (TEDS). TEDS is presented as an integrative and innovative approach committed to an interdisciplinary perspective. Thereby, TEDS reflects all social areas of the human lifeworld in their ethical scope. With recourse to phenomenological methods, TEDS helps to address ethical implications which arise from deep interference of autonomous systems with the human lifeworld. The meaning of intentional structures and the problem of appresentations in the phenomenological sense still represents a blank gap in the current ethical discourse on the problem of data breaches. The findings provide methods for dealing with ethical challenges and explain the problem area of an appropriate technoethical use in the lifeworld. In this way, problems can already be avoided in the development process of artificial intelligence systems and their applications by specifically searching for blind spots in a technical and ethical manner. Furthermore, this approach helps to assure a technoethical use of autonomous systems in an appropriate way and ultimately leads to a limitation of damages – which may occur in case of malfunctions and data breaches of artificial intelligence systems – in the lifeworld of humans. Our contribution is to introduce TEDS as a new ethical concept that has not existed before. This new concept focuses on the application of phenomenological methods to detect ethical errors in digital systems.",0.13877551020408163
24,Technical Briefing: Hands-On Session on the Development of Trustworthy AI Software,V. Vakkuri; K. -K. Kemell; P. Abrahamsson,ieee,10.1109/ICSE-Companion52605.2021.00142,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9402396,"Following various real-world incidents involving both purely digital and cyber-physical Artificial Intelligence (AI) systems, AI Ethics has become a prominent topic of discussion in both research and practice, accompanied by various calls for trustworthy AI systems. Failures are often costly, and many of them stem from issues that could have been avoided during development. For example, AI ethics issues, such as data privacy are currently highly topical. However, implementing AI ethics in practice remains a challenge for organizations. Various guidelines have been published to aid companies in doing so, but these have not seen widespread adoption and may feel impractical. In this technical briefing, we discuss how to implement AI ethics. We showcase a method developed for this purpose, ECCOLA, which is based on academic research. ECCOLA is intended to make AI ethics more practical for developers in order to make it easier to incorporate into AI development to create trustworthy AI systems. It is a sprint-based and adaptive tool designed for agile development that facilitates reflection within the development team and helps developers make ethics into tangible product backlog items.",0.13812154696132597
25,AI Digital Tool Product Lifecycle Governance Framework through Ethics and Compliance by Design†,E. Ortega; M. Tran; G. Bandeen,ieee,10.1109/CAI54212.2023.00155,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10195137,"The acceleration of Artificial Intelligence (AI) has brought forward new digital tools that have had a wide impact across society. However, AI digital tools (such as ChatGPT, midjourney, DALL-E 2) have brought forward legal and ethical concerns. — Internationally, public, and private leaders are introducing regulatory frameworks to address data governance for such these AI digital tools (i.e., Global Data Protection Regulation, the European AI Act, Blueprint for an AI Bill of Rights, NIST Risk Management Framework, etc.). We recognize that these AI digital tools are a vital aspect of future technological development, but they require input from various sectors in addressing ethics and compliance design. We survey the current landscape of published AI-specific regulatory frameworks and known engineering design process methods. Using a product lifecycle approach, we also introduce a trans-disciplinary framework to address AI ethics and compliance via design. This product lifecycle approach considers several principles: a Human-Centered Design for Risk Assessment, Functional Safety and Risk Management Standardization, and Continuous Governance throughout Product Lifecycle. Establishing risk management throughout AI product lifecycles can ensure accountability for AI product use cases. In addition, by utilizing previous Functional Safety considerations we can create safety mechanisms throughout the product lifecycle of AI digital tools. Finally, establishing in-field testing for continuous governance will enable the flexibility for new compliance standards and transparency. We establish this governance framework to aid in new compliance strategies for these emerging issues with AI digital tools.",0.13445378151260504
26,Analysis of Sentiment Towards Artificial Intelligent Industry Using Hybrid Natural Language Processing Technique,H. Chang,ieee,10.1109/ICSECS58457.2023.10256397,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10256397,"Artificial Intelligence (AI) has revolutionized various aspects of human life and transformed how people live, work, and interact. However, the development of AI also poses potential risks and ethical concerns. In this report, we aim to analyze the sentiment toward the AI industry using hybrid natural language processing techniques. To achieve our aim, we propose a model that draws upon a survey of related work. Data collection involves gathering user-generated data from social media platforms. We then use hybrid natural language processing techniques to analyze the sentiment toward the AI industry. Our analysis reveals that the sentiment towards the AI industry is generally positive, with many people recognizing its potential benefits. However, there are also concerns about the potential risks and ethical implications of AI development. Some leading figures in the AI industry have expressed concerns about the potential misuse of AI and the need for ethical guidelines. In conclusion, our analysis highlights the transformative effects of AI on various industries and the potential risks associated with its development. We recommend that policymakers and industry leaders work together to develop ethical guidelines for the development and use of AI. This will help to ensure that the benefits of AI are maximized while minimizing the potential risks and ethical concerns.",0.1339712918660287
27,A Study on the Development of Digital literacy Diagnosis Tool for Lifelong Education Institutions,C. -J. Lee; S. -W. Choi,ieee,10.1109/SNPDWinter52325.2021.00025,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9403504,"It is an era in which the level of national digital literacy is the adaptability and competitiveness of the future society. In line with these times, studies on various literacy education and programs are being actively conducted in the field of lifelong education. However most of them are fragmentary event education or one-time programs. It is difficult to say that it is an education for continuous improvement of digital literacy capabilities.Lifelong education institutions need educational programs and teachers that able to not onlyutilize ICT but also communicate through digital, exchange information and creatively construct newly accepted information. For this it is necessary to measure the digital literacy competency and level of lifelong education teachers to properly recognize the digital literacy competency required for their job.They can continually develop and test their digital literacy capabilities by repeating these measurements, This study aims to present a methodology for developing competency diagnosis tools in the categories of digital ethics, digital competence, and digital application according to the education association's digital literacy framework.",0.1301775147928994
28,The Ethical Approach to AI,,ieee,10.1002/9781119831808.ch2,https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9822260.pdf&bkn=9820928&pdfType=chapter,"The pace of technological innovation and the temporality of its worldwide launch, supported by the digital economy, is clearly outpacing the speed of human awareness. Artificial intelligence (AI) ethics is a branch of digital ethics specific to robots and other artificially intelligent agents. One of the important ethical issues of Big Data concerns their apparent objectivity in illustrating social reality with scientific authority and technical rigor. The emergence of AI is likely to mask the development of a societal project, modeled according to their economic interests and the increase of their vision. The chapter aims to list and define the main ethical criteria that will constitute the basis of a future reference system in order to move toward AI at the service of human intelligence and prevent and anticipate the drifts and possible consequences of the improvement of algorithmic systems.",0.12857142857142856
29,"Dealing with Ethics, Privacy, and Security",S. Sinha; K. Al Huraimel,ieee,10.1002/9781119709183.ch12,https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9821896.pdf&bkn=9820895&pdfType=chapter,"This chapter broadens the horizon about ethics, data privacy, and cybersecurity in businesses. It gives practical guidance on how to build barriers against threats. In the age of artificial intelligence (AI), ethics has attained a completely different level of significance and debate. The chapter discusses some of the key issues to consider around ethics and AI, including artificial stupidity and data trustworthiness. Privacy starts with data ownership. The General Data Protection Regulation (GDPR) has stringent stipulations around the various rights of individuals around the personal data. It brings personal data into a complex and protective regulatory regime. AI programs have increased vulnerabilities because there are more difficult‐to‐identify places to inject and bury threat vectors. The chapter provides information on cybersecurity assurance practices and industry standards for cybersecurity compliance. AI is also a great tool for identifying cyber‐threats. This is one of the biggest emerging applications of AI techniques.",0.12837837837837837
30,AI Ethics: An Empirical Study on the Views of Practitioners and Lawmakers,A. A. Khan; M. A. Akbar; M. Fahmideh; P. Liang; M. Waseem; A. Ahmad; M. Niazi; P. Abrahamsson,ieee,10.1109/TCSS.2023.3251729,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10066257,"Artificial intelligence (AI) solutions and technologies are being increasingly adopted in smart systems contexts; however, such technologies are concerned with ethical uncertainties. Various guidelines, principles, and regulatory frameworks are designed to ensure that AI technologies adhere to ethical well-being. However, the implications of AI ethics principles and guidelines are still being debated. To further explore the significance of AI ethics principles and relevant challenges, we conducted a survey of 99 randomly selected representative AI practitioners and lawmakers (e.g., AI engineers and lawyers) from 20 countries across five continents. To the best of our knowledge, this is the first empirical study that unveils the perceptions of two different types of population (AI practitioners and lawmakers) and the study findings confirm that transparency, accountability, and privacy are the most critical AI ethics principles. On the other hand, lack of ethical knowledge, no legal frameworks, and lacking monitoring bodies are found to be the most common AI ethics challenges. The impact analysis of the challenges across principles reveals that conflict in practice is a highly severe challenge. Moreover, the perceptions of practitioners and lawmakers are statistically correlated with significant differences for particular principles (e.g. fairness and freedom) and challenges (e.g. lacking monitoring bodies and machine distortion). Our findings stimulate further research, particularly empowering existing capability maturity models to support ethics-aware AI systems’ development and quality assessment.",0.12556053811659193
31,An End-to-End Data Pipeline for Managing Learning Analytics,J. C. Farah; J. S. Machado; P. T. da Cunha; S. Ingram; D. Gillet,ieee,10.1109/ITHET50392.2021.9759783,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9759783,"Despite the importance of learning analytics in digital education, there is limited support for researchers in education to generate, access, and share experimental data while complying with ethical and privacy legislation. We propose a set of related tools that support researchers with these tasks and present a blueprint for how these tools can be integrated with existing platforms, enabling researchers to run studies within learning environments, adhere to legal and ethical privacy frameworks, and share their anonymous or anonymized data with a wider audience. We demonstrate the integration of these features into an existing online learning platform.",0.12371134020618557
32,A Deployment Model to Extend Ethically Aligned AI Implementation Method ECCOLA,J. Antikainen; M. Agbese; H. -K. Alanen; E. Halme; H. Isomäki; M. Jantunen; K. -K. Kemell; R. Rousi; H. Vainio-Pekka; V. Vakkuri,ieee,10.1109/REW53955.2021.00043,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582298,"There is a struggle in Artificial intelligence (AI) ethics to gain ground in actionable methods and models to be utilized by practitioners while developing and implementing ethically sound AI systems. AI ethics is a vague concept without a consensus of definition or theoretical grounding and bearing little connection to practice. Practice involving primarily technical tasks like software development is not aptly equipped to process and decide upon ethical considerations. Efforts to create tools and guidelines to help people working with AI development have been concentrating almost solely on the technical aspects of AI. A few exceptions do apply, such as the ECCOIA method for creating ethically aligned AI -systems. ECCOIA has proven results in terms of increased ethical considerations in AI systems development. Yet, it is a novel innovation, and room for development still exists. This study aims to extend ECCOIA with a deployment model to drive the adoption of ECCOIA, as any method - no matter how good -is of no value without adoption and use. The model includes simple metrics to facilitate the communication of ethical gaps or outcomes of ethical AI development. It offers the opportunity to assess any AI system at any given life-cycle phase, e.g., opening possibilities like analyzing the ethicality of an AI system under acquisition.",0.12264150943396226
33,AI Technology in the Field of Logistics,V. Soumpenioti; A. Panagopoulos,ieee,10.1109/SMAP59435.2023.10255203,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10255203,"This academic paper explores the implications and future trends of Artificial Intelligence (AI) in the logistics industry. The study focuses on the impact of AI on job roles and employment, as well as addressing concerns related to data privacy, security, and ethical considerations. The research highlights that AI technology is reshaping job roles in logistics through automation and the emergence of new positions. Routine tasks such as data entry and inventory management are being automated, resulting in streamlined processes and increased operational efficiency. Simultaneously, the introduction of AI necessitates the development of new job roles such as AI system trainers, data analysts, and AI strategists. The paper also outlines future trends in AI adoption in logistics. These include the integration of AI with robotics, enabling cognitive robots to perform complex tasks such as autonomous picking and packing in warehouses. Additionally, the integration of AI with blockchain technology enhances transparency, traceability, and security in logistics operations. However, the paper acknowledges the challenges associated with AI implementation. Logistics companies must ensure compliance with privacy regulations and implement robust cybersecurity measures to safeguard critical infrastructure and data. Furthermore, ethical considerations regarding transparency, fairness, and accountability must be addressed to ensure responsible and unbiased use of AI technology. Overall, the research highlights the significance of AI in transforming the logistics industry. AI enables enhanced efficiency, improved decision-making, and cost savings. It provides opportunities for upskilling while creating new job roles. To fully harness the benefits of AI, logistics companies must navigate the challenges of data privacy, security, and ethical considerations.",0.12109375
34,AI4Eq: For a True Global Village Not for Global Pillage,A. Manjarrés; S. Pickin; M. A. Artaso; E. Gibbons,ieee,10.1109/MTS.2021.3056290,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9379044,"The last few years have seen a large number of initiatives on artificial intelligence (AI) ethics: intergovernmental-institution initiatives such as “Ethics Guidelines for Trustworthy AI” from the high-level expert group on AI of the European Commission [1] or the Organisation for Economic Cooperation and Development (OECD) Council Recommendation on Artificial Intelligence [2], government initiatives such as that of the U.K. Parliament Select Committee on Artificial Intelligence [3], industry initiatives on AI ethical codes such as those of Google, IBM, Microsoft, and Intel, academic initiatives such as the Montreal declaration for the responsible development of AI [4], the Stanford University 100 Year Study on AI [5] or the Alan Turing Institute's “Understanding Artificial Intelligence Ethics and Safety” [6], and finally professional body initiatives such as the IEEE Global Initiative on Ethics of Autonomous/Intelligent Systems (A/IS) [7]. These initiatives, while acknowledging the potential of A/IS technologies to contribute to global socioeconomic solutions, highlight the increasing challenges posed by these technologies in the ethical, moral, legal, humanitarian, and sociopolitical domains.",0.11976047904191617
35,The Different Faces of AI Ethics Across the World: A Principle-to-Practice Gap Analysis,L. N. Tidjon; F. Khomh,ieee,10.1109/TAI.2022.3225132,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9964285,"Artificial Intelligence (AI) is transforming our daily life with many applications in healthcare, space exploration, banking, and finance. This rapid progress in AI has brought increasing attention to the potential impacts of AI technologies on society, with ethically questionable consequences. In recent years, several ethical principles have been released by governments, national organizations, and international organizations. These principles outline high-level precepts to guide the ethical development, deployment, and governance of AI. However, the abstract nature, diversity, and context-dependence of these principles make them difficult to implement and operationalize, resulting in gaps between principles and their execution. Most recent work analyzed and summarized existing AI principles and guidelines but did not provide findings on principle-to-practice gaps nor how to mitigate them. These findings are particularly important to ensure that AI practical guidances are aligned with ethical principles and values. In this article, we provide a contextual and global evaluation of current ethical AI principles for all continents, with the aim to identify potential principle characteristics tailored to specific countries or applicable across countries. Next, we analyze the current level of AI readiness and current practical guidances of ethical AI principles in different countries, to identify gaps in the practical guidance of AI principles and their causes. Finally, we propose recommendations to mitigate the principle-to-practice gaps.",0.11682242990654206
36,Towards Implementing Responsible AI,C. Sanderson; Q. Lu; D. Douglas; X. Xu; L. Zhu; J. Whittle,ieee,10.1109/BigData55660.2022.10021121,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10021121,"As the deployment of artificial intelligence (AI) is changing many fields and industries, there are concerns about AI systems making decisions and recommendations without adequately considering various ethical aspects, such as accountability, reliability, transparency, explainability, contestability, privacy, and fairness. While many sets of AI ethics principles have been recently proposed that acknowledge these concerns, such principles are high-level and do not provide tangible advice on how to develop ethical and responsible AI systems. To gain insight on the possible implementation of the principles, we conducted an empirical investigation involving semi-structured interviews with a cohort of AI practitioners. The salient findings cover four aspects of AI system design and development, adapting processes used in software engineering: (i) high-level view, (ii) requirements engineering, (iii) design and implementation, (iv) deployment and operation.",0.11627906976744186
37,Data Ethics Framework for Artificial Intelligence in Education (AIED),Y. Hong; A. Nguyen; B. Dang; B. -P. T. Nguyen,ieee,10.1109/ICALT55010.2022.00095,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9853807,"In recent years, we have gradually adopted the applications of artificial intelligence in education (AIED) to improve our understanding of students’ learning and enhance their learning experiences. AIED can have a profound impact on the educational landscape, influencing the role of all involved in education. The adoption of AIED and its related large-scale data collection and analysis to do with learners seriously concern human-rights and related ethical and privacy aspects. This paper presents conceptual research establishing a data ethics framework for AIED by mapping and analyzing international organizations’ current policies and guidelines. In addition to contributing to the discussion of the benefits of AI in education, this paper raises data ethics concern for AIED. The proposed framework helps promote the design, development, and implementation of ethical and trustworthy AIED.",0.11627906976744186
38,Design of an Ethical Framework for Artificial Intelligence in Cultural Heritage,S. Pansoni; S. Tiribelli; M. Paolanti; E. Frontoni; B. Giovanola,ieee,10.1109/ETHICS57328.2023.10155020,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155020,"In recent years Artificial Intelligence (AI) has found its way into the creative and cultural industries, opening up new challenges and opportunities, poorly sufficiently explored today. However, when it comes to culture and creativity, many social and political cost factors should be taken into account. It is crucial to identify the opportunities that AI can offer in terms of the preservation, use, promotion, and accessibility of Cultural Heritage (CH). However, ethical concerns should be outlined when applying AI in cultural settings, such as for the digital replica of official UNESCO heritage sites or an unbiased explanation and interpretation of a work of art. This paper provides a first attempt to define the main ethical findings on this topic and propose it as an ethical framework to assess different risks arising from the use of AI in the CH domain. The application of this disruptive technology in the arts is evaluated through the lens of ethical principles for trustworthy AI and it explores whether the wider accessibility and improved preservation techniques enabled by AI come at some cost in terms of interpretation, social and cultural inclusion, subjectivism, or other forms of bias. The main ethical principles that emerge from the literature for the application of AI in the cultural domain are the following: Shared Responsibility, Meaningful Participation, Explainability, Accessibility, Sustainability, Reliability and Dignity. The findings underline the importance of establishing specific sectoral ethical guidelines for AI in the field of tangible and intangible CH to support and enhance its sustainable development without compromising its values, significance, sense of belonging and strong social impact.",0.11450381679389313
39,AI Governance and Ethics in Public Procurement: Bridging the Gap Between Theory and Practice,T. Von Behr; P. Abrahamsson,ieee,10.1109/ICE/ITMC-IAMOT55089.2022.10033173,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10033173,"As Artificial Intelligence (AI) systems have become increasingly widespread, research in AI ethics has sparked. When developing the systems, many tools and methods are available for implementing AI ethics in practice. In addition, the research in AI governance is starting to activate, and some models for AI governance have already been introduced. Simultaneously, the role of the information systems (IS) procurement function has developed from its traditional operative role to a more strategic position, as the investments in IT have been on a constant rise. Success in procurement is found to be critical regarding the success of the development and implementation of information systems. But how are the existing tools and methods in AI ethics related to procurement practices? And how is procurement positioned in the proposed AI governance frameworks? This study answers these questions by setting up a research framework based on AI governance models and analyzing existing tools and methods in AI ethics.",0.10967741935483871
40,AI Ethics: A Long History and a Recent Burst of Attention,J. Borenstein; F. S. Grodzinsky; A. Howard; K. W. Miller; M. J. Wolf,ieee,10.1109/MC.2020.3034950,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321834,"Artificial intelligence (AI) ethics has become a hot topic in the popular press and in scholarly writing. In this column, five noted scholars give their opinions on what AI issues will become important in the foreseeable future.",0.10810810810810811
41,Ethical and Sustainability Considerations for Knowledge Graph based Machine Learning,C. F. Draschner; H. Jabeen; J. Lehmann,ieee,10.1109/AIKE55402.2022.00015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9939282,"Artificial Intelligence (AI) and Machine Learning (ML) are becoming common in our daily lives. The AI-driven processes significantly affect us as individuals and as a society, spanning across ethical dimensions like discrimination, misinformation, and fraud. Several of these AI & ML approaches rely on Knowledge Graph (KG) data. Due to the large volume and complexity of today's KG-driven approaches, enormous resources are spent to utilize the complex AI approaches. Efficient usage of the resources like hardware and power consumption is essential for sustainable KG-based ML technologies. This paper introduces the ethical and sustainability considerations, challenges, and optimizations in the context of KG-based ML. We have grouped the ethical and sustainability aspects according to the typical Research & Development (R&D) lifecycle: an initial investigation of the AI approach's responsibility dimensions; technical system setup; central KG data analytics and curating; model selection, training, and evaluation; and final technology deployment. We also describe significant trade-offs and alternative options for dedicated scenarios enriched through existing and reported ethical and sustainability issues in AI-driven approaches and research. These include, e.g., efficient hardware usage guidelines; or the trade-off between transparency and accessibility compared to the risk of manipulability and privacy-related data disclosure. In addition, we propose how biased data and barely explainable AI can result in discriminating ML predictions. This work supports researchers and developers in reflecting, evaluating, and optimizing dedicated KG-based ML approaches in the dimensions of ethics and sustainability.",0.10638297872340426
42,CARE-AI special session on AI ethics,C. Baleshta; D. White; G. Reavie; A. Cooper; G. Taylor; J. A. G. Skorburg; D. V. Bruwaene; S. Gignac; C. Schmidt; L. McDonald; P. Thaine; C. Ryan; R. Luan,ieee,10.1109/ISTAS52410.2021.9629130,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9629130,"Summary form only given. A complete record of the panel discussion was not made available for publication as part of the conference proceedings. This special session organized by the Centre for Advancing Responsible and Ethical Artificial Intelligence (CARE-AI) consists of two 90-minute parts, focusing on two groups at the frontline of AI Ethics: students and start-up founders. Part 1 is a student-led AI Ethics paper presentation and critique: two students from the Philosophy program will present original work, “Analyzing Distrust in Human Interactions with AI,” and “Enactivism and Modelling Human Behaviour in AI,” (20 min); each presentation will be followed by a prepared critique from a student in the Collaborative Specialization in AI (10 min) and a 15-minute general discussion with the audience. Part 2 is an AI Ethics start-up showcase: 5 Canadian start-up companies (whose products or services either present an AI Ethics dilemma or propose a solution) will present 5-minute pitches, which will each be followed by 5 minutes of expert commentary and 5 minutes of open discussion.",0.10588235294117647
43,"Who to Trust, How and Why: Untangling AI Ethics Principles, Trustworthiness and Trust",A. Duenser; D. M. Douglas,ieee,10.1109/MIS.2023.3322586,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10273868,"We present an overview of the literature on trust in AI and AI trustworthiness and argue for the need to distinguish these concepts more clearly and to gather more empirically evidence on what contributes to people’s trusting behaviours. We discuss that trust in AI involves not only reliance on the system itself, but also trust in the developers of the AI system. AI ethics principles such as explainability and transparency are often assumed to promote user trust, but empirical evidence of how such features actually affect how users perceive the system’s trustworthiness is not as abundance or not that clear. AI systems should be recognised as socio-technical systems, where the people involved in designing, developing, deploying, and using the system are as important as the system for determining whether it is trustworthy. Without recognising these nuances, ‘trust in AI’ and 'trustworthy AI’ risk becoming nebulous terms for any desirable feature for AI systems.",0.10457516339869281
44,Exploring ethical decision-making in group settings with real-life case studies,D. A. Martin; G. Bombaerts,ieee,10.1109/ETHICS53270.2021.9632713,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9632713,"Ethical decision-making has been recognised as an important goal of engineering ethics education. This goal has been formulated as enabling students to make decisions based on different ethical theories and frameworks [1], providing conceptual tools for students to recognize and counteract the potential threats of organizational practices [2], or helping students deal with ambiguity in decision-making situations [3]. EDMMs are a commonly taught theoretical base for ethical decision-making. Yet the focus has preponderantly been on students' responses to hypothetical, obvious and brief ethical dilemmas (vignettes), bracketing the group dimension or real features of the context of engineering practice [4]. This approach was shown to lead students to consider solely the perspective of the person making the decision, neglecting the stance of other stakeholders ([5], p.603). At the same time, studies exploring decision-making in STEM education group settings overlooked the ethical dimension of this process [6]. It is thus essential to introduce engineering students to ethical decision-making as situated practice [7], in a manner that can account for the complexities of real-life situations [8]. Our contribution examines students' emerging ethical decision-making process in a group setting when faced with a case (socio-technical problem) given by a stakeholder within their university's ecosystem. It is based on a Challenge-Based Learning course on Ethics and Data Analytics offered by a Dutch technological university in the spring of 2021. The research methods used are student interviews and document analysis of written assignments. The study aims to contribute to a better understanding of (i) how students move through the different steps of the decision-making process of finding an ethical solution to a real-life case, (ii) how they consider different stakeholder perspectives, (iii) the criteria and values guiding their decision-making, and (iv) how having a real case affects their view on the role of ethics in engineering decision-making. Bringing these processes to the forefront can guide engineering instructors in structuring the learning components of their course as to better support students' ethical reasoning. The study thus contributes to the limited body of evidence on how students engage in ethical decision-making in real-life contexts [9] and of the factors considered (Atesh et al., 2017).",0.10393258426966293
45,From value-lists to value-based engineering with IEEE 7000™,S. Spiekermann,ieee,10.1109/ISTAS52410.2021.9629134,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9629134,"Digital ethics is currently being discussed worldwide as a necessity to create more reliable IT systems. This discussion, fueled by the fear of uncontrollable general artificial intelligence (AI) and by ethical dilemmas of existing systems, has moved many institutions and scientists to demand value principles that should guide the development of future IT systems. These usually include the demand for privacy, security, transparency, fairness, etc. This article shows why working through lists of values is insufficient for good or ethically aligned design. It will be shown how a truly ethical ‘Value-based Engineering’ (VbE) would have to look like instead, so that technical product innovation as a whole is put on better (more ethical) feet. VbE is a process-driven, holistic approach to system engineering which initially drew from the ideas of Value Sensitive Design and Ethical Computing. From 2016-2021 VbE was further fleshed out in the IEEE 7000™standardization project *.*This article presents inter alia guidance for ethical engineering given in the forthcoming IEEE 7000− standard. However, this article solely represents the views of the author and does not necessarily represent a position of either the IEEE P7000 Working Group, IEEE or the IEEE Standards Association. The official link to the IEEE P7000 is: https://sagroups.iece.org/7000/.",0.10344827586206896
46,Z-Inspection®: A Process to Assess Trustworthy AI,R. V. Zicari; J. Brodersen; J. Brusseau; B. Düdder; T. Eichhorn; T. Ivanov; G. Kararigas; P. Kringen; M. McCullough; F. Möslein; N. Mushtaq; G. Roig; N. Stürtz; K. Tolle; J. J. Tithi; I. van Halem; M. Westerlund,ieee,10.1109/TTS.2021.3066209,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380498,"The ethical and societal implications of artificial intelligence systems raise concerns. In this article, we outline a novel process based on applied ethics, namely, Z-Inspection®, to assess if an AI system is trustworthy. We use the definition of trustworthy AI given by the high-level European Commission's expert group on AI. Z-Inspection® is a general inspection process that can be applied to a variety of domains where AI systems are used, such as business, healthcare, and public sector, among many others. To the best of our knowledge, Z-Inspection® is the first process to assess trustworthy AI in practice.",0.10309278350515463
47,Doctoral Colloquium-Pandemic Pirouettes: AR Ballet Exploring Data Ethics for the Computing Classroom,G. S. Nunes; A. Shaw,ieee,10.23919/iLRN52045.2021.9459242,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9459242,"This Doctoral Colloquium paper explores the pivot from in-person to virtual and digital means in developing an Augment Reality (AR) classical ballet experiencedue to Covid-19. This work-in-progress explores novel teaching and learning approaches to the computing concepts of data transmission, signal processing, and therefore necessarily data ethics through classical ballet and bio-metric data the body and brain waves as data artefacts, the data ethics implications of biometrics. Innovative approaches to subject knowledge, programming competency, and probing engender thinking of the field of computing if any. This study uses the emergent methodology of AgileDBR, a hybrid of design-based research (DBR) and Agile developed as part of author one's Ph.D.",0.10185185185185185
48,SIAMES: Social Impact Advisor and Measurement System,D. H. Marín; M. Solórzano-García,ieee,10.1109/MTS.2021.3056299,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9379041,"Intelligent technologies offer the potential to generate unprecedented levels of prosperity for all, while posing increasing challenges in the ethical, moral, legal, humanitarian, and sociopolitical spheres. In this regard, the recently released the United Nations (UN) report on extreme poverty and human rights1 warns of the risk of a digital dystopia driving a growing inequality that is facilitating the creation of a vast digital subclass. This report provides many well-documented examples in different countries of how dehumanized smart technologies are creating barriers to accessing a wide range of social rights for those who lack Internet access and digital skills.",0.10101010101010101
49,Recommendations of the Ethical Issues to Accommodate when Digitalizing the Big Data in the Field of Arts & Humanities,N. F. Pirbhai; C. Peoples,ieee,10.1109/ICECCME55909.2022.9988592,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9988592,"The fields of information science and digital humanities are closely linked, with the overlapping of common research themes noted in many research papers. National libraries and archives have been mass collecting and digitizing cultural and scholarly productions for a long time. However, with the data accessibility offered by web and search engines, questions surrounding ethical issues and transparency behind the actual practices of big data/mass digitization, such as collecting and using data, arise. It is important to find out whether, under the General Data Protection Regulation (GDPR) as one example, human rights are being respected. Since digital libraries, as a field of research, are focusing on certain fundamental concerns in the growing cyberculture, this qualitative research through a literature review analyzes the ethical implications of big data and digitalization. In fact, even though mass digitalization is beneficial, there is a need for more control on how data is stored and disseminated. This study will therefore focus on the insights and suggestions of existing authors to understand the different loopholes that must be consideration when embarking in a digitalization project. Google LLC is used as a case study to contextualize the ethical issues. The study revealed that the process of digitalization is complex as there are many unknowns and ethical standards. Furthermore, security issues are not often a priority during the digitalization process. Recommendations of further procedures around the digitalization process will therefore create a more human-centered, ethical, computing environment",0.100418410041841
50,"Enabling scalable AI for Digital Health: interoperability, consent and ethics support",Z. Milosevic,ieee,10.1109/EDOCW52865.2021.00028,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9626264,"This paper proposes an approach for building scalable AI applications in digital health, with a specific focus on addressing interoperability, consent and ethics challenges. These challenges need to be considered in the context of increasingly available tooling for streamlined model development, training, validation, and deployment, while accommodating novel solutions for explainable AI support for clinicians. Such an approach is required because digital health ecosystems involve many data type created by different systems, and often used as part of workflows over different jurisdictional boundaries. Interoperability solutions are needed to support technical and business agreements between parties providing data and services, including knowledge intensive services, such as ML and AI. Computable expression of consent and ethics policies are needed to control how patient information is used, including compliance with regulative rules, possibly from different policy contexts. Our approach, based on the latest interoperability and enterprise policy standards may provide a useful guidance for the practitioners building scalable AI solutions for digital health.",0.1
51,The Role of Analyst Engineer in Algorithm Life and Social Cycle,Y. S. Gosudarkin; K. V. Krinkin; M. V. Takmakov; L. V. Sharakhina,ieee,10.1109/ElConRus51938.2021.9396293,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9396293,"The problems and perspectives of ethics based approach development of AI algorithms are presented in the article. The issue of ethical limitations and responsibilities of AI software developers during the life cycle of algorithms is examined. The analyses of corporate AI ethics guidelines and precedents in their application for analyst engineers' professional activities serve us empirical examples. The authors reveal potential impact of algorithms on different spheres of human lives such as education, medicine, enterprises, etc. in connection to rising control power of employer over the employees. Potential algorithms failures and engineers' illegal labour practices are also considered. Such examples and possibilities of ethical violations need to be accessibly documented and introduced to AI developers departments. The terms of potential engineers and employers interactions are to be set with the option of mutual assessments and tools for algorithm maintenance checkup.",0.1
52,Linking Team-level and Organization-level Governance in Machine Learning Operations through Explainable AI and Responsible AI Connector,E. Neghawi; Z. Wang; J. Huang; Y. Liu,ieee,10.1109/COMPSAC57700.2023.00185,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10197114,"The adoption of AI systems has been widely used across multiple industry domains at an alerting rate without focusing on its ethical concerns. In order to address those concerns, an increasing number of AI ethics frameworks have been suggested recently, which focus on the algorithmic level rather than the systems level. Nonetheless, some system-level approaches mostly cover a single-level governance pattern of the system components in the entire software design life cycle. However, the need to go beyond the single-level system design AI ethics frameworks to allow not only a better responsible-AI-by-design but also a trustworthy process pattern that abstracts and links the underlying layers of responsible AI on every level. This paper illustrates a principal-to-practice guide of the multi-level governance within organizations across the globe for AI ethics frameworks. We outline the main gap areas in organizations for AI ethics frameworks. Consecutively, we propose a multi-level governance pattern for responsible AI systems within organizations which is participatory, iterative, flexible and operable that targets those main gap areas. Finally, to assist practitioners in applying the multi-level governance AI in organizations and its impact on the industry level, we will translate it into effective and responsible AI practices using a case study.",0.09950248756218906
53,Building Trustworthy AI Solutions: A Case for Practical Solutions for Small Businesses,K. Crockett; E. Colyer; L. Gerber; A. Latham,ieee,10.1109/TAI.2021.3137091,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9658213,"Building trustworthy artificial intelligence (AI) solutions, whether in academia or industry, must take into consideration a number of dimensions including legal, social, ethical, public opinion, and environmental aspects. A plethora of guidelines, principles, and toolkits have been published globally, but have seen limited grassroots implementation, especially among small- and medium-sized enterprises (SMEs), mainly due to the lack of knowledge, skills, and resources. In this article, we report on qualitative SME consultations over two events to establish their understanding of both data and AI ethical principles and to identify the key barriers SMEs face in their adoption of ethical AI approaches. We then use independent experts to review and code 77 published toolkits designed to build and support ethical and responsible AI practices, based on 33 evaluation criteria. The toolkits were evaluated considering their scope to address the identified SME barriers to adoption, human-centric AI principles, AI life cycle stages, and key themes around responsible AI and practical usability. Toolkits were ranked on the basis of criteria coverage and expert intercoder agreement. Results show that there is not a one-size-fits-all toolkit that addresses all criteria suitable for SMEs. Our findings show few exemplars of practical application, little guidance on how to use/apply the toolkits, and very low uptake by SMEs. Our analysis provides a mechanism for SMEs to select their own toolkits based on their current capacity, resources, and ethical awareness levels – focusing initially at the conceptualization stage of the AI life cycle and then extending throughout.",0.09716599190283401
54,SimCollege: A Digital Game for Promoting the Ethical Framework of the Edu-Metaverse,Y. Wu; F. Hao; T. Wu,ieee,10.1109/SmartWorld-UIC-ATC-ScalCom-DigitalTwin-PriComp-Metaverse56740.2022.00348,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10189502,"Education is considered one of the metaverse’s main application scenarios. Education based on the metaverse will greatly reduce the cost of education, realize equity of education, and promote the advantages of personalized education. However, with the construction of the Edu-Metaverse, ethical issues emerge one after another. Concerns include that players will gradually have a biased understanding of the social structure and dual roleplaying in interpersonal relationships; indulge in self-intoxication and ignore self-responsibility; and/or be indifferent to life and blindly worship power and money; a separate concern is the inadequate laws and regulations. This article summarizes the commonalities between the Edu-Metaverse and game design ethics, focusing on game ethics. A digital game, “SimCollege”, was designed that promotes the ethical framework of the Edu-Metaverse, and a questionnaire was administered to learn what a group of teachers and students considered the most relevant aspects of maintaining Edu-Metaverse ethics.",0.09655172413793103
55,AI in Healthcare: Opportunities and Challenges for Personalized Medicine and Disease Diagnosis,B. Rawat; Y. Joshi; A. Kumar,ieee,10.1109/ICIRCA57980.2023.10220746,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10220746,"Artificial intelligence (AI) has the potential to revolutionize healthcare by enabling personalized medicine and improving disease diagnosis. This research study explores the latest AI algorithms and applications in healthcare, highlighting their ability to provide faster and more accurate predictions, risk stratification, and improved outcomes through augmented intelligence. However, challenges related to data privacy, ethics, and regulation must be addressed. By leveraging the benefits of AI while addressing these challenges, this study presents an innovative perspective on the transformative potential of AI in healthcare.",0.0963855421686747
56,Implementing AI Ethics in the Design of AI-assisted Rescue Robots,D. Martin; M. W. Schmidt; R. Hillerbrand,ieee,10.1109/ETHICS57328.2023.10155062,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155062,"For implementing ethics in AI technology, there are at least two major ethical challenges. First, there are various competing AI ethics guidelines and consequently there is a need for a systematic overview of the relevant values that should be considered. Second, if the relevant values have been identified, there is a need for an indicator system that helps assessing if certain design features are positively or negatively affecting their implementation. This indicator system will vary with regard to specific forms of AI technology. An adequate indicator system for the ethical development of recommendation algorithms, for example, will diverge considerably from another for autonomous road vehicles, although both are based on shared values. In this contribution, we propose solutions to both challenges with regard to the special case of the development of an AI-assisted rescue robot.",0.0962962962962963
57,Mobile Ethics of the Digital World: Co-evolution and Counter-etiquette,A. N. Gorodishcheva; A. V. Gorodishchev; S. S. Takhan; D. O. Baigozhina; G. P. Kovalev,ieee,10.1109/ComSDS55328.2022.9769142,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9769142,"Researchers in digital ethics argue that precedents of the activity of network users create biases in the behavior of both human and artificial intelligence. The hypothesis of the study states that biases cause violations of the rules of ethics, which provoke incorrect assessments for artificial intelligence statements in social networks, working with headlines and articles in online media, content dangerous for children, etc. The portability of AI ethics rules can improve communication and decision making when evaluating text, ideas, and even technologies, while the electronic document is a ""live"" template and is already there.",0.09574468085106383
58,Spatio-Temporal Graph Analytics on Secondary Affect Data for Improving Trustworthy Emotional AI,M. T. Uddin; L. Yin; S. Canavan,ieee,10.1109/TAFFC.2023.3296695,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10189072,"Ethical affective computing (AC) requires maximizing the benefits to users while minimizing its harm to obtain trust from users. This requires responsible development and deployment to ensure fairness, bias mitigation, privacy preservation, and accountability. To obtain this, we require methodologies that can quantify, visualize, analyze, and mine insights from affect data. Hence, in this paper, we propose a spatio-temporal model for representing secondary affect data from network sciences' perspective. We propose a network science-based model to represent spatio-temporal data, e.g., action units' sequences, and continuous affect reports. In particular, the proposed model captures the spatial and temporal strength of the relationship among essential variables in the data. The proposed model allows to analyze data as a whole system. We also demonstrated the use case of the model for graph analytics on secondary affect data that can assist to measure and quantify several issues that can be originated from the study setup, data recording devices, and the influences/biases that can originate from the perspective of the affect reporters. We also demonstrated the use cases of the proposed method on ethical trustworthy emotional AI via measuring biases from de-identified data and how it contributes towards ethics, transparency, value alignment, and governance.",0.09547738693467336
59,The Ethical Landscape of Data and Artificial Intelligence: Citizen Perspectives,K. Crockett; E. Colyer; A. Latham,ieee,10.1109/SSCI50451.2021.9660153,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9660153,"Globally, there is growing acknowledgement that those involved in the development and deployment of AI products and services should act responsibly and conduct their work within robust ethical frameworks. Many of the ethical guidelines now published highlight a requirement for citizens to have greater voice and involvement in this process and to hold actors to account regarding compliance and the impacts of their AI innovations. For citizens to participate in co-creation activities they need to be representative of the diverse communities of society and have an appropriate level of understanding of basic AI concepts. This paper presents the preliminary results of a longitudinal survey designed to capture citizen perspectives of the ethical landscape of data and AI. Forty participants were asked to participate in a survey and results were analyzed based on gender, age range and educational attainment. Results have shown that participant perception of AI, trust, bias and fairness is different but related to specific AI applications, and the context in which is applied. Citizens also are also very receptive to undertaking free courses/workshops on a wide range of AI concepts, ranging from family workshops to work-based training.",0.09523809523809523
60,"DataVaults: A Secure, Distributed and Privacy Preserving Personal Data Management Platform",W. Meng; W. -Y. Chiu,ieee,10.1109/ICDCS57875.2023.00117,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10272554,"With the rapid development of information technology, the ethical use of data and users' privacy has become a big concern. In European Union, the General Data Protection Regulation (GDPR) has been enforced since 2018, aiming to protect a person's privacy. However, the growth of the data economy might be hindered due to the lack of a trusted, secure and privacy-aware tool. Motivated by this observation, this work presents Data Vaults - a secure, distributed and privacy-preserving personal data management platform. The main goal is to mitigate various privacy concerns through allowing an individual to maintain the ownership, handle and share the data based on their willingness. The platform enables a flexible data sharing method with fair compensation schemes. In particular, with the Data Vaults platform, an individual can protect the sharing of personal data and fairly define how value can be captured, created, released and cashed out for the benefit of all the stakeholders involved (companies or not).",0.0949367088607595
61,Towards a Roadmap on Software Engineering for Responsible AI,Q. Lu; L. Zhu; X. Xu; J. Whittle; Z. Xing,ieee,10.1145/3522664.3528607,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796410,"Although AI is transforming the world, there are serious concerns about its ability to behave and make decisions responsibly. Many ethical regulations, principles, and frameworks for responsible AI have been issued recently. However, they are high level and difficult to put into practice. On the other hand, most AI researchers focus on algorithmic solutions, while the responsible AI challenges actually crosscut the entire engineering lifecycle and components of AI systems. To close the gap in operationalizing responsible AI, this paper aims to develop a roadmap on software engineering for responsible AI. The roadmap focuses on (i) establishing multi-level governance for responsible AI systems, (ii) setting up the development processes incorporating process-oriented practices for responsible AI systems, and (iii) building responsible-AI-by-design into AI systems through system-level architectural style, patterns and techniques. CCS CONCEPTS • Software and its engineering;",0.0948905109489051
62,Perceptions of AI Ethics on Social Media,A. Ocal,ieee,10.1109/ETHICS57328.2023.10155069,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155069,"Since the emergence of Artificial intelligence (AI), despite a common expectation that AI should be ‘ethical’ [1], there are many different interpretations, assumptions, and expectations about what constitutes ""ethical AI"" and which ethical problems and requirements are pointed out by the public. Even though many private companies and research institutions have highlighted present and possible future problems, needs, and guidelines associated with AI ethics, relevant public visions regarding how ""ethical AI"" can be constituted [1] have not been explored sufficiently. For obtaining public opinions, although questionnaires and interviews are commonly used, the questions in these methods are designed based on only the researchers' preferences, and this could be a limitation. Social media data, however, are produced by users freely [2], and many people share their ideas in social media discussions [3]. Social media data usage, therefore, has been growing in various research studies. Researchers intending to utilize social media as a data source predominantly harness Twitter data, yet in recent years Reddit has also gained the attention of scholars with the same research purpose, as in [2], [3]. Reddit is a huge social media platform involving over 50 million daily active users with diverse mentalities shaped by different backgrounds, prior beliefs, personal experiences, and personalities, from various geographical locations, and 100 thousand active communities, thereby it brings different segments of the public together. Moreover, users benefit from a level of anonymity on Reddit not typically accomplished on other social media platforms [4], thereby users may feel more secure and share more honest thoughts on a topic, thus the Reddit data have been used to gather public opinions in prior research as in [3]. Through the lens of technological frames [5], to explore social media users' interpretations, assumptions, and expectations about how ethical AI is built, and which problems hinder building ethical AI, Reddit conversations were analyzed. More specifically, a corpus consisting of 998 unique Reddit post titles and their corresponding 16611 comments extracted from 15 AI-related subreddits were identified by using topic modelling supported by human judgment for frame identification as in [6] based on BERTopic [7]. The findings show that perceptions about AI ethics are clustered around several themes (AI's gender bias; humans' gender bias about perceived gender of bots; regulation and patent laws related to AI use; AI spreading disinformation; AI making fake faces, videos, music; misuse of personal data; and AI impact on crime), with deviations about how these themes are interpreted, what problems or actors they pertain to, and what appropriate measures should be taken to address problems pointed out by the public. While some of these ethical issues were also highlighted in prominent AI ethics literature as in [8], the findings of this study indicated new insights such as humans' gender bias about the perceived gender of bots. The findings offer important implications. First, as a practical implication, the findings can enrich current public voice-centric explorations of AI ethics. Also, they could help designing suitable interfaces that allow proper human-AI task coordination and collaboration and deploying innovative solutions for existing or anticipated ethical problems. Second, expected outcomes can demonstrate areas where misconceptions and unrealistic visions about AI ethics are widespread, which may trigger speculative fears or concerns. Researchers may be encouraged to more focus on the areas where public misconceptions are more common; educational programs may be arranged to reduce speculative fears or concerns or take necessary measures for real ethical risks. Academia, industry and government communities may collaborate for research and policy arrangements in those areas. Third, through employing computeraided textual analysis, this study reveals frames in social media conversations to showcase the latest perceptions from different viewpoints. This method may be an example method for relevant future research.",0.0943089430894309
63,Comparisons of Different Clustering Algorithms for Privacy of Online Social Media Network,R. Gangarde; A. Pawar; A. Sharma,ieee,10.1109/PuneCon52575.2021.9686522,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9686522,"Online Social Networks (OSN) connect billions of users with direct consequences to offline activities. As of late, OSNs have seen critical development and accepted much consideration in exploration. These Networks have consistently been a significant part of daily life; however, since an ever-increasing number of individuals are associated with the internet, their online partners satisfy an undeniably significant job. Users use online applications where they end up sharing lots of information including personal data. Hence this data including huge information is money-making for data owners and they share data with third parties like advertisers who are ethical users. This data also consists of personal data. As data can be used for unethical purposes by unauthorized users which leads to different attacks and illegal use of data and personal information. It is fundamental to first anonymize users’ data before imparting it to any of the third parties like advisers. Anonymization preserves data privacy. However, anonymization prompts data loss, which by implication influences the data utility. Balancing data privacy and utility of information is an open research issue. Different clustering algorithms can be applied for anonymizing social network data. Comparison of clustering algorithms leads to the best algorithm to provide k-anonymity to social media networks.",0.09359605911330049
64,PRIVEE: A Visual Analytic Workflow for Proactive Privacy Risk Inspection of Open Data,K. Bhattacharjee; A. Islam; J. Vaidya; A. Dasgupta,ieee,10.1109/VizSec56996.2022.9941431,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9941431,"Open data sets that contain personal information are susceptible to adversarial attacks even when anonymized. By performing low-cost joins on multiple datasets with shared attributes, malicious users of open data portals might get access to information that violates individuals’ privacy. However, open data sets are primarily published using a release-and-forget model, whereby data owners and custodians have little to no cognizance of these privacy risks. We address this critical gap by developing a visual analytic solution that enables data defenders to gain awareness about the disclosure risks in local, joinable data neighborhoods. The solution is derived through a design study with data privacy researchers, where we initially play the role of a red team and engage in an ethical data hacking exercise based on privacy attack scenarios. We use this problem and domain characterization to develop a set of visual analytic interventions as a defense mechanism and realize them in PRIVEE, a visual risk inspection workflow that acts as a proactive monitor for data defenders. PRIVEE uses a combination of risk scores and associated interactive visualizations to let data defenders explore vulnerable joins and interpret risks at multiple levels of data granularity. We demonstrate how PRIVEE can help emulate the attack strategies and diagnose disclosure risks through two case studies with data privacy experts.",0.09345794392523364
65,Data Protection: Trust to Government and Willingness to Provide Information,E. S. Kassim; M. S. Shazwan Bin Abdul Halim; S. Kamal; M. K. Hayat Mohd Banuri,ieee,10.1109/ICONDA56696.2022.10000336,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10000336,"The COVID-19 pandemic has seen many countries took their best measures to prevent the spread of the virus. Hence, the use of contact tracing apps to track infection and help to diagnose symptoms has become common. However, digital innovation for public health management has posed some challenges to the government and the society. There are trade-offs between the benefits of health protection and the risks of loss of data privacy. Therefore, the study aims to examine what data protection factors will predict users' trust to the government, and whether the trust will impact on how the users provide data to COVID-19 contact tracing apps. A self-administered survey was conducted, and 497 data was obtained. Analysis on structural equation modeling was done by using SmartPLS. The findings show trust to government is determined by perception of the users on ethics of data collection, regulation by the government, data protection policy, and information disclosure prevalence. Trust affects willingness to provide information in a different manner. The willingness to provide information is determined by cognitive trust. But affective trust increases people's willingness for falsification. The research contributes to data privacy field by demonstrating how different forms of trust to government during the pandemic influence cooperative behavior, and the identification of clear distinction of trust antecedents, which will be useful for the redesign of government relationship with the people.",0.09333333333333334
66,Building Trust – The People’s Panel for AI,K. Crockett; A. Latham; M. Wood; L. Abberley; M. Rawsthorne; S. Attwood,ieee,10.1109/CAI54212.2023.00080,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10195009,"This paper describes The People’s Panel for AI – a mechanism to build public trust in AI products and services from conceptualization to deployment. To increase public awareness of how AI and data-driven systems are affecting the lives of ordinary people, a series of Artificial Intelligence Roadshows were delivered in community centers. Community members were recruited to the People’s Panel and completed two days of training about key aspects of data, AI and ethics, including learning a technique for exploring ethical aspects of new technologies (consequence scanning). As part of a pilot study, four People’s Panel sessions were held where tech businesses and researchers pitched their ideas and discussed questions and concerns of the panel members. Through participating in the panel, panel members reported an increase in confidence in being able to question businesses and businesses heard a diverse stakeholder voice on the ethical impacts of their products / services, leading to change.",0.0915032679738562
67,“How technical do you get? I’m an English teacher”: Teaching and Learning Cybersecurity and AI Ethics in High School,Z. Kilhoffer; Z. Zhou; F. Wang; F. Tamton; Y. Huang; P. Kim; T. Yeh; Y. Wang,ieee,10.1109/SP46215.2023.10179333,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10179333,"Today’s cybersecurity and AI technologies are often fraught with ethical challenges. One promising direction is to teach cybersecurity and AI ethics to today’s youth. However, we know little about how these subjects are taught before college. Drawing from interviews of US high school teachers (n=16) and students (n=11), we find that cybersecurity and AI ethics are often taught in non-technical classes such as social studies and language arts. We also identify relevant topics, of which epistemic norms, privacy, and digital citizenship appeared most often. While teachers leverage traditional and novel teaching strategies including discussions (treating current events as case studies), gamified activities, and content creation, many challenges remain. For example, teachers hesitate to discuss current events out of concern for appearing partisan and angering parents; cyber hygiene instruction appears very ineffective at educating youth and promoting safer online behavior; and generational differences make it difficult for teachers to connect with students. Based on the study results, we offer practical suggestions for educators, school administrators, and cybersecurity practitioners to improve youth education on cybersecurity and AI ethics.",0.09090909090909091
68,Colonization by Algorithms in the Fourth Industrial Revolution,W. Lambrechts; S. Sinha; S. Mosoetsa,ieee,10.1109/ACCESS.2022.3145236,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9690490,"Data gathering and information processing have evolved to where it is almost unfathomable how much exists in digital form today. The generation thereof also no longer involves an explicit instruction from human to machine but can happen in real-time without human intervention. Artificial intelligence, machine learning, and cognitive computing are being utilized to mine data from a variety of sources. One such (profitable) source is human beings. Digital algorithms are designed to harness the power of technology to gather information. There has always been a sense of secrecy regarding some information (classified, top secret, confidential, etc.) but the Fourth Industrial Revolution has created the means to gather extremely large amounts of data, unknown to its sources. Anthropological value systems should become a fundamental foundation of digital algorithms. Such an approach could prevent software from exploiting its sources, especially minorities. Value systems together with ethics are guided by people’s culture. In ethically aligned algorithm design, value systems and digital technologies intersect and govern how algorithms are developed, the way data is engaged, and further the discipline of digital humanities.",0.0898876404494382
69,The Value of Deeds in a Digital Society,A. N. Gorodishcheva; A. V. Gorodishchev; S. V. Uskova; D. O. Baigozhina; G. P. Kovalev,ieee,10.1109/ComSDS55328.2022.9769093,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9769093,"The act as a way of mastering the reality given to a person goes beyond stereotypical actions and is not recognized by modern AI as a necessary condition for human development. The act is connected by semantic fields with the world where it takes place and the dynamics of the multi-level components of natural language do not always correspond to the dynamics of the digital situation. Thus, they stimulate a person to commit acts to determine the boundaries of acceptability, ethics, and the norms of the digital space. AI acts as a representative of that other world, which is also not mirrored but is a reflection of a person in the digital space.",0.08849557522123894
70,A Practical Study on the Integration of College Students' Professional Ethics Education into College English Teaching Based on Data Analysis,Y. Zhang,ieee,10.1109/ICEKIM55072.2022.00023,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10027315,"As a code of conduct for employees, professional ethics standards have always been the concern of the contemporary vocational education. This paper studies the integration between college students' professional ethics education and English teaching implementation. According to the employment requirements survey, the basic professional ethics and core professional quality in different majors were confirmed. Based on the comparative experiment and the data analysis, the teaching implementation plan was formulated. In the practice of college English education, the teaching design of the integration of professional ethics education and course teaching was carried out on the principle of SMART. The effectiveness of this teaching strategy has been proved in teaching practice shown on the research data.",0.08771929824561403
71,When AI Facilitates Trust Violation: An Ethical Report on Deep Model Inversion Privacy Attack,M. Khosravy; K. Nakamura; A. Pasquali; O. Witkowski; N. Nitta; N. Babaguchi,ieee,10.1109/CSCI58124.2022.00166,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10216545,"This article raises concerns about the considerable capability of artificial intelligence in boosting privacy violations and motivates the necessity of AI ethics. Despite all AI advantages like the efficiency and accuracy of recent techniques, and its positive effects on our life quality, when it comes to security and privacy the facilities with AI empowerment have been met with anxiousness and distrust in the public. This article is an ethical view of the AI role in a recent work wherein AI considerably facilitates privacy violation in a gray-box attack on a deep face recognition system. While the user identities' data is fully secured and just the recognition deep model is accessible, AI-boosted model inversion reveals the faces of the identities via high-accuracy generated clones. An analytical and subjective evaluation of the generated face clones with and without AI integration in model inversion illustrates a big gap from non-clear noise face clones to crystal clear face clones which efficiently reveal the identity of a targeted user by their high-level naturalness, similarity, and recognizability amongst many users.",0.08620689655172414
72,Pragmatic Online Privacy: the SftE Approach,V. Jesus,ieee,10.1109/EuroSPW54576.2021.00035,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9583726,"This position paper presents and proposes new requirements for Privacy and Data Protection. We first raise misalignments of current Privacy regulations and argue that current regulatory approaches do not benefit individuals as much as expected to the point that it primarily shields large organisations from ethical management of personal data. From this assessment, we propose the Start-from-the-End (SftE, pronounced “soft”) approach to online Privacy. It puts the focus on the later stages of the lifecycle of Personal Data (such as the Right to Erasure), while removing focus from the points of collection of personal data. The ultimate goal is to reclaim straightforward enforcement and re-empower individuals in a way that is meant to be feasible and practical.",0.08547008547008547
73,"Standards, Ethics, Legal Implications & Challenges of Artificial Intelligence",S. Chauhan; A. Keprate,ieee,10.1109/IEEM55944.2022.9989614,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9989614,"We are moving towards an era of automation and technological revolution with Artificial Intelligence (AI) at its core. There is no doubt that AI has created commercial value across various industries such as e-commerce, security, engineering, etc. Thus, the paradigm of AI is understood as something that is making our lives easier, but is it as simple as it looks? This paper looks at some challenges and risks of AI through the lens of ethics and law. The risks are multifaceted and bring about chaos in society if no strict measures are taken. By looking at various ethical and legal concerns we will look at the current ongoing legislation at the European Parliament regarding law and AI.",0.08547008547008547
74,Leveraging Data Science to Advance the United Nations Sustainable Development Goals,A. Pradeep; Z. Muytenbaeva,ieee,10.1109/IMTIC58887.2023.10178477,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10178477,"This paper explores the potential of leveraging data science to advance the United Nations Sustainable Development Goals (SDGs). Data science is a multidisciplinary field that uses statistical and computational methods to extract insights and knowledge from data. The SDGs are 17 interrelated goals designed to promote sustainable development and eradicate poverty. The paper discusses how data science techniques can be applied to each of the 17 SDGs and also mentions the role of AI in achieving the SDGs. While data science presents a tremendous opportunity to advance the SDGs, it poses challenges like data privacy or quality. The paper reviews several examples of how data science has been used to address specific SDGs, such as ending hunger, promoting health and well-being, and reducing inequalities. The paper also discusses some of the challenges and opportunities for leveraging data science in the context of the SDGs, including issues related to data quality, privacy, and equity. Overall, the paper argues that data science has the potential to be a powerful tool for advancing the SDGs, but that careful attention must be paid to the ethical and social implications of data-driven approaches.",0.0851063829787234
75,Data Science as Political Action: Grounding Data Science in a Politics of Justice,B. Green,ieee,10.23919/JSC.2021.0029,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684742,"In response to public scrutiny of data-driven algorithms, the field of data science has adopted ethics training and principles. Although ethics can help data scientists reflect on certain normative aspects of their work, such efforts are ill-equipped to generate a data science that avoids social harms and promotes social justice. In this article, I argue that data science must embrace a political orientation. Data scientists must recognize themselves as political actors engaged in normative constructions of society and evaluate their work according to its downstream impacts on people's lives. I first articulate why data scientists must recognize themselves as political actors. In this section, I respond to three arguments that data scientists commonly invoke when challenged to take political positions regarding their work. In confronting these arguments, I describe why attempting to remain apolitical is itself a political stance—a fundamentally conservative one—and why data science's attempts to promote “social good” dangerously rely on unarticulated and incrementalist political assumptions. I then propose a framework for how data science can evolve toward a deliberative and rigorous politics of social justice. I conceptualize the process of developing a politically engaged data science as a sequence of four stages. Pursuing these new approaches will empower data scientists with new methods for thoughtfully and rigorously contributing to social justice.",0.08411214953271028
76,Artificial Intelligence Trends and Future Scenarios: Relations Between Statistics and Opinions,G. Velarde,ieee,10.1109/CogMI52975.2021.00017,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9750280,"Artificial Intelligence (AI) is a trend in innovation and research expected to significantly impact society and firms. However, there are various opinions about its possible effects. This study compares the World Intellectual Property Organization (WIPO) statistics with opinions from 21 AI researchers, self-identified as professors and postdocs. Within AI-based innovations, WIPO data shows that Deep Learning is the technique with the largest average growth rate in recent years. Similarly, AI researchers consider that Deep Learning is a strong trend in AI. The survey also revealed that perceived AI research trends are somewhat different from ideal AI research trends. Ideal trends include AI fundamental research, ethics, data usage, human-machine interaction, learning, and good practices. In addition, 181 self-identified professionals, professors, postdocs, and doctoral students, among others involved in AI communities, shared their opinion on the impact of AI and the possible future scenarios. Most respondents identified pragmatics (57%), while very few were pessimists (4%), among other options.",0.08333333333333333
77,"Technology, equity and social justice roundtable",A. Ansari; A. L. Hoffmann; S. Gürses; M. Sloane; M. A. Vasquez; Z. Pearl,ieee,10.1109/ISTAS52410.2021.9629208,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9629208,"Only a summary overview is provided. This roundtable discussion, sponsored by a SSHRC Connection Grant, brings together four international faculty members from a range of academic and industry backgrounds in engineering and social sciences to discuss how they engage with equity and social justice issues in their work, focusing specifically on methodology and how students and young professionals can approach these issues. Ansari will describe his current efforts to decolonize design research in the university community, in particular through the _Decolonising Design_ platform. Gürses will discuss her ongoing work in the field of Privacy Engineering, which focuses on designing, implementing, adapting, and evaluating theories, methods, techniques, and tools to systematically capture and address privacy issues in the development of sociotechnical systems. Hoffman will focus on a novel and timely intervention into Data Ethics: Feminist Data Ethics, which engages with the ethical implications of data’s production, circulation, application, and storage. Sloane will highlight the critical importance of responsible AI design and governance, interdisciplinary opportunities for researchers to develop and implement tools to engage with responsible innovation, innovation in AI procurement, and AI auditing.",0.08241758241758242
78,Statistical Methods for ICT Ethics Studies,M. M. Razak; M. F. Othman; R. M. Kutty; N. N. N. Mohamed; N. A. Rahim,ieee,10.1109/ICORIS52787.2021.9649488,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9649488,"Statistical methods are essential for qualitative, quantitative, and mixed-method research methodology. Mostly, statistical methods involve mathematical formulas, models, and techniques used in analyzing data. Each method and statistical analysis used brings different results to a study. Therefore, this study aims to explore the use of statistical methods in the ICT ethics area. This study reviews the research done on ICT ethics for the years 2015 until 2020. The research questions addressed in this study are: (i) What statistical methods were used in the ICT ethics research? and (ii) What application area in ICT ethics employ the statistical methods? The findings indicated that the inferential statistical method was most employed, followed by the descriptive statistical method and other methods. Also, non-parametric was the most technique used compared to parametric. Meanwhile, the application area in ICT ethics that employ statistical methods is privacy, piracy, access right, cybercrime, harmful action, social impact, and other related ethics issues such as hacking, internet addiction, free speech, and cyberloafing. The implication of the study is described.",0.08235294117647059
79,Embedding Ethics and Trustworthiness for Sustainable AI in Earth Sciences: Where Do We Begin?,P. Dias; D. Lunga,ieee,10.1109/IGARSS46834.2022.9883030,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883030,"As in many other research domains, Artificial Intelligence (AI) techniques have been increasing their footprint in Earth Sciences to extract meaningful information from the large amount of high-detailed data available from multiple sensor modalities. While on the one hand the existing success cases endorse the great potential of AI to help address open challenges in ES, on the other hand on-going discussions and established lessons from studies on the sustainability, ethics and trustworthiness of AI must be taken into consideration if the community is to ensure that its research efforts move into directions that effectively benefit the society and the environment. In this paper, we discuss insights gathered from a brief literature review on the subtopics of AI Ethics, Sustainable AI, AI Trustworthiness and AI for Earth Sciences in an attempt to identify some of the promising directions and key needs to successfully bring these concepts together.",0.08163265306122448
80,Review on the ethical and legal challenges with IoT,B. Siddiqua Oosman; R. Dudhe,ieee,10.1109/ICCIKE51210.2021.9410714,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9410714,"IoT technology is vast field. It comprises of smart devices and applications connected to each other using internet. These devices like sensors, wearable health monitors, smart security systems etc, are continuously collecting data and monitoring people around it. All this data collected by the smart devices results in Big Data. When it comes to handling big data, safeguarding this sensitive data from hackers and cyber bullies is a difficult task. Apart from this, Big Data collection also gives rise to some serious ethical and legal issues. While in most countries there are now laws to deal with these issues, it is still a complicated task to tackle these cyber activities as they are not governed geographically. In the paper below we discuss the different technologies we can utilize, and the various cyber laws introduced to prevent the ethical and legal problems occurring due to the use of these IoT devices.",0.08
81,"Developing conceptual and methodological foundations for a cross-cultural, multi-institutional study of ethical reasoning and moral dispositions of engineering students",A. R. Gammon; Q. Zhu; S. Streiner; R. Clancy; R. Thorpe,ieee,10.1109/FIE56618.2022.9962559,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9962559,"This full research paper develops a framework for using comparative case studies to triangulate with quantitative survey data in engineering ethics education research.Ethics has long been recognized as crucial to responsible engineering, but the increasingly globalized environments of contemporary engineering present challenges to effective engineering ethics training. An overarching goal of our team’s larger project is to examine the effects of culture and education on ethics training in undergraduate engineering students at universities in the United States, China, and the Netherlands to assess how this training impacts students’ ethical reasoning and moral dispositions, and how this differs cross-culturally. To gauge students’ moral dispositions and ethical reasoning skills and to measure any change in these, we administer the Moral Foundations Questionnaire and the Engineering & Science Issues Test to engineering students longitudinally over four years. Because the conditions related to engineering ethics education differ widely per participating institution, interpreting and analyzing survey quantitative data will require understanding the contextual conditions of education at each institution. In this paper we ask the question what and how can case study methods contribute to longitudinal and cross-cultural ethics educational research with large data sets? To answer it, we develop conceptual and methodological foundations for the design of comparative, multi-institutional case studies to contextualize, complement, and interpret quantitative and qualitative data on ethical reasoning and moral dispositions. We develop comparative case studies to supply missing contextual information for triangulation with quantitative and qualitative data and to provide a more complete picture of the engineering ethics educational contexts, strategies, and practices at each of the participating universities. In this project, case studies provide informational and contextual significance to the other sources of data our research produces, elucidating conditions required to understand and make sense of the results of the research. In the paper we introduce our research project, motivate the use of case studies in our research by reviewing literature on case studies and multi-method triangulation in educational research. We explain how specific cases will be designed, and by providing the first step of two cases, timelines of ethics interventions for two degree programs, demonstrate the informational and interpretive need for comparative case studies in triangulating with other data sources. By using multiple case design to compare universities’ approaches in this frame, our analysis can respond to particular institutional educational contexts and cultural and language factors, make cross-cultural comparisons, and offer recommendations about responsible and culturally responsive engineering ethics education.",0.07920792079207921
82,Building Toward More Just Data Practices,C. C. Gouge; E. B. Carlson,ieee,10.1109/TPC.2021.3137675,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9695260,"Introduction: This tutorial offers technical and professional communication (TPC) professionals a heuristic designed to support more just data practices. Key concepts: Understanding how data contribute to discussions of public problems matters, especially in times of crisis during which multiply marginalized communities are disproportionately affected. Critical Data Studies clarifies how data practice and priorities emerging from various domains of power exacerbate structural inequalities. If we recognize, reveal, and reject data practices that cast data as if they were neutral or fixed, we can ensure that our data practices as TPC professionals are more just. Key lessons: 1. Recognize that data are socially constructed and often incomplete. 2. Reveal the overarching social, political, cultural, and economic conditions that shape data collection and by extension, data itself. 3. Reject faulty or biased processes for data interpretation and analysis that perpetuate inequality. Implications for practice: By acknowledging the relationship between data and context, we can promote better, more just data practices, preparing TPC professionals to work alongside community stakeholders in intersectional coalitions and challenging the conditions that lead to unjust data that fail to represent, over-represent, or blatantly misrepresent the realities of vulnerable communities.",0.07894736842105263
83,AI Regulation in Healthcare: New Paradigms for A Legally Binding Treaty Under the World Health Organization,R. Bouderhem,ieee,10.1109/CICN56167.2022.10008303,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10008303,"Our use and dependency to information and communication technology (ICT) creates undoubtedly new opportunities but also new risks. To ensure that ICT helps to promote healthcare and medicine worldwide, we necessarily need to address issues related to the implementation of Artificial Intelligence (AI) in healthcare. Human rights such as data privacy; ethics in the use of data; the digital gap or bias in AI are new challenges to tackle. According to the World Health Organization (WHO), AI promises to facilitate access to healthcare and medicine worldwide. Our postulation is that the current legal framework cannot regulate adequately the use of AI in healthcare. International cooperation is a prerequisite to ensure that all new risks and challenges associated with the use of AI in healthcare are tackled. A revision of the WHO International Health Regulations (IHR) is necessary as well as new coercive powers for the WHO to enable effective global public health policies.",0.0784313725490196
84,Artificial Intelligence Involvement in Graphic Game Development,S. Antony; S. T; R. I. Joshua; N. Jayapandian,ieee,10.1109/ICAISS58487.2023.10250553,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10250553,"Games have always been a popular form of entertainment and with the advancements in technology, the integration of Artificial Intelligence (AI) in gaming has revolutionized the gaming industry. This research article aims to explore the various applications of AI in gaming and its impact on the industry and player experience. Unlike the typical straightforward nature of AI, this research paper takes a more human approach to discussing the topic. It delves into the evolution of AI in games and the various types of AI used in game development. These include rule-based AI, learning- based AI, and evolutionary AI, which have all contributed to the development of increasingly immersive gaming experiences. The benefits and challenges of using AI in games are also explored, considering the impact on player experience. While AI-powered opponents can provide a greater challenge, balancing the difficulty level is critical to ensuring the game remains enjoyable. The potential ethical concerns of using AI in games are also discussed, such as data privacy, bias, and fairness. Furthermore, this research paper looks into the future of AI in games and how it may shape the gaming industry and player experience in the years to come. With the continued development of AI techniques such as reinforcement learning and GANs, the possibilities for more immersive and engaging gaming experiences are endless.",0.0776255707762557
85,Towards an AI-centric Requirements Engineering Framework for Trustworthy AI,K. Ronanki,ieee,10.1109/ICSE-Companion58688.2023.00075,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172807,"Ethical guidelines are an asset for artificial intel-ligence(AI) development and conforming to them will soon be a procedural requirement once the EU AI Act gets ratified in the European parliament. However, developers often lack explicit knowledge on how to apply these guidelines during the system development process. A literature review of different ethical guidelines from various countries and organizations has revealed inconsistencies in the principles presented and the terminology used to describe such principles. This research begins by identifying the limitations of existing ethical AI development frameworks in performing requirements engineering(RE) processes during the development of trustworthy AI. Recommendations to address those limitations will be proposed to make the frameworks more applicable in the RE process to foster the development of trustworthy AI. This could lead to wider adoption, greater productivity of the AI systems, and reduced workload on humans for non-cognitive tasks. Considering the impact of some of the newer foundation models like GitHub Copilot and ChatGPT, the vision for this research project is to work towards the development of holistic operationalisable RE guidelines for the development and implementation of trustworthy AI not only on a product level but also on process level.",0.07731958762886598
86,Doctoral Colloquium—ME++ Data Ethics of Biometrics Through Ballet and AR,G. Smith-Nunes; A. Shaw,ieee,10.23919/iLRN55037.2022.9815898,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815898,This Doctoral Colloquium explores data ethics and biometric data through the development of an augmented reality (AR) classical ballet experience. This paper focuses on two areas: (i) The development and use of tool sets for motion capture and video extraction. (ii) On dancers’ understanding and experiences of the ‘body as a data artefact’ for the creation of motion graphic (3D rigged) characters of an AR experience. Questions: (1) Is there a difference in sense of self (identity) between the human and the virtual? (2) How does sharing your personal biometric data make you feel? (3) How can biometric and immersive development tools be used in the computing classroom and dance studios to raise awareness of data ethics?,0.07692307692307693
87,Security for Internet-of-Things Enabled E-Health using Blockchain and Artificial Intelligence: A Novel Integration Framework,B. Ikharo; A. Obiagwu; C. Obasi; S. U. Hussein; P. Akah,ieee,10.1109/ICMEAS52683.2021.9692368,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9692368,"This paper upon setting the background of ethical issues with electronic data in healthcare, discusses enabling technologies that ensure secured network in digital health. It reviews the unique features of e-health using Artificial Intelligence (AI), Internet-of-Things (IoT) and Blockchain (BC). The paper elaborates on areas in which one technology complements another by the integration of all three health technologies for smarter and secured application. As a result, we propose a novel framework for the actualization of the anticipated security of e-health data in AI, IoT and BC ecosystem and we conclude by positing that the integrated technology's security interface will be a robust and secured e-health services configuration that will lessen the security setbacks in the independent ones.",0.07627118644067797
88,ETHICS-2023 Session D1 - Open Forum: Building a Technology Ethics Community,T. Creely; M. Cheong; H. Love; K. Schmitt,ieee,10.1109/ETHICS57328.2023.10154968,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10154968,"This session was an open forum where audience members were invited to participate in discussions of a number of themes with relevance to ethics and technology and to future conferences in the IEEE ETHICS series. The discussions took place in small groups, with groups reporting back to the full cohort for collaborative brainstorming.",0.07547169811320754
89,Digital Technology Meets Ethics: How to Think About the Global Good When You are Changing the World,A. Renda,ieee,10.1109/Transducers50396.2021.9495741,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9495741,"Innovation and digital technology are changing the world every day, bit by bit. Innovations in domains like the Internet of Things and Artificial intelligence are our best bet for sustainability and prosperity, and our reliance on them (especially after the pandemic) cannot be overstated. At the same time, these technologies must be handled with care, since they can lead to concerns and risks related to discrimination, excess energy consumption, problems with safety and security. This talk shows how governments around the world are trying to embed sustainability and ethical alignment in the policy framework for digital technologies: an endeavour that critically requires dialogue with the innovation community.",0.07476635514018691
90,Challenges facing AI and Big data for Resource-poor Healthcare System,A. Kaur; R. Garg; P. Gupta,ieee,10.1109/ICESC51422.2021.9532955,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9532955,"During the last decade, major advancements in the health-care system have developed by offering numerous benefits to the patients throughout the world but resource-poor countries are not benefited through the best practices of health-care due to the lack of educated health-care providers, infrastructure, financial and technical issues, etc. Health-care systems in resource-poor countries face many challenges including increased healthcare cost, patient safety, overtreatment and failure to adopt best practices for health-care. In such countries, massive data generate from various resources including medical imaging, patient record, pharmaceutical reports, and medical devices. The exponential growth in medical data and advancement in health-care technologies focus data analysts to come up with innovative solutions for improving health-care practices in poor countries. Big data analytics provide tools to collect manage and analyze structured and unstructured medical data to find useful insights. Complexity and volume of medical data also show that, Artificial intelligence (AI) has the ability to approximate conclusions without direct human input, which can be applied in the health-care system of resource-poor countries and is now being utilized to further develop health services in high-income countries. Numerous investigations show that, AI performs better than humans in certain health-care undertakings such as diagnosis of cancer, tumor, heart diseases, radiology, etc. Popular AI techniques include machine learning methods such as neural network, support vector machine, and deep learning for structured data as well as natural language processing for unstructured data. There is a variety of hurdles around the use of big data and AI in health-care includes regulation, permission, transparency, and accountability. Also, the collection of data from an individual-a prerequisite for big data analytics is a technical and ethical issue. There are a lot of challenges for AI and big data in health-care but efforts need to be made before these techniques can be deployed in ethical and safe way. In this chapter, we discuss the challenges that AI and big data techniques face in resource-poor health care system and how it can be used to improve health outcomes in resource-poor countries.",0.07418397626112759
91,Towards User Online Security and Privacy Protection,J. Silaa; M. Morolog; A. Gamundani; F. Bhunu-Shava,ieee,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9577017,"ICT end-users are trapped in the dilemma of online freebies as some online services run background data mining algorithms to harvest usage patterns, behaviours, and other relevant personal attributes. Such end-user digital footprints are fertile grounds for security and privacy attacks. Therefore, trade-offs between user privacy and data security are hard to dissect. In this paper, we revisit these issues as revealed by the workshop conducted at the Namibia Internet Governance Forum (NamIGF) in 2019. The workshop hinted at the need for supportive legislative frameworks for the ethical adoption of recent technologies towards addressing dynamic challenges on security and privacy attacks. Participants’ perceptions, experiences and practices signalled the role of end users in shaping a national cyber security culture and policy development. Finally, a supportive legislative framework that could adopt the Quadruple Helix model to address these socio-technical issues pertaining to online user security and privacy challenges is recommended.",0.0738255033557047
92,Clustering Approach to Anonymize Online Social Network Data,R. Gangarde; A. Sharma; A. Pawar,ieee,10.1109/ICSCDS53736.2022.9760742,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9760742,"OSNs (Online Social Networks) link billions of people to offline activities. OSNs have recently undergone significant development with increasing users every day. These networks are now an essential partner for individuals, but their online companions now play an unquestionably important role with expanding internet users. Users connect with other users who have overlapping personal trajectories after establishing confidence. OSN and other comparable programs extract massive amounts of data from individuals. As a result, data owners profit from this data, including personal information, sharing it with ethical third parties such as marketers. Unauthorized users can utilize data for unethical goals, resulting in various attacks and illicit uses of data. In this case, it is necessary to anonymize users' data before sharing it with others. Clustering users and anonymizing data set in a way that will not isolate individuals from the group. By failing to form tighter and k-anonymized clusters, one can track a person and perform illegal activities such as theft, robbery, and persona profiling. Anonymization protects personal information from prying eyes. However, data loss occurs as privacy increases, decreasing data utility. Hence, balancing privacy and utility is an open research issue.",0.07329842931937172
93,Privacy Computing Issues in Collecting and Using Customer Data of Mobile Devices,D. Q. Ren; H. Liu,ieee,10.1109/ICSIP55141.2022.9886951,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9886951,"Merchants through smartphones and mobile applications measure and analyze users’ interests and behaviors, and identify users in applications and browsers to push services, updates, and advertisements to the users. This way of providing personalized services to smartphone users to attract potential customers has improved the user experience, created new opportunities for advertising, and changed the marketing trend of enterprises. However, the collection, processing, and analysis of user personal data has brought serious privacy issues to individuals and organizations. This paper introduces privacy risks, including user information collection and analysis of information flow between networks, analysis procedures and standards. Discussed the challenges of protecting user privacy, including privacy threats brought by user information and analysis, extraction, and exchange of private information between various advertising entities, privacy threats tracked by third parties, privacy information and related privacy issues. Next, based on these technologies, related underlying architecture, privacy mechanisms, and deployment scenarios, several technologies, and various suggestions for protecting user privacy are analyzed. Finally, the respect for people, regulations and laws, the limitations of technical solutions, ethical principles and moral dilemmas were discussed.",0.07222222222222222
94,Being Proactive for Responsible AI: Analyzing Multiple Sectors for Innovation via Systematic Literature Review,L. J. Wiese; D. S. Schiff; A. J. Magana,ieee,10.1109/ETHICS57328.2023.10154947,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10154947,"Background: Questions surrounding the ethics of artificial intelligence (AI) have been debated for decades [1]. However, in recent years there have been multiple initiatives, scholarly reviews, and policy documents to identify and define ethical issues in play [2]. The efforts to bring high-level principles to applicable practice are complex and can be lost in translation [3]. Moreover, a call to be proactive, rather than reactive, stems from a deduction of intentions behind responsible innovation, value-centric design principles, education efforts, and representative data management techniques. Contemporary applications of AI are complex and difficult to explain, edit, and deal with once integrated in a natural system [4] [5]. Therefore, the analysis conducted within this systematic literature review (SLR) will clarify methods to promote and engage practice on the front end of ethical and responsible AI. As such, the research question is explored: How does each helix in the Quintuple Innovation model address responsible and ethical AI technology with anticipatory or proactive approaches? Methods: To conduct this ongoing research, an adaptation of the PRISMA framework and Hess & Fore's 2017 methodological approach guides the SLR [6] [7]. We included journal articles that were written in English and published between 2018-2023. The collected studies aim to examine how academic scholarship approaches to responsible AI within academia, government, industry, civil society, or the natural environment (the Quintuple Helix). The Web of Science, Google Scholar, and PhilPapers databases were used to identify a set of prominent publications in this field: AI & Society, Nature Machine Intelligence, Minds and Machines, IEEE Transactions on Technology and Society, AI and Ethics, Science and Engineering Ethics, and Communications of the ACM. A key limitation of this study is that it cannot gather the entirety of literature written about the topics of proactively promoting ethical AI due to the vast size and definitional complexity of the associated fields. These inclusion criteria allow the researchers to manage the data and draw meaningful insights from the most current thinking that is reflected in the rapid development of AI innovation we see today. Results and discussion: This poster will present preliminary results and the theoretical framework that guided the qualitative coding process. Additionally, this poster will serve as a forum to collect experts' opinions about what they would like to see from this SLR dataset, and how we can incorporate those elements into our coding. As a result, this data will be able to inform future work to investigate multiple gaps in the literature. For instance, U.S. Government work not protected by U.S. copyright this study will result in a theoretical framework that identifies proactive approaches to responsible and sustainable AI aligned with the five sectors for innovation. Inspired from [8], the effects of investments in education, and other sectors, will be mapped as a chain of responsible AI innovation across all innovation sectors. Finally, we can draw informed conclusions about the use and misuse of experts in AI, ethics, education, and policy. By working towards these objectives, we can see how the interdisciplinary field has made (or not made) a collective effort toward promoting responsible AI-filling a gap in the literature that highlights proactive approaches, rather than reactive. In conclusion, this data will inform experts across multiple domains about how to approach and organize a concerted effort to promote ethical and responsible AI in a pragmatic way.",0.07220216606498195
95,Ethics of AI as practical ethics,F. Richter,ieee,10.1109/ISTAS52410.2021.9629163,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9629163,"Whereas we acknowledge in general certain values as crucial for the ethical debate in AI, like e.g., fairness, transparency, and accountability, these values often can stand in conflict with each other. E.g., more transparency can lead to less privacy. Introducing higher principles to balance the values faces two problematic issues: (1.) Principles also can stand in conflict with each other and defer the discussion into a purely theoretical realm. (2.) If a higher-level principle is introduced and this also stands in conflict with another principle, then a higher-higher-level principle is needed, and we will get into an infinite regress. Although ethics of AI is part of the so-called field of applied ethics and it seems therefore that it is about the application of principles and values and finding the right balance regarding certain ethical theories, e.g., Kantian ethics or utilitarianism ([1][2][3]), the traditional approaches in the field of applied ethics do not offer sufficient conceptual means to deal with practical problems. Thus, the problems that arise from the implementation of intelligent systems can also not be handled adequately, because the same issue as above arises: How can the values be balanced regarding the ethical theories? If higher-level principles are not a viable approach to resolve conflicts of values, the criteria under which they can be implemented should be taken into consideration. Therefore, it is proposed that specific criteria for the implementation of the values need to be made explicit, which will result at least in a clarification for the public debate about certain technological advancements in the field of AI. [4] Furthermore, it is proposed that to resolve these conflicts the implementation must be evaluated, whether it enables human intervention in the future instead of making further actions and interventions impossible.",0.07216494845360824
96,Dignity or degradation: The risks and realities of carebots in Quebec,S. Knappe,ieee,10.1109/ISTAS52410.2021.9629175,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9629175,"The use of robots in elder care has been a topic of debate in ethics for the last twenty years. Care robots (carebots) present an opportunity to improve health outcomes for those in long term care by facilitating patients’ independence and reducing the workload on caregivers. However, many existing carebot projects have the potential to do harm, both on an individual and societal level. In this paper, the author examines the ethical implications of deploying carebots in the context of Quebec Public Health with a focus of the potential consequences of use in residential and long-term care centers (CHSLDs). The author connects the ethical principles that have been adopted by Quebec Public Health with the ethical discourse surrounding care robots, discusses the way Quebec Public Health adopts technology, then analyzes the relevance of various care robot projects. The result is a set of guidelines for the deployment of carebots in Quebec care homes.",0.0718954248366013
97,On the Ethics of Autonomous and Intelligent Systems (AIS),H. Messer,ieee,10.1109/ICAS49788.2021.9551187,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9551187,"In the 4th industrial revolution under which autonomous, intelligent systems are designed, certain human brain capacities are delegated to machines. This brings in great opportunity to reduce the need for human intervention in routines of daily lives, together with considerable ethical challenges. The role of the designers of such systems, i.e., engineers, is most important in balancing the opportunities and the challenges. Being a global organization with more than 450,000 members, IEEE took responsibility and has set up the Global Initiative on Ethics of Autonomous and Intelligent Systems, whose mission is: “To ensure every stakeholder involved in the design and development of autonomous and intelligent systems is educated, trained, and empowered to prioritize ethical considerations so that these technologies are advanced for the benefit of humanity.” In this talk I will present the various activities of the global initiative to promote ethics in AIS and, in particular, I will introduce Ethically Aligned Design, First Edition, which is a comprehensive treatise that combines a conceptual framework addressing universal human values, sustainability, data agency, and technical dependability, among other pressing issues with a set of principles to guide A/IS creators and users through a wide-ranging set of recommendations, further resources and reference material, and a painstakingly created glossary. Moreover, users - at all levels - of artificial intelligent systems must be aware of the ethical implications when deciding to use them. Policy makers are responsible for their regulation. But most importantly, designers of AIS systems -engineers - who are the only ones that can control some of the features reflecting on ethical issues (e.g., transparency) must take personal responsibility for the systems they produces to make sure they prioritize ethical considerations so that these technologies are advanced for the benefit of humanity. The way to raise awareness and responsibility is education, and IEEE has a special role in educating present and future engineers in the ethically aligned design of autonomous, intelligent systems.",0.071875
98,"AI Ethics in the Public, Private, and NGO Sectors: A Review of a Global Document Collection",D. Schiff; J. Borenstein; J. Biddle; K. Laas,ieee,10.1109/TTS.2021.3052127,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9327495,"In recent years, numerous public, private, and non-governmental organizations (NGOs) have produced documents addressing the ethical implications of artificial intelligence (AI). These normative documents include principles, frameworks, and policy strategies that articulate the ethical concerns, priorities, and associated strategies of leading organizations and governments around the world. We examined 112 such documents from 25 countries that were produced between 2016 and the middle of 2019. While other studies identified some degree of consensus in such documents, our work highlights meaningful differences across public, private, and NGO sectors. We analyzed each document in terms of how many of 25 ethical topics were covered and the depth of discussion for those topics. As compared to documents from private entities, NGO and public sector documents reflect more ethical breadth in the number of topics covered, are more engaged with law and regulation, and are generated through processes that are more participatory. These findings may reveal differences in underlying beliefs about an organization's responsibilities, the relative importance of relying on experts versus including representatives from the public, and the tension between prosocial and economic goals.",0.0718232044198895
99,“Resurrecting” dead celebrities: Editing and using remnant data of the deceased through AI,A. Orita,ieee,10.1109/ISTAS55053.2022.10227098,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10227098,"This paper explores the public perception toward handling remnant data of a celebrity after their death. It attempts to compile or publish these data, aiming to “resurrect” the celebrity through virtual reality (VR) and artificial intelligence (AI). Although such data are used for the memorial of the deceased, their autonomy and privacy preferences regarding the handling of their data must be addressed. Moreover, businesses that use remnant data of the deceased are emerging. This paper presents the results of an online survey conducted with 1,200 participants. The results showed that the percentage of respondents who wanted to utilize the data was low, with most answering “neither” and “don’t know” to questions regarding handling of remnant data of the deceased. In the responses, clear differences were observed based on gender, religion, and age group, with those by respondents in their 20s and 40s being the most distinctive. The methods preferred by the respondents to utilize remnant data varied according to the circumstances of the death and not celebrity type. In the case of predicted deaths, respondents preferred to compile posthumous data, whereas in the case of suicides, they preferred not to resurrect the individual via AI or VR. This indicates that the demand to resurrect celebrities is currently low; however, this may change in the future, and the ethical aspects will need to be considered.",0.07142857142857142
100,What Is a Subliminal Technique? An Ethical Perspective on AI-Driven Influence,J. P. Bermúdez; R. Nyrup; S. Deterding; L. Moradbakhti; C. Mougenot; F. You; R. A. Calvo,ieee,10.1109/ETHICS57328.2023.10155039,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155039,"Concerns about threats to human autonomy feature prominently in the field of AI ethics. One aspect of this concern relates to the use of AI systems for problematically manipulative influence. In response to this, the European Union's draft AI Act (AIA) includes a prohibition on AI systems deploying subliminal techniques that alter people's behavior in ways that are reasonably likely to cause harm (Article 5(1)(a)). Critics have argued that the term ‘subliminal techniques’ is too narrow to capture the target cases of AI-based manipulation. We propose a definition of ‘subliminal techniques’ that (a) is grounded on a plausible interpretation of the legal text; (b) addresses all or most of the underlying ethical concerns motivating the prohibition; (c) is defensible from a scientific and philosophical perspective; and (d) does not over-reach in ways that impose excessive administrative and regulatory burdens. The definition provides guidance for design teams seeking to pursue responsible and ethically aligned AI innovation.",0.07096774193548387
101,AI and Blackness: Toward Moving Beyond Bias and Representation,C. L. Dancy; P. K. Saucier,ieee,10.1109/TTS.2021.3125998,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9606203,"In this article, we argue that AI ethics must move beyond the concepts of race-based representation and bias, and toward those that probe the deeper relations that impact how these systems are designed, developed, and deployed. Many recent discussions on ethical considerations of bias in AI systems have centered on racial bias. We contend that antiblackness in AI requires more of an examination of the ontological space that provides a foundation for the design, development, and deployment of AI systems. We examine what this contention means from the perspective of the sociocultural context in which AI systems are designed, developed, and deployed and focus on intersections with anti-Black racism (antiblackness). To bring these multiple perspectives together and show an example of antiblackness in the face of attempts at de-biasing, we discuss results from auditing an existing open-source semantic network (ConceptNet). We use this discussion to further contextualize antiblackness in design, development, and deployment of AI systems and suggest questions one may ask when attempting to combat antiblackness in AI systems.",0.07058823529411765
102,Human behaviour analysis and face detection using machine learning,A. K. Dohare; M. Sharma; R. S. Pathak,ieee,10.1109/ICAC3N56670.2022.10074045,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10074045,Human behaviour analysis is a difficult aspect to maintain for a normal human being. This human behaviour analysis is unpredictable generally. The alignment of advanced technology such as machine learning is essential in this context. The machine learning technology plays an important role in structuring all human data and analysis their behavioural pattern considering accuracy and frequency of response. This research has evaluated multiple factors of human behaviour analysis considering its major of utilisation. This research has followed secondary research method based few specific and realistic objectives. An ethical consideration section states the ethical norms that this research has maintained. All the collected data of this research have been analysed considering all research objectives.,0.07017543859649122
103,Ethically Informed Software Process for Smart Health Home,X. Zhang; M. Pike; N. Mustafa; V. Brusic,ieee,10.1109/CBMS55023.2022.00040,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9867025,"Smart health homes (SHHs) integrate wearable sensors and various interconnected devices using the Internet of Things (IoT) technologies. SHHs combine IoT, data communication, and health-related applications to deliver healthcare services at home. The existing regulations and standards for SHH design are insufficient for home health care. Technical and device standards are available for guiding SHH design and implementation, but ethical standards are lacking. We identified six ethical requirements important for SHH: safety/trust, privacy/data security, vulnerable groups, individual autonomy, transparency/explainability/fairness, and social responsibility/ morality. We identified a set of questions useful for software engineering (SE) process for ethically informed software in SHH design and mapped them to the steps of software process. We mapped related guidelines from relevant professional codes of conduct. These questions can guide ethically informed software process of SHH.",0.06870229007633588
104,Contextuality and Intersectionality of E-Consent: A Human-centric Reflection on Digital Consenting in the Emerging Genetic Data Markets,S. Human; M. Kazzazi,ieee,10.1109/EuroSPW54576.2021.00051,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9583707,"Consent plays an essential role in different digital regulations, such as the European General Data Protection Regulation (GDPR). As a result, obtaining consent from data subjects (e.g. end-users or end-customers) are widely practised by many data controllers (e.g. service providers, companies, or organisations). Considering the importance and the widespread practice of consent-obtaining in different domains, critical and interdisciplinary studies of the current consent-obtaining mechanisms are highly needed. In this paper, we first shortly discuss an interdisciplinary human-centric perspective to consenting and propose that, among others, the contextuality of consent, as well as the potential intersectionality of consent, should be carefully considered in the development of consent-obtaining mechanisms. Then we elaborate on the distinction between “consent to personal data processing for commercial purposes” and “consent to personal data donations intended for research” in the field of direct-to-consumer genetic testing (DTC-GT). We show that based on our human-centric perspective, the contextuality and intersectionality of consent are sometimes overlooked in the current DTC-GT services, which are of considerable significance in the emerging genetic data markets. We hope that this paper can contribute towards the development of human-centric, accountable, lawful, and ethical (HALE) sociotechnical information systems dealing with consent and privacy management as fundamental building blocks of a sustainable digital economy.",0.06763285024154589
105,Qualitative Study of Text-to-Image AI Generators and their Relationship with NFTs,E. Arikan; S. Aram,ieee,10.1109/CSCI58124.2022.00046,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10216665,"The evolution of technology and science has brought groundbreaking developments to the current visual arts, and the application of digital technology has brought significant changes to the creation and aesthetic taste of traditional art. This study, therefore, investigates the current state-of-the-art artificial intelligence (AI) technologies and applications in generating visual art while giving a brief history of the intersection of AI and art, including the milestone advancements in neural networks. Fifteen interviews were conducted with technical artists who use text-to-image AI generators to gather data. Based on the findings from the interviews, the state-of-the-art applications were reviewed and analyzed in six categories: Accessibility, Barrier to Entry, Novelty, Ethics and Morality, Control, Non-fungible tokens (NFT) and Monetization which were widely discussed along with their success and limitations. The research concludes with three main findings; (a) monetization of digital media through NFTs that has a direct impact on the advancement of art generating AI applications, (b) there is a significant change in the traditional creative process with the integration of AI applications, and AI is not just a tool but it's a creative agent that artists collaborate with (c) art generating AI applications can generate limitless possibilities within the same aesthetics as a result revolutionize the way humans create and interact with art.",0.06635071090047394
106,Digital Health and Artificial Intelligence: Advancing Healthcare Provision in Latin America,R. García Alonso; U. Thoene; D. Dávila Benavides,ieee,10.1109/MITP.2022.3143530,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9770444,"Artificial intelligence (AI) has shown enormous potential for transforming healthcare delivery and accessibility in low- and middle-income countries such as those in Latin America, which are among the least equitable regions of the world. While healthcare analytics is already a global trend, in Latin America, it is gaining relevance given its demographic and socio-economic specificity and its particular healthcare systems. Hence, we first explore the linkage between the concepts of AI and digital health. Second, we analyze various types of AI technology in the healthcare sector, and finally, we discuss AI health-related services in Latin American countries and classify them according to applications and digital health interventions. We highlight pertinent issues of privacy and transparency in the use of patient data and records, as well as the technological and regulatory difficulties Latin American countries encounter in implementing AI-based services in the healthcare sector, a provision that also contributes to advancing United Nations Sustainable Development Goals.",0.06451612903225806
107,SHAPES Project Pilots' Self-assessment for Trustworthy AI,J. Rajamäki; P. A. Lebre Rocha; M. Perenius; F. Gioulekas,ieee,10.1109/DESSERT58054.2022.10018790,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10018790,"The Assessment List for Trustworthy AI (ALTAI) was developed by the High-Level Expert Group on Artificial Intelligence (AI HLEG) set up by the European Commission to help assess whether the AI system that is being developed, deployed, procured, or used, complies with the seven requirements of Trustworthy AI, as specified in the AI HLEG's Ethics Guidelines for Trustworthy AI. This paper describes the self-evaluation process of the SHAPES pilot campaign and presents some individual case results applying the prototype of an interactive version of the Assessment List for Trustworthy AI. Finally, the available results of two individual cases are combined. The best results are obtained from the evaluation category ‘transparency’ and the worst from ‘technical robustness and safety’. Future work will be combining the missing self-assessment results and developing mitigation recommendations for AI-based risk reduction recommendations for new SHAPES services.",0.06428571428571428
108,A toolkit of dilemmas: Beyond debiasing and fairness formulas for responsible AI/ML,A. Domínguez Hernández; V. Galanos,ieee,10.1109/ISTAS55053.2022.10227133,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10227133,"Approaches to fair and ethical AI have recently fell under the scrutiny of the emerging, chiefly qualitative, field of critical data studies, placing emphasis on the lack of sensitivity to context and complex social phenomena of such interventions. We employ some of these lessons to introduce a tripartite decision-making toolkit, informed by dilemmas encountered in the pursuit of responsible AI/ML. These are: (a) the opportunity dilemma between the availability of data shaping problem statements versus problem statements shaping data collection and processing; (b) the scale dilemma between scalability and contextualizability; and (c) the epistemic dilemma between the pragmatic technical objectivism and the reflexive relativism in acknowledging the social. This paper advocates for a situated reasoning and creative engagement with the dilemmas surrounding responsible algorithmic/data-driven systems, and going beyond the formulaic bias elimination and ethics operationalization narratives found in the fair-AI literature.",0.06382978723404255
109,Synthetic Differential Privacy Data Generation for Revealing Bias Modelling Risks,M. Wilchek; Y. Wang,ieee,10.1109/ISPA-BDCloud-SocialCom-SustainCom52081.2021.00211,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9644810,"Personally identifiable information (PII) continues to be used in predictive modeling by academic researchers and industry organizations. Most notably, the healthcare industry has been a popular testbed for innovative approaches from academia and institutions to address research using PII in predictive applications and synthetic data generation. The majority of these approaches that generate synthetic PII are based on actual data or obfuscating real data parts. Privacy leakage and ethical disclosure results continue to be among the largest issues that are difficult to avoid in synthetic PII generation techniques. In this analysis, we propose a novel method to generate synthetic, differential privacy data while avoiding the common pitfalls and capable of being leveraged broadly. Evidence is also shown that proves how our novel approach can maintain inference for modeling and potential risks tied to PII features. We conclude with a summarization of our findings and results and a short discussion on how using PII data may impact organizations interested in developing predictive applications.",0.06172839506172839
110,Age Appropriate Digital Services for Young People: Major Reforms,R. Farthing; K. Michael; R. Abbas; G. Smith-Nunes,ieee,10.1109/MCE.2021.3053772,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9333669,"Young people's digital lives are bigger than they have ever been. This means that realizing young people's rights now requires a concerted focus on the digital world as well. Terms and Conditions (from Cookies Policies to Terms of Service) are an important part of young people's digital worlds because they set the “rules of engagement” between digital products and young service users. However important, these Terms and Conditions rarely recognize young people's rights, let alone uphold them. This article outlines some of the ways Terms and Conditions fail young people, and why this is problematic from moral, legal, and commercial perspectives. This suggests there is a critical need for Terms and Conditions that uphold rights, and that a Standard around Terms and Conditions may be an effective way of addressing this problem.",0.06060606060606061
111,Critical Reflections on the Ethical Regulation of AI: Challenges with Existing Frameworks and Alternative Regulation Approaches,H. Cooreman; Q. Zhu,ieee,10.1109/ISTAS55053.2022.10227116,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10227116,"This paper synthesizes three fundamental challenges within existing frameworks for the ethical regulation of artificial intelligence (AI) identified in recently published literature. These challenges have recently been raised by ethicists, computer scientists, and policymakers. More specifically, existing frameworks are encountering challenges such as the difficulties that come along with defining an AI, adapting to the needs of the public in participating in democratic governance, and considering the environmental impacts of these systems. After critically reviewing the three challenges, this paper proposes alternative regulatory approaches to address each of these regulatory challenges. To address the definition challenge, we propose a multidimensional approach to defining AI. We argue that a relational approach can be helpful for making visible the cultural context in which AI systems are embedded. Finally, we suggest that involving a systematic environmental studies approach in assessing AI is conducive to the development of not only more environmentally friendly AI systems but also AI technologies that can be used to address challenging global environmental issues.",0.06060606060606061
112,Remote biometric identification systems and ethical challenges: The case of facial recognition,M. Milossi,ieee,10.1109/SEEDA-CECNSM53056.2021.9566226,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9566226,"Artificial Intelligence (AI) is the field of computer science progressing rapidly, simulating human behavior and thinking and affecting already the most of economic and social activities. The use of AI has undoubtedly positive outcomes but also implies high-risks. One of the most common AI applications is the case of facial recognition, a remote biometric identification system that raises the conversation around the intrusion into individuals’ privacy. In an attempt to balance ethical values and legal principles concerning, inter alia, automated recognition, European Commission puts forward a regulatory framework with specific objectives. The paper aims to highlight the precautionary principle that EU enforces in the case of facial recognition practice, establishing security mechanisms with the aim of mining, re-using and sharing data that are required for the buildout of a reliable Artificial Intelligence.",0.06060606060606061
113,Machine Excellence Tradeoffs to Ethical and Legal Perspectives,J. Torresen; D. Saplacan; A. Baselizadeh; T. Mahler,ieee,10.1109/CAI54212.2023.00109,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10195045,"We appreciate well-functioning technology being able to also personalize its services. However, to protect privacy and avoid a potential misuse of personal data, we are encouraged to limit the amount of personal data we share through apps and Internet services. While some services do not really need all the data they ask us to provide, others depend on it to provide the best possible performance of its service. That regards systems that apply data in machine learning for tasks like medical diagnostics. Especially deep learning algorithms perform better by using a large amount of data and are now able to benefit from the large amount as well with limited training time given access to high-performance computing resources. This paper address and discuss the tradeoffs like the one we have between data sharing minimalization for increased privacy and data maximization for machine learning systems. Perspectives related to ethics, legal, and social issues are considered in the paper. There is no single conclusion on the challenge, but attention to it can increase the awareness that the best balance differs depending on the application addressed.",0.06043956043956044
114,"If our aim is to build morality into an artificial agent, how might we begin to go about doing so?",R. Seeamber; C. Badea,ieee,10.1109/MIS.2023.3320875,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10268648,"As Artificial Intelligence (AI) becomes pervasive in most fields, from healthcare to autonomous driving, it is essential that we find successful ways of building morality into our machines, especially for decision-making. However, the question of what it means to be moral is still debated, particularly in the context of AI. In this paper, we highlight the different aspects that should be considered when building moral agents, including the most relevant moral paradigms and challenges. We also discuss the top-down and bottom-up approaches to design and the role of emotion and sentience in morality. We then propose solutions including a hybrid approach to design and a hierarchical approach to combining moral paradigms. We emphasize how governance and policy are becoming ever more critical in AI Ethics and in ensuring that the tasks we set for moral agents are attainable, that ethical behaviour is achieved, and that we obtain good AI.",0.06040268456375839
115,Cybersecurity Issues in Generative AI,S. Oh; T. Shon,ieee,10.1109/PlatCon60102.2023.10255179,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10255179,"Generative AI technology is being applied in various fields. However, the advancement of these technologies also raises cybersecurity issues. In fact, there are cases of cyber attack using Generative AI, and the number is increasing. Therefore, this paper analyzes the potential cybersecurity issues associated with Generative AI. First, we looked at the fields where Generative AI is used. Representatively, Generative AI is being used in text, image, video, audio, and code. Based on these five fields, cybersecurity issues that may occur in each field were analyzed. Finally, we discuss the obligations necessary for the future development and use of Generative AI.",0.0594059405940594
116,"Platform and Model Design for Responsible AI: Design and build resilient, private, fair, and transparent machine learning models",A. Kapoor; S. Chatterjee,ieee,,https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10251240.pdf&bkn=10251239&pdfType=book,"Craft ethical AI projects with privacy, fairness, and risk assessment features for scalable and distributed systems while maintaining explainability and sustainability Purchase of the print or Kindle book includes a free PDF eBookKey FeaturesLearn risk assessment for machine learning frameworks in a global landscapeDiscover patterns for next-generation AI ecosystems for successful product designMake explainable predictions for privacy and fairness-enabled ML trainingBook DescriptionAI algorithms are ubiquitous and used for tasks, from recruiting to deciding who will get a loan. With such widespread use of AI in the decision-making process, it’s necessary to build an explainable, responsible, transparent, and trustworthy AI-enabled system. With Platform and Model Design for Responsible AI, you’ll be able to make existing black box models transparent. You’ll be able to identify and eliminate bias in your models, deal with uncertainty arising from both data and model limitations, and provide a responsible AI solution. You’ll start by designing ethical models for traditional and deep learning ML models, as well as deploying them in a sustainable production setup. After that, you’ll learn how to set up data pipelines, validate datasets, and set up component microservices in a secure and private way in any cloud-agnostic framework. You’ll then build a fair and private ML model with proper constraints, tune the hyperparameters, and evaluate the model metrics. By the end of this book, you’ll know the best practices to comply with data privacy and ethics laws, in addition to the techniques needed for data anonymization. You’ll be able to develop models with explainability, store them in feature stores, and handle uncertainty in model predictions.What you will learnUnderstand the threats and risks involved in ML modelsDiscover varying levels of risk mitigation strategies and risk tiering toolsApply traditional and deep learning optimization techniques efficientlyBuild auditable and interpretable ML models and feature storesUnderstand the concept of uncertainty and explore model explainability toolsDevelop models for different clouds including AWS, Azure, and GCPExplore ML orchestration tools such as Kubeflow and Vertex AIIncorporate privacy and fairness in ML models from design to deploymentWho this book is forThis book is for experienced machine learning professionals looking to understand the risks and leakages of ML models and frameworks, and learn to develop and use reusable components to reduce effort and cost in setting up and maintaining the AI ecosystem.",0.05804749340369393
117,ETHICS-2023 Session B1 - Panel: Perspectives from Liberal Arts on the practical turn in AI Ethics,J. Messina; K. J. Schiff; S. A. Matei; S. A. Matei; D. Schiff,ieee,10.1109/ETHICS57328.2023.10154920,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10154920,"The increasing proliferation of advanced digital technologies like artificial intelligence (AI) capable of performing tasks and making decisions previously reserved for humans has surfaced important ethical questions. Emerging transformative applications like generative and multi-modal AI systems and automated decision-support systems in government have raised the stakes as developers, regulators, researchers, and civil society have worked to respond. Current discourse emphasizes issues like the distribution of costs and benefits across groups and contexts, the translation of principle-based frameworks to practices, the role of diversity and public participation, and trade-offs between goals like innovation and the protection of human rights. Yet dominant responses in scholarly and policy discourse have emphasized some perspectives and solutions while other approaches have arguably not been fully explored.",0.05785123966942149
118,AI Ethics Principles in Practice: Perspectives of Designers and Developers,C. Sanderson; D. Douglas; Q. Lu; E. Schleiger; J. Whittle; J. Lacey; G. Newnham; S. Hajkowicz; C. Robinson; D. Hansen,ieee,10.1109/TTS.2023.3257303,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10071542,"As consensus across the various published AI ethics principles is approached, a gap remains between high-level principles and practical techniques that can be readily adopted to design and develop responsible AI systems. We examine the practices and experiences of researchers and engineers from Australia’s national scientific research agency (CSIRO), who are involved in designing and developing AI systems for many application areas. Semi-structured interviews were used to examine how the practices of the participants relate to and align with a set of high-level AI ethics principles proposed by the Australian Government. The principles comprise: (1) privacy protection and security, (2) reliability and safety, (3) transparency and explainability, (4) fairness, (5) contestability, (6) accountability, (7) human-centred values, (8) human, social and environmental well-being. Discussions on the gained insights from the interviews include various tensions and trade-offs between the principles, and provide suggestions for implementing each high-level principle. We also present suggestions aiming to enhance associated support mechanisms.",0.057692307692307696
119,Predicting and Characterizing Legal Claims of Hospitals with Computational Intelligence: the Legal and Ethical Implications,C. Gallese; C. Fuchs; S. G. Riva; E. Foglia; F. Schettini; L. Ferrario; E. Falletti; M. S. Nobile,ieee,10.1109/CIBCB55180.2022.9863033,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9863033,"In this paper we propose a fuzzy logic-based approach to analyze UK National Health Service (NHS) public administrative data related to pre- and post-pandemic claims filed by patients, analyzing the legal and ethical issues connected to the use of Artificial Intelligence systems, including our own, to take critical decisions having a significant impact on patients, such as employing computational intelligence to justify the management choices related to Intensive Care Unit (ICU) bed allocation. Differently from previous papers, in this work we follow an unsupervised approach and, specifically, we perform an analysis of UK hospitals by means of a computational intelligence algorithm integrating Fuzzy C- Means and swarm intelligence. The dataset that we analyse allows us to compare pre- and post-pandemic data, to analyze the ethical and legal challenges of the use of computational intelligence for critical decision-making in the health care field.",0.056338028169014086
120,On Digital Ethics for Artificial Intelligence and Information Fusion in the Defense Domain,W. Koch,ieee,10.1109/MAES.2021.3066841,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9475911,"“For knowledge itself is power...”--- Francis Bacon's statement on achieving power as the meaning of all knowledge marks the beginning of the modern project. At the latest since the advent of AI in the defense domain, however, technology meant for the benefit of humanity may turn against humanity. This specific type of instrumental knowledge makes the modern crisis as visible as in spotlight. Ethical knowledge of man and his nature must complement Bacon's knowledge. There is an “ecology of man”: He does not make himself; he is responsible for himself and others. How can the data fusion community technically support responsible use of the power we are harvesting from AI? To argue more specifically, we consider documents of the German Bundeswehr, founded in the 1950s when the term AI was coined. Since these armed forces have learned lessons from “total war” and tyranny, they seem conceptually prepared for mastering the digital challenge. There exist parallels to ongoing IEEE P7000 standardization activities.",0.055900621118012424
121,The potential for co-operatives to mitigate AI ethics catastrophes: perspectives from media analysis,D. Marino; A. Moon,ieee,10.1109/ETHICS57328.2023.10155081,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155081,"Would the world have seen less AI-related scandals if more AI companies operated as co-operatives? As a response to multiple high profile tech scandals within the last decade, there has been an increased call for introducing more accountability in the AI industry. However, it is unclear to what degree the proposed efforts have been or will be effective in practice. The question remains whether these incremental, multi-stakeholder AI ethics efforts are in fact trying to address a fundamentally systemic issue inherent to the existing corporate power structure. As an attempt to address this question, we gain an understanding of the major themes in high profile AI-related catastrophes in the last four years (2018–2021) through an inductive media analysis. We then investigate how the principle of democratic gov-ernance and distributive executive power - core to co-operative organization structure - could have prevented or mitigated the contributing factors of the reported events. We find that the vast majority (71%) of the recent AI ethics scandals are not the result of a lack of knowledge or tools, but attributed to power dynamics that hinder the ability of internal stakeholders from taking action. We present the co-operative governance structure as a possible mitigating solution to addressing future AI ethics catastrophes, and provide a critical look at practical challenges inherent to AI co-operatives.",0.05504587155963303
122,Unfair AI: It Isn’t Just Biased Data,C. M. R. Haider; C. Clifton; Y. Zhou,ieee,10.1109/ICDM54844.2022.00114,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10027771,"Conventional wisdom holds that discrimination in machine learning is a result of historical discrimination: biased training data leads to biased models. We show that the reality is more nuanced; machine learning can be expected to induce types of bias not found in the training data. In particular, if different groups have different optimal models, and the optimal model for one group has higher accuracy, the optimal accuracy joint model will induce disparate impact even when the training data does not display disparate impact. We argue that due to systemic bias, this is a likely situation, and simply ensuring training data appears unbiased is insufficient to ensure fair machine learning.",0.05504587155963303
123,"Responsible AI, SDGs, and AI Governance in Africa",K. Wakunuma; G. Ogoh; D. O. Eke; S. Akintoye,ieee,10.23919/IST-Africa56635.2022.9845598,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9845598,"More than ever before, AI is now an area of national strategic importance. This has become quite evident with the proliferation of national AI strategies since the first was launched in Canada in 2017. There is now an ever-growing body of national AI strategies especially in countries situated in the Global South. AI is seen as a key driver of economic development and the strategies describe how countries plan to exploit AI technologies to achieve national development goals. However, AI technologies also generate problematic and unintended consequences, and the national strategies often describe governance mechanisms for mitigating such issues. As the national development goals of many countries also align with the UN SDGs, this paper explores the relationship between responsible governance of AI, the attainment of the UN SDGs and the implications for African countries. The paper shows that there is a clear link between the development of AI and the attainment of the SDGs. Also, based on an analysis of two AI policy tracking repositories - the OECD AI Policy Observatory and Oxford AI Readiness Index – this paper shows how African countries have lagged behind countries in the Global South in terms of the development of governance structures for AI. This has far-reaching implications for the attainment of the SGDs and the paper provides recommendations in this area.",0.05454545454545454
124,Exploring the Assessment List for Trustworthy AI in the Context of Advanced Driver-Assistance Systems,M. Borg; J. Bronson; L. Christensson; F. Olsson; O. Lennartsson; E. Sonnsjö; H. Ebabi; M. Karsberg,ieee,10.1109/SEthics52569.2021.00009,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9474814,"Artificial Intelligence (AI) is increasingly used in critical applications. Thus, the need for dependable AI systems is rapidly growing. In 2018, the European Commission appointed experts to a High-Level Expert Group on AI (AI-HLEG). AI- HLEG defined Trustworthy AI as 1) lawful, 2) ethical, and 3) robust and specified seven corresponding key requirements. To help development organizations, AI-HLEG recently published the Assessment List for Trustworthy AI (ALTAI). We present an illustrative case study from applying ALTAI to an ongoing development project of an Advanced Driver-Assistance System (ADAS) that relies on Machine Learning (ML). Our experience shows that ALTAI is largely applicable to ADAS development, but specific parts related to human agency and transparency can be disregarded. Moreover, bigger questions related to societal and environmental impact cannot be tackled by an ADAS supplier in isolation. We present how we plan to develop the ADAS to ensure ALTAI-compliance. Finally, we provide three recommendations for the next revision of ALTAI, i.e., life-cycle variants, domainspecific adaptations, and removed redundancy.",0.05454545454545454
125,Protecting Minors’ Personal Data in IoT-based Smart Homes According to GDPR,S. Rizou; E. Alexandropoulou-Egyptiadou; Y. Ishibashi; K. E. Psannis,ieee,10.1109/ICICN52636.2021.9673911,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9673911,"Apart from the positive effects of smart homes, such as economic, energy, and security enhancements, and the focus on their efficiency and reliability, it should also be paid attention to the legal, ethical and social impacts of this ICT ecosystem. The field of children’s data protection is challenging, as they are likely more vulnerable to online risks, and as a result, their protection requires a specialized privacy-preserving scheme. This research work addresses the crucial issues of minors’ data protection, from a European law perspective, through IoT-based devices inside a smart home environment.",0.05434782608695652
126,System Dynamics-Based Analysis on Factors Influencing Artificial Intelligence Talents Training,S. Jing; X. Liu; X. Gong; H. Zhao,ieee,10.1109/JRFID.2022.3216063,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9925578,"There are gaps between education supply and industrial demand of talents in intelligent era. Thus, the shortage of artificial intelligence(AI) talents becomes the top challenges facing China’s companies. Hence it is essential to implement educational reform to improve quality of education supply talents. However, educational reform is affected by multiple and intertwined factors. This research, therefore, developed a system dynamics-based model of education reform to sort out relationships among all factors and predict the influence of several factors on AI talents output. Then, based on this model, series of experiments are carried out to find main factors affecting cultivation of AI talents. Results show that: 1)this model could accurately simulate trends of output ratio AI talents under different educational reform measures; 2) Measures including teaching mode reform, improving the application rate of new teaching model, speeding up the construction of new disciplines in higher education, developing AI, improving ethics of AI, and strengthening the integration of AI and education could play significant roles in promoting cultivation of AI talents.",0.05325443786982249
127,Can Explanations Support Privacy Awareness? A Research Roadmap,W. Brunotte; L. Chazette; K. Korte,ieee,10.1109/REW53955.2021.00032,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582383,"Using systems as support tools for decision-making is a common part of a citizen’s daily life. Systems support users in various tasks, collecting and processing data to learn about a user and provide more tailor-made services. This data collection, however, means that users’ privacy sphere is increasingly at stake. Informing the user about what data is collected and how it is processed is key to reaching transparency, trustworthiness, and ethics in modern systems. While laws and regulations have come into existence to inform the user about privacy terms, this information is still conveyed in a complex and verbose way to the user, making it unintelligible to them. Meanwhile, explainability is seen as a way to disclose information about a system or its behavior in an intelligible manner. In this work, we propose explanations as a means to enhance users’ privacy awareness. As a long-term goal, we want to understand how to achieve more privacy awareness with respect to systems and develop heuristics that support it, helping end-users to protect their privacy. We present preliminary results on private sphere explanations and present our research agenda towards our long-term goal.",0.05319148936170213
128,"ETHICS-2021 Special Session 6: Panel- Well-being and ethically aligned design: ETHICS-2021 Panel Session, Sunday October 31,2021,11:00 AM-12:30 PM ET",B. Rakova; S. Spiekermann; M. Stephens; D. Hagar; J. Havens; M. Liu,ieee,10.1109/ETHICS53270.2021.9632707,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9632707,Wellbeing and Ethically Aligned Design: Defining and Implementing New Metrics of Success for Engineering and CSR (Corporate Social Responsibility).,0.05263157894736842
129,"The Road to a Successful HRI: AI, Trust and ethicS (TRAITS) Workshop",A. Rossi; S. Rossi; A. Andriella; A. van Maris,ieee,10.1109/HRI53351.2022.9889348,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9889348,"The aim of this workshop is to foster the exchange of insights on past and ongoing research towards effective and long-lasting collaborations between humans and robots. This workshop will provide a forum for representatives from academia and industry communities to analyse the different aspects of HRI that impact on its success. We particularly focus on AI techniques required to implement autonomous and proactive interactions, on the factors that enhance, undermine, or recover humans' acceptance and trust in robots, and on the potential ethical and legal concerns related to the deployment of such robots in human-centred environments. Website: https://sites.google.com/view/trains-hri-2022.",0.05102040816326531
130,Ensuring Global Perspectives within Reading Lists to Increase Students’ Engagement,G. J. Collins,ieee,10.23919/MIPRO57284.2023.10159772,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10159772,"University College London attracts students worldwide and provides students with the latest research opportunities to meet global challenges. The Department of Computer Science within the university has won recognition for its diversity and inclusion initiatives. During 2022 a series of AI ethics lectures were developed for the software engineering professional practice module to help students prepare for their research projects. Teaching was through the viewpoints of power imbalances relating to AI and green technologies, including resource extraction. The AI ethics series was designed as online flipped lectures. Students were encouraged to read research papers beforehand, which were subsequently discussed during the online lecture. Qualitative data analysis of the reading list provided insight to optimize content and reduce cognitive load. During 2022/23, students completed redesigned questionnaires to help the lecturer understand their knowledge of the topics and interests. Students outlined their interests in leading-edge AI concepts and how AI can reduce energy consumption and protect the environment and biodiversity. Analysis of questionnaires and discussions indicates students’ increased engagement in sustainability related topics. When perspectives from different regions of the world, reflecting the class’s global community, were introduced to the reading list, students were more engaged with the module.",0.050761421319796954
131,Artificial Intelligence Governance: A Study on the Ethical and Security Issues that Arise,A. Ndrejaj; M. Ali,ieee,10.1109/iCCECE55162.2022.9875082,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9875082,"artificial intelligence (AI) is rapidly becoming integrated into every facet of society. However, its use in current governance is lacking. Across major global powers, attempts are currently being made to regulate AI with the aim of protecting citizens, corporations and political realms. Despite this, there have been several serious incidents involving AI recently. The current gaps in governance could give way to even greater future problems as AI becomes a more pervasive part of society. This research examines both current attempts at governance and common concerns to address using both a case study on Amazon’s Alexa and a previously conducted survey of U.S. public opinion on AI. The results of these studies show that AI is not necessarily always secure and that citizens’ concerns over AI risks are growing. Overall, this research highlights some of the key areas governing bodies should seek to address.",0.04861111111111111
132,An efficient twitter data collection and analytics framework for effective disaster management,A. Aswathy; R. Prabha; L. S. Gopal; D. Pullarkatt; M. V. Ramesh,ieee,10.1109/DELCON54057.2022.9753627,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9753627,"The world has faced an exponential increase in disasters and it is very evident that losses incurred due to disasters and the risk of disasters are also increasing. The literature [1] states that India has faced 371 natural hazards resulting in considerable deaths, infrastructural, agricultural, and economic devastation. Social networking development has been expeditious and has been considered beneficial in disaster management. In culture, social media sites such as Twitter and Facebook have reached an irreplaceable stature that demonstrates the prominence of colossal data acquired. Social networking data can be gathered and used for disaster-specific data analysis, which can be used to extract disaster logistics, identify patterns, and provide public preparedness assistance. The proposed work establishes a data collection system that is capable of capturing disaster-related tweets such as landslides, rain and flood in focus, eliminating obsolete and irrelevant data, retaining related data such as media and location without breaching social media ethics privacy policies. Within the period from May 2020 to December 2021, the system was able to collect 9,21,897 tweets. The diversity of culture, language and expressions prevalent in different parts of the globe is reflected in the way knowledge is conveyed, which makes it relevant to collect tweets in Indian languages. So, for easier data analysis, this system gathers tweets that are in Indian languages and translates them into English for efficient data analysis.",0.048458149779735685
133,"Gender, Workforce and Artificial Intelligence",I. Idemudia; C. Onoshakpor,ieee,10.1109/AFRICON55910.2023.10293367,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10293367,"Our aim is to explore the role Artificial Intelligence has on widening the gender inequality gap that currently exists in the field of Information Technology. This study builds on the ‘Advancement of Women in Technology (AWT) framework and ‘The implicit bias theory to explore women's ability and willingness to enter and remain in an AI related career. By conducting semi-structured interviews of 4 users of AI as a pilot study, data gathered enables us to draw a parallel to fully understand the existing gender gap in AI and the general invisibility which women as contributors to the industry experience and make recommendations for industry practise.",0.047619047619047616
134,Network Data Acquisition and Monitoring System for Intensive Care Mechanical Ventilation Treatment,Q. A. Ng; Y. S. Chiew; X. Wang; C. P. Tan; M. B. M. Nor; N. S. Damanhuri; J. G. Chase,ieee,10.1109/ACCESS.2021.3092194,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9464296,"The rise of model-based and machine learning methods have created increasingly realistic opportunities to implement personalized, patient-specific mechanical ventilation (MV) in the ICU. These methods require monitoring of real-time patient ventilation waveform data (VWD) during MV treatment. However, there are relatively few non-invasive and/or non-proprietary systems to monitor and record patient-specific lung condition in real-time. In this paper, we present a CARE network data acquisition and monitoring system (CARENet) to automate data collection and to remotely monitor patient-specific lung condition and ventilation parameters. The automated system acquires VWD from a mechanical ventilator using a data acquisition device (DAQ), stores data in network-attached storage (NAS), and processes VWDs via a data management platform (DMP) web application. The web application enables real-time and retrospective model-based monitoring and analysis of clinical MV data. In particular, CARENet provides detailed breath-by-breath patient-specific respiratory mechanics, as well as the overall trends assessing changes in patient condition. Validation testing with a retrospective data set illustrated how breath-to-breath and time-varying patient-ventilator interaction during MV can be monitored, and, in turn, can be used to guide MV treatment. The network data acquisition system design presented is low-cost, open, and enables continuous, automated, scalable, real-time collection and analysis of waveform data, to help improve decision making, care, and outcomes in MV.",0.04739336492890995
135,Towards a Taxonomy of AI Risks in the Health Domain,D. Golpayegani; J. Hovsha; L. W. S. Rossmaier; R. Saniei; J. Mišić,ieee,10.1109/TransAI54797.2022.00007,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9951508,"The adoption of AI in the health sector has its share of benefits and harms to various stakeholder groups and entities. There are critical risks involved in using AI systems in the health domain; risks that can have severe, irreversible, and life-changing impacts on people’s lives. With the development of innovative AI-based applications in the medical and healthcare sectors, new types of risks emerge. To benefit from novel AI applications in this domain, the risks need to be managed in order to protect the fundamental interests and rights of those affected. This will increase the level to which these systems become ethically acceptable, legally permissible, and socially sustainable. In this paper, we first discuss the necessity of AI risk management in the health domain from the ethical, legal, and societal perspectives. We then present a taxonomy of risks associated with the use of AI systems in the health domain called HART, accessible online at https://w3id.org/hart. HART mirrors the risks of a variety of different real-world incidents caused by use of AI in the health sector. Lastly, we discuss the implications of the taxonomy for different stakeholder groups and further research.",0.04736842105263158
136,Examination of Ethical Principles for LLM-Based Recommendations in Conversational AI,J. Bang; B. -T. Lee; P. Park,ieee,10.1109/PlatCon60102.2023.10255221,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10255221,"Conversational interfaces allow users to experience artificial intelligence (AI) services through text or voice conversations. One common form of a conversational interface is a chatbot, which can be scenario-based or large language model (LLM)-based. A scenario-based chatbot generates a response within a predefined scenario for a user query on a specific domain or topic. The chatbot's response for recommendation is processed in conjunction with a separate algorithm. A LLM-based chatbot generates a response through a pretrained model to a user query on a wide range of topics. In this process, the LLM-based chatbot's response takes the form of a kind of recommendation, which is different from the existing recommendation services. To look at the issue more comprehensively, this paper examines recommendation-style system responses of a LLM-based chatbot with the principles of AI ethics. Several examples are shown where the chatbot's responses are modified according to principles of AI ethics.",0.04697986577181208
137,Major threats to the continued adoption of Artificial Intelligence in today's hyperconnected world,O. T. Eluwole; S. Akande; O. A. Adegbola,ieee,10.1109/AIIoT54504.2022.9817247,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9817247,"From the golden era of science fiction which dates to the late 1930s, scientific and technological advances in artificial intelligence (AI), along with one of its key subsets, machine learning (ML) have been growing significantly, especially in recent years. In 2021 alone, notable feats included an AI program capable of creating images from seen or previously unseen textual captions, an AI model that effectively integrates computer vision and natural language processing, and a novel AI framework for diagnosing dementia in 24 hours with real-world feasibility underway amongst a host of other fascinating breakthroughs. This paper briefly delves into AI/ML and recaps some key essentials, covering AI and ML subfields, ML methods, industries where AI/ML finds relevance, key stages and the common technical challenges in ML development. Importantly, the paper shifts attention from the latter to underscore the duo of transparency and ethics in AI, highlighting specifically what these are and why they are important, subsequently positing a PESTEL (Political, Economic, Social, Technological, Environmental and Legal) framework for AI design, build and implementation. It is anticipated that the upshot of this would be the facilitation of continuous adoption and long-term sustainability of AI/ML.",0.046875
138,Privacy is a feminist issue: Reconsidering data sharing in menstrual self-tracking apps,A. Fabricius,ieee,10.1109/ETHICS53270.2021.9632745,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9632745,"Though data governance, regulation and privacy are thought to be at the centre of a just society [1], feminist scholars have pointed out that privacy has historically been “a right not granted equally to all” [2, p. 1450]. Indeed, recent work has sought to identify how marginalized groups are especially prone to invasions of privacy, including having their private information used without their knowledge or consent in ways that can sustain and/or exacerbate social inequities [3],[4],[5]. In this presentation, I explore how the unethical data sharing practices of menstrual self-tracking apps like Flo and Ovia contribute to these problems. Flo prods users to log sensitive health data with explicit promises to “keep personal information private and secure” [6], though the Wall Street Journal demonstrated in 2019 that the company secretly shared user data with corporations for years [7]. Similarly, Ovia shared data with users' employers [8]. The consequences of these actions are complex, ranging from undermining users' health and well-being to potentially contributing to gender gaps in employment opportunities, pay, and access to resources. While there are benefits associated with using menstrual self-tracking apps, they can only be fully realized when these technologies are designed and operated ethically. I explore one possible path to improved corporate social responsibility by outlining the importance of developing theoretically informed corporate privacy policies that keep marginalized users' data private and secure. Drawing on insights from Nissenbaum's [9] theory of contextual integrity and feminist approaches to privacy that trouble the public/private dichotomy and the liberal democratic notion of a sovereign individual [10], [11], I explore what menstrual self-tracking apps could look like in the future, ultimately arguing that privacy is a feminist issue.",0.046762589928057555
139,Prioritizing Policies for Furthering Responsible Artificial Intelligence in the United States,E. Hadley,ieee,10.1109/BigData55660.2022.10020551,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10020551,"Several policy options exist, or have been proposed, to further responsible artificial intelligence (AI) development and deployment. Institutions, including U.S. government agencies, states, professional societies, and private and public sector businesses, are well positioned to implement these policies. However, given limited resources, not all policies can or should be equally prioritized. We define and review nine suggested policies for furthering responsible AI, rank each policy on potential use and impact, and recommend prioritization relative to each institution type. We find that pre-deployment audits and assessments and post-deployment accountability are likely to have the highest impact but also the highest barriers to adoption. We recommend that U.S. government agencies and companies highly prioritize development of pre-deployment audits and assessments, while the U.S. national legislature should highly prioritize post-deployment accountability. We suggest that U.S. government agencies and professional societies should highly prioritize policies that support responsible AI research and that states should highly prioritize support of responsible AI education. We propose that companies can highly prioritize involving community stakeholders in development efforts and supporting diversity in AI development. We advise lower levels of prioritization across institutions for AI ethics statements and databases of AI technologies or incidents. We recognize that no one policy will lead to responsible AI and instead advocate for strategic policy implementation across institutions.",0.046511627906976744
140,IEEE Standard for Security Management for Customer Cryptographic Assets on Cryptocurrency Exchanges,,ieee,10.1109/IEEESTD.2022.9676563,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9676563,"In this standard requirements are defined for multiple aspects of security management for customer cryptographic assets on cryptocurrency exchanges, such as user identification using multi-factor authentication, prioritized protection of customer assets under unforeseen circumstances, and professional ethics of operation for cryptocurrency exchange platforms.",0.046511627906976744
141,Decolonial Ethics in Training in Computational Engineering. A Qualitative Study of Professors' and Students' Perspectives,M. C. Castillo-González; A. L. Sánchez-Hernández; N. Lugo; C. V. Pérez-Lezama,ieee,10.1109/WEEF/GEDC53299.2021.9657297,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9657297,"We present an exploratory study that aims to diagnose the Engineering in Computational Technologies students' level of awareness with respect to the impact of the accelerated use of technology and the exponential growth that private socio-digital platforms have in everyday life because of the COVID-19 confinement. We research possible deterministic postures in the students' positions that could impede their ethical analysis of the social and environmental effects of the advance of data capitalism, among which racialization, algorithmic sexualization, and discrimination, as well as the erosion of the Commons on the Internet, stand out. The theoretical approach comes from a decolonial ethical framework, and the methodology of this study is qualitative. It consists of, in the first phase of the implementation, two focus groups with engineering students between the ages of 19 and 22 from different semesters and genders. In a second phase, we include eight in-depth interviews with professors from the School of Engineering and the School of Humanities who teach disciplinary and general education subjects in two campuses of a private university in Mexico.",0.045714285714285714
142,FAIR-DB: A system to discover unfairness in datasets,F. Azzalini; C. Criscuolo; L. Tanca,ieee,10.1109/ICDE53745.2022.9866857,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9866857,"In our everyday lives, technologies based on data play an increasingly important role. With the widespread adoption of decision making systems also in very sensitive environments, fairness has become a very important topic of discussion within the data science community. In this context, it is crucial to ensure that the data on which we base these decisions, are fair, and do not reflect historical biases. In this demo, we propose FAIR-DB (FunctionAl dependencIes to discoveR Data Bias), a system that exploiting the notion of Functional Dependency, a particular type of constraint on the data, can discover unethical behaviours in a dataset. The proposed solution is implemented as a web-based application, that, given an input dataset, generates such dependencies, walks the user trough their analysis, and finally provides many insights about bias present in the data. Our tool uses a novel metric to evaluate the unfairness present in datasets, identifies the attributes that encompass discrimination (e.g. ethnicity, sex or religion), and provides very precise information about the groups treated unequally. We also provide a detailed description of the system architecture and present a demonstration scenario, based on a real-world dataset frequently used in the field of computer ethics.",0.04568527918781726
143,Tackle Cognitive Biases in Videosurveillance,C. Nicodeme,ieee,10.1109/ISIE45552.2021.9576423,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9576423,"Artificial Intelligence and Deep Learning have been developing rapidly for almost a decade. New solutions emerged and many jobs, systems and processes were transformed using these technologies. They impacted lots of professions in a positive way, such as reducing repetitive and dangerous tasks, lessening operation costs and gaining productivity. Despite the real benefits coming from AI, limitations arose and may dramatically influence the results. The biases in AI are one of the major restrictions to mass industrialization of such tools. Indeed, biases exist in data and people. Algorithms might perpetuate or emphasize these biases and propose prejudiced decisions, causing societal questioning. Emergent research works aim at reducing the inequalities, in particular with the study of Ethics and Fairness in Artificial Intelligence algorithms. In this paper we propose a synthesis of bias origins and how to tackle them through fairness and ethics. This is illustrated by the chosen use case of videosurveillance in train stations.",0.045454545454545456
144,Managing the Cyber World: Hacker Edition,S. Vandervelden; M. M. Chowdhury; S. Latif,ieee,10.1109/ICECCME52200.2021.9590870,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9590870,"When surfing the internet, your input data can be put into one website, but do we have any concrete idea that who can see it. The hacking community lies within the bottom layers of the internet and can be fishing for people's data with intentions to fix the security flaw or to steal the person's data for financial gain. It is important to classify these hackers and figure out where the line is between good and bad to further create restrictions and stop hackers from harming people's data.",0.045454545454545456
145,Algorithmic Silence: A Call to Decomputerize,J. Penn,ieee,10.23919/JSC.2021.0023,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9698154,"Tech critics become technocrats when they overlook the daunting administrative density of a digital-first society. The author implores critics to reject structural dependencies on digital tools rather than naturalize their integration through critique and reform. At stake is the degree to which citizens must defer to unelected experts to navigate such density. Democracy dies in the darkness of sysadmin. The argument and a candidate solution proceed as follows. Since entropy is intrinsic to all physical systems, including digital systems, perfect automation is a fiction. Concealing this fiction, however, are five historical forces usually treated in isolation: ghost work, technical debt, intellectual debt, the labor of algorithmic critique, and various types of participatory labor. The author connects these topics to emphasize the systemic impositions of digital decision tools, which compound entangled genealogies of oppression and temporal attrition. In search of a harmonious balance between the use of “AI” tools and the non-digital decision systems they are meant to supplant, the author draws inspiration from an unexpected source: musical notation. Just as musical notes require silence to be operative, the author positions algorithmic silence-the deliberate exclusion of highly abstract digital decision systems from human decision-making environments-as a strategic corrective to the fiction of total automation. Facial recognition bans and the Right to Disconnect are recent examples of algorithmic silence as an active trend.",0.04524886877828054
146,Enhancing Non-Mass Breast Ultrasound Cancer Classification with Knowledge Transfer,Y. Hu; Y. Guo; F. Zhang; M. Wang; T. Lin; R. Wu; Y. Xu,ieee,10.1109/ISBI52829.2022.9761455,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761455,"Much progress has been made in the deep neural network (DNN) based diagnosis of mass lesions breast ultrasound (BUS) images. However, the non-mass lesion is less investigated because of the limited data. Based on the insight that mass data is sufficient and shares the same knowledge structure with non-mass data of identifying the malignancy of a lesion based on the ultrasound image, we propose a novel transfer learning framework to enhance the generalizability of the DNN model for non-mass BUS with the help of mass BUS. Specifically, we train a shared DNN with combined non-mass and mass data. With the prior of different marginal distributions in input and output space, we employ two domain alignment strategies in the proposed transfer learning framework with the insight of capturing domain-specific distribution to address the issue of domain shift. Moreover, we propose a cross-domain semantic-preserve data generation module called CrossMix to recover the missing distribution between non-mass and mass data that is not presented in training data. Experimental results on an in-house dataset demonstrate that the DNN model trained with combined data by our framework achieves a 10% improvement in AUC on the malignancy prediction task of non-mass BUS compared to training directly on non-mass data.",0.04433497536945813
147,Artificial Intelligence (AI) Literacy Questionnaire with Confirmatory Factor Analysis,D. T. Kit Ng; W. Wu; J. K. Lok Leung; S. K. Wah Chu,ieee,10.1109/ICALT58122.2023.00074,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10260973,"In recent years, schools started to incorporate artificial intelligence (AI) into computer science/STEAM curricula. However, few validated measurements have been designed to examine how secondary students develop AI literacy and perceive their learning outcomes. AI literacy has been measured from students' knowledge and skill acquisition, and behavior and attitudes. This research aims to develop and validate an instrument to assess AI literacy for secondary students. A questionnaire with 25 items measured in a 5-point Likert scale was created. In a pilot study, the questionnaire was administered to a sample of 363 secondary school students from two different schools in Hong Kong. Confirmatory factor analysis was conducted and grouped into six factors: (1) intrinsic motivation, (2) self-efficacy, (3) behavioral intention, (4) behavioral engagement, (5) know and understand, and (6) use and apply AI. The questionnaire showed a good fit model to support internal consistency reliability in most of the factors, with Cronbach's Alpha levels ranging from .58 to .88. A less-parsimonious model was proposed that help educators measure a wider AI literacy skill set with an acceptable model fit, with Cronbach's Alpha levels ranging from .91 to .94 based on affective, behavorial, cognitive and ethical (ABCE) learning framework. Further studies are needed to confirm the factor structure.",0.043689320388349516
148,Towards Trusting the Ethical Evolution of Autonomous Dynamic Ecosystems,E. Cioroaica; B. Buhnova; E. Tomur,ieee,10.1145/3526073.3527585,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9808797,"Until recently, systems and networks have been designed to implement established actions within known contexts. However, gaining the human trust in system behavior requires development of artificial ethical agents proactively acting outside fixed context boundaries for mitigating dangerous situations in which other interacting entities find themselves. A proactive altruistic behavior oriented towards removing danger needs to rely on predictive awareness of a dangerous situation. Differentthatcurrentapproachesfordesigningcognitivearchitectures, in this paper, we introduce a method that enables the creation of artificial altruistic trusted behavior together with an architecture of the framework that enables its implementation.",0.043478260869565216
149,Assessing Trustworthy AI in Times of COVID-19: Deep Learning for Predicting a Multiregional Score Conveying the Degree of Lung Compromise in COVID-19 Patients,H. Allahabadi; J. Amann; I. Balot; A. Beretta; C. Binkley; J. Bozenhard; F. Bruneault; J. Brusseau; S. Candemir; L. A. Cappellini; S. Chakraborty; N. Cherciu; C. Cociancig; M. Coffee; I. Ek; L. Espinosa-Leal; D. Farina; G. Fieux-Castagnet; T. Frauenfelder; A. Gallucci; G. Giuliani; A. Golda; I. van Halem; E. Hildt; S. Holm; G. Kararigas; S. A. Krier; U. Kühne; F. Lizzi; V. I. Madai; A. F. Markus; S. Masis; E. W. Mathez; F. Mureddu; E. Neri; W. Osika; M. Ozols; C. Panigutti; B. Parent; F. Pratesi; P. A. Moreno-Sánchez; G. Sartor; M. Savardi; A. Signoroni; H. -M. Sormunen; A. Spezzatti; A. Srivastava; A. F. Stephansen; L. B. Theng; J. J. Tithi; J. Tuominen; S. Umbrello; F. Vaccher; D. Vetter; M. Westerlund; R. Wurth; R. V. Zicari,ieee,10.1109/TTS.2022.3195114,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9845195,"This article’s main contributions are twofold: 1) to demonstrate how to apply the general European Union’s High-Level Expert Group’s (EU HLEG) guidelines for trustworthy AI in practice for the domain of healthcare and 2) to investigate the research question of what does “trustworthy AI” mean at the time of the COVID-19 pandemic. To this end, we present the results of a post-hoc self-assessment to evaluate the trustworthiness of an AI system for predicting a multiregional score conveying the degree of lung compromise in COVID-19 patients, developed and verified by an interdisciplinary team with members from academia, public hospitals, and industry in time of pandemic. The AI system aims to help radiologists to estimate and communicate the severity of damage in a patient’s lung from Chest X-rays. It has been experimentally deployed in the radiology department of the ASST Spedali Civili clinic in Brescia, Italy, since December 2020 during pandemic time. The methodology we have applied for our post-hoc assessment, called Z-Inspection®, uses sociotechnical scenarios to identify ethical, technical, and domain-specific issues in the use of the AI system in the context of the pandemic.",0.043478260869565216
150,"Democracy Framework, ColaboFlow, and Wikipedia - Governing Face-to-virtual Systems and Processes According to Democratic and Ethical Principles",S. M. Rudan; L. Kovacevic; S. Rudan,ieee,10.1109/ICEDEG52154.2021.9530998,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9530998,"We are witnessing a dramatic migration of society from the real world into virtual worlds (online systems) and face-to-virtual worlds (hybrid systems and events). Apart from the conventional e-gov and e-dem systems, virtual worlds (social media or other forms of online systems) become increasingly used as tools for promoting (or suppressing) democratic values and calls for changes. There is significant research on designing more efficient systems for practising e-democracy and (digital) ethics [1] [2]. However, fewer examples exist when it comes to mechanisms capable of managing democratic and ethical values in neutral digital systems whose main purpose is not related to e-gov and e-dem [3]. Together with a large stratum of society, power structures also migrate to virtual worlds. Therefore, there is a strong need to successfully migrate and enable democratic and ethical principles - one of the oldest and the most important values of a society.We propose a paradigm shift in system design to make online systems more transparent and open to external evaluation by neutral domain experts and institutions through visual workflows and behavioral processes. One implementation of such an approach is the ColaboFlow workflow framework, together with an associated domain-specific framework - Democracy Framework. We argue for the benefits of such an approach especially in the face-to-virtual context, which has become the primary modus operandi for many community-related events during the COVID- 19 era. We demonstrate ColaboFlow and Democracy in the real context of Wikipedia by analyzing its community and users, i.e. knowledge workers, and their behavior. We analyze and evaluate the Wikipedia community’s engagement (motivation) and participation in collaborative work in the relationship in terms of democratic and ethical community behaviors. We observe the types and quantities of the Wikipedia policies that knowledge workers refer to in the process of deliberative democracy, and correlate these findings with user behavior and motivation for contributing within the online ecosystem. We propose a two-tier model where we detect system anomalies at the (i) high, statistical and resource-cheap level, and understand and semi-automatically normalize (heal) the recognized anomalies at the (ii) low, behavioral and resource-demanding level.",0.04335260115606936
151,Creative Narration as an Ideation Technique,D. Manias; I. Mavrommati; I. Chatzigiannakis,ieee,10.1109/SEEDA-CECNSM53056.2021.9566217,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9566217,"Creative Narration is a technique that has the potential to enhance the initial design process of ideation in terms of collaboration and creativity. In this case study, the technique was used in the context of a distance creative (ideation) workshop to ideate on products in the specific field of Data Ethics. An initial assessment from this process, highlighting the strong and weak points of the technique, is discussed in this paper.",0.04225352112676056
152,"Precarious Data: Crack, Opioids, and Enacting a Social Justice Ethic in Data Visualization Practice",C. A. Welhausen,ieee,10.1109/TPC.2022.3144826,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9726517,"Background: The linguistic framing strategies used in media reporting on illegal drugs have been extensively documented, but less attention has been directed toward visuals, particularly data visualizations. Literature review: Positioning illegal drug use as a criminal justice problem or a public health issue are types of frameworks that use specific rhetorical strategies. Research questions: 1. What are the rhetorical strategies used in data visualizations published during the crack and opioid drug epidemics, respectively? 2. Do these strategies advance dominant media narratives that crack addiction should be criminalized but opioid addiction should be treated like a public health issue? And if so, how is this accomplished? Methodology: Drawing from the media studies approach previously employed in a study in technical and professional communication (TPC) on information design trends, I apply the concept of “scripto-visual” rhetoric to select data visualizations published by mainstream news media during both drug epidemics. Results: I argue these graphics escalated the perceived threat during both drug epidemics but different scripto-visual rhetorical strategies were used. Conclusions: Attending to ethical considerations in the creation of data visualizations has long been important in TPC, while scholarship has integrated social justice as a core component of the discipline. In the last section of this article, I bring these themes together by arguing that a social justice ethic is needed in data design work. I then propose a critical heuristic constructed from Jones et al.’s positionality, privilege, and power framework that can be used analytically or as an inventional tool to tease out the ways particular scripto-visual rhetorical decisions may be promoting inequities.",0.0421455938697318
153,Learning Analytics and MOOLs: there is much more than equipment usage logs,M. Zappatore,ieee,10.1109/LWMOOCS53067.2022.9927869,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9927869,"When dealing with online laboratories (either remote or virtual), it is crucial to monitor experiment activities and their outcomes closely, as well as to control how students access to these labs. A similar need also exists for evaluating student learning patterns and results, at both the individual and group level, so that customized study paths and contents can be proposed. To such aim, the research in the field of Learning Analytics has been very prolific in the recent decade, especially in the STEM area. This scenario becomes more challenging when online labs are offered as Massive Open Online Laboratories (MOOLs), large-scale and cloud-based infrastructure allowing students to access catalogs of online experiments on several topics as normally happens with traditional courses accessible via Massive Open Online Courses (MOOCs). This paper aims at focusing on the most relevant aspects of LA for MOOLs in terms of data requirements and data-related challenges, by examining four aspects that are tightly related to LA: data models and catalogs, data quality and scope, data privacy and ethics, and data visualizations. The resulting considerations can be used as a set of guidelines to take into account when designing a MOOL.",0.041237113402061855
154,Implementing Responsible AI: Tensions and Trade-Offs Between Ethics Aspects,C. Sanderson; D. Douglas; Q. Lu,ieee,10.1109/IJCNN54540.2023.10191274,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10191274,"Many sets of ethics principles for responsible AI have been proposed to allay concerns about misuse and abuse of AI/ML systems. The underlying aspects of such sets of principles include privacy, accuracy, fairness, robustness, explainability, and transparency. However, there are potential tensions between these aspects that pose difficulties for AI/ML developers seeking to follow these principles. For example, increasing the accuracy of an AI/ML system may reduce its explainability. As part of the ongoing effort to operationalise the principles into practice, in this work we compile and discuss a catalogue of 10 notable tensions, trade-offs and other interactions between the underlying aspects. We primarily focus on two-sided interactions, drawing on support spread across a diverse literature. This catalogue can be helpful in raising awareness of the possible interactions between aspects of ethics principles, as well as facilitating well-supported judgements by the designers and developers of AI/ML systems.",0.04081632653061224
155,How do AI systems fail socially?: an engineering risk analysis approach,S. Rismani; A. Moon,ieee,10.1109/ETHICS53270.2021.9632769,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9632769,"Failure Mode and Effect Analysis (FMEA) has been used as an engineering risk assessment tool since 1949. FMEAs are effective in preemptively identifying and addressing how a device or process might fail in operation and are often used in the design of high-risk technology applications such as military, automotive industry and medical devices. In this work, we explore whether FMEAs can serve as a risk assessment tool for machine learning practitioners, especially in deploying systems for high-risk applications (e.g. algorithms for recidivism assessment). In particular, we discuss how FMEAs can be used to identify social and ethical failures of Artificial Intelligent Systemss (AISs), recognizing that FMEAs have the potential to uncover a broader range of failures. We first propose a process for developing a Social FMEAs (So-FMEAs) by building on the existing FMEAs framework and a recently published definition of Social Failure Modes by Millar. We then demonstrate a simple proof-of-concept, So-FMEAs for the COMPAS algorithm, a risk assessment tool used by judges to make recidivism-related decisions for convicted individuals. Through this preliminary investigation, we illustrate how a traditional engineering risk management tool could be adapted for analyzing social and ethical failures of AIS. Engineers and designers of AISs can use this new approach to improve their system's design and perform due diligence with respect to potential ethical and social failures.",0.04072398190045249
156,"An Automatically Inferable Format for Creating Big Data of Morals, Ethics and ORDER OF VALUES Written Almost in Natural Language",K. Nakamura; T. Ando,ieee,10.1109/BigData55660.2022.10020724,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10020724,"If there is a format that is easy for both humans and AI (computers) to understand and infer, and also if the humans let the AI learn various morals, ethics and values in the above format, these data may be operated automatically by the AI in a way that the humans concerned are able to check for mistakes / lacks of thoughts in the automatic judgments by the AI, avoiding arbitrary thoughts / judgments by both the providers(humans) of such data and the AI.On the other hand, morals, etc. are diverse depending on the country, history, culture, social position, and/or individual. So in order to accurately express such data for reducing interpretation mistakes, lacks of required conditions of thought-rules and so on, we need to allow, as such data, expressions almost in (or from completely including all) the natural languages used in each cultural area.In this paper, we (1) propose a format based on natural language that we called as ""situation-specific-value-order-formula"" as a starting point for an expression format that satisfy the above needs, (2) explain its components: situations / viewpoints and items ( positive / 0 / negative ) ordered by the value all based on natural language, (3) explain related things including the specific l ogical i nference f eature o f t he n atural language based programming where variables are embedded in the natural language.We conclude that our proposed format is feasible and practical to some extent for the above Purpose and need.",0.04048582995951417
157,"The Privacy Universe – a game-based learning platform for data protection, privacy and ethics",M. Christensen; D. Britze; J. Vejlin; L. T. Sørensen; J. M. Pedersen,ieee,10.1109/EDUCON54358.2023.10125160,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10125160,"Recruiting and educating cybersecurity professionals continues to be a challenge. It is not hard for people with a preexisting interest to learn more, but in order to fill the gap of missing professionals within the field it is necessary to reach a broader audience and make more people interested in cybersecurity. One element in achieving this, is to show that cybersecurity is not only a technical discipline. Privacy Universe is a platform built within the Haaukins training platform, which a focus on privacy, data protection, ethics and social media usage, targeting less technical students. It enables students to learn about cybersecurity and privacy with hands-on training in a closed and secure environment. This paper presents the platform as well as a survey of 50 students of which 80% who have replied that their learning outcome is 4 or 5 on a scale from 1–5, 5 being the highest. In addition to this, a majority also found that their interest within cybersecurity increased based on their experience with Privacy Universe. This indicates that Privacy Universe is a beneficial addition to the already existing platforms to make cybersecurity interesting for a broader audience, in a field where those competences are much needed.",0.04
158,Cyberbullying Detection With Fairness Constraints,O. Gencoglu,ieee,10.1109/MIC.2020.3032461,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9233943,"Cyberbullying is a widespread adverse phenomenon among online social interactions in today’s digital society. While numerous computational studies focus on enhancing the cyberbullying detection performance of machine learning algorithms, proposed models tend to carry and reinforce unintended social biases. In this study, we try to answer the research question of “Can we mitigate the unintended bias of cyberbullying detection models by guiding the model training with fairness constraints?” For this purpose, we propose a model training scheme that can employ fairness constraints and validate our approach with different datasets. We demonstrate that various types of unintended biases can be successfully mitigated without impairing the model quality. We believe our work contributes to the pursuit of unbiased, transparent, and ethical machine learning solutions for cyber-social health.",0.04
159,"The IEEE Global Initiative on Ethics of Extended Reality (XR) Report--Extended Reality (XR) Ethics and Diversity, Inclusion, and Accessibility",D. Fox; I. G. Thornton,ieee,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9727122,"This report is the result of work within the IEEE Global Initiative on Ethics of Extended Reality (XR), a multidiscipline group of industry practitioners, ethicists, academics, researchers, educators, and technology enthusiasts. It has been written to focus on a wide range of ethical issues related to XR within the medicine domain. This report builds on work outlined in the ""Extended Reality"" chapter of the IEEE's seminal ethics-focused publication Ethically Aligned Design. XR is a term used to broadly refer to a suite of immersive technologies including virtual reality, augmented reality, and spatial computing. The scope of this report is the exploration of ethics-related issues to support the development, design, and deployment of XR applications in terms of diversity, inclusion and accessibility and the aim is to initiate expert-driven, multidiscipline analysis of the evolving XR Ethics requirements, with a vision to propose solutions, technologies, and standards in future updates. The set of recommendations within this report will hopefully contribute to industry conceptualization of socio-technological issues, highlight concreted recommendations, and lay the groundwork for future technical-standardization activities.",0.04
160,AI Value Alignment Problem: The Clear and Present Danger,S. Chaturvedi; C. Patvardhan; C. V. Lakshmi,ieee,10.1109/ISCON57294.2023.10112100,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10112100,"Artificial intelligence (AI) refers to the development of machines that are able to think and act like humans. Current advances in AI are targeting the advancements of systems that perform at super human level in particular tasks or domains. The critical challenge in developing AI is ensuring that the technology is safe and can be trusted. Because AI systems are capable of making decisions and taking actions without human intervention, it is crucial to ensure that they do not make mistakes or act in ways that are harmful to people or the environment. In this paper, we aim to present a clear conceptual understanding of the AI value alignment problem, the need to solve this problem, the major issues involved, approaches to tackle them and the way forward.",0.0390625
161,Sociotechnical Perspectives on AI Ethics and Accountability,N. Kokciyan; B. Srivastava; M. N. Huhns; M. P. Singh,ieee,10.1109/MIC.2021.3117611,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9646536,"The articles in this special section focus on sociotechnical perspectives on artificial intelligence (AI) ethics and accountability. Suppose we were to develop a loan-processing tool based on artificial intelligence (AI) to process applications by people for financial loan products. The tool would consider application data and recommend whether to give a loan and for how much. It would even seek out prospective borrowers online for new business and offer loans. Or, suppose we were to develop a career coach that recommends career tracks and training based on a user’s career goal, biosketch, and time and money available to invest in training. Applications of AI in decision support are not hypothetical, and applications such as loan processing and career coaching are becoming mainstream. However, although like other algorithms, their inputs and outputs are data; these AI applications are embedded in society, their decisions and recommendations have direct effects on people’s lives. Denial of a loan reduces financial options and may harm a borrower’s wellbeing, while giving a loan but at usurious interest rates might expose a borrower to financial ruin. Likewise, whereas career advice can be valuable to someone who does not have strong mentors, narrow or biased career advice can impede their future and, through them, their family’s prospects.",0.03827751196172249
162,Could an ISMS Model (ISO/IEC 27001:2013 Standard) Implementation Really Protect Public Data?,R. Tintin; M. Hidalgo,ieee,10.1109/ICEDEG58167.2023.10122109,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10122109,"This paper aims to present the experience on the design and implementation of an Information Security Management System (ISMS) model given under the international standard ISO/IEC 27001:2013 for the security of public data. To do this, the model taken as a reference is the one implemented by the Property Registry of the Pedro Moncayo Canton (PRPMC), Pichincha Province, Ecuador which due to its operability in the management of public data, brought about the achievement of said ISO international seal on Information Security and therefore became a benchmark for good practices in Ecuador at a national level. A quantitative methodology was used to analyze the design of the ISMS adopted by the PRPMC, under the international standard ISO/IEC 27001:2013 with the integration of some national regulations issued by the different competent control bodies. When a model is implemented, it can be considered that it indisputably ensures public data at a good level and allows us to be prepared through a contingency plan in the face of any adversity that implies damage or loss of physical or digital information and therefore be able to continue operating. In the same way, through the Gray Box-type ethical hacking reports, the evolution of the security and vulnerabilities of public data allocated at servers and in the cloud is shown. In the Property Registry case, the object of this study, it can be determined that said institution has reached a high standard of security of public data that guarantees reliability and trust of the procedures and contracts registered by the owners of any type of property in the canton. As a conclusion then it is recommended to take the protection of personal information of citizens as an obligation of the Ecuadorian State. This can be done through the updating of regulations so that the entities that handle public data are forced to implement information security based on these international standards.",0.03821656050955414
163,AI Support Marketing: Understanding the Customer Journey towards the Business Development,M. Tanveer; N. Khan; A. -R. Ahmad,ieee,10.1109/CAIDA51941.2021.9425079,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9425079,"Artificial Intelligence (AI) fundamentally works on the antecedents of business management’s exploration, systematical incorporation of businesses details, and focus on business extension. The main purpose of this study is to know the morals of services related to AI in order to develop the marketing and businesses. This study shows the opinions of marketers to know the value of Artificial Intelligence. We propose the research model so that study can be seen in one frame. Study indicates the observations of marketers regarding AI which is composed of 12 services of marketing, the 4Ps (Product, Price, Place, Promotion), the 4Cs (Consumer, Cost, Convenience, Communication), and the 4Es (Experience, Exchange, Everyplace, Evangelism). Using Cronbach’s alpha to analyze the data collected from 508 samples. We showed the reliability and validity of the data so that it can be used for further analysis. We proposed the hypothesis which showed the relationship of each marketing service with AI for developing the business. Consequently, results indicates that all the services, except Evangelism, have positive relationship with AI. Additionally, study also showed that AI highly works on the business development. And marketing also shows significant effect on Business development. Study also offers some important implications for business development that further research should be done on different services, area and audience.",0.03773584905660377
164,Web 3.0 Credibility: Principles for Ranking Media Sources,A. V. Gorodishchev; A. N. Gorodishcheva; D. O. Baigozhina; G. P. Kovalev,ieee,10.1109/ComSDS58064.2023.10130407,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10130407,"The search for reliable sources during the analysis, preparation and decision-making on the information publication has become resource-intensive with the evolution of the digital era. The proposed automated fact and partial distortion, forgery, falsification checking systems have low scores of accuracy and explain ability applied to social media. Involving people in the verification makes the process more accurate, but leads to delays. Automatic ranking framework of search engines is based on the parameters of reputation, image, information release time, consistency, without taking into account the role of the primary source and its attributes. In the course of the study, we show that work on AI is far from complete and human intervention is necessary at all levels of training, since automatically collected parameters and data are not enough at the current stage of AI development.",0.037037037037037035
165,Tempering Transparency in Human-Robot Interaction,K. Rogers; A. Howard,ieee,10.1109/ETHICS57328.2023.10154942,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10154942,"In recent years, particular interest has been taken by researchers and governments in examining and regulating aspects of transparency and explainability within artificially intelligent (AI) system. An AI system is “transparent” if humans can understand the mechanisms behind its behavior and use this understanding to make predictions about future behavior while the goal of explainable AI is to clarify an AI system's actions in a way that humans can understand. With this increased interest, research has presented conflicting views on the benefits of algorithmic transparency and explanations [1]. Moreover, research has also highlighted flaws within policy implementations of algorithmic transparency which generally remain too vague and often results in deficient adoption [2]. Even with these pitfalls of transparency, it seems as if the default view of many societies is that AI systems should be made more transparent and explainable; however, we argue that there needs to exist added skepticism of this position. In particular, we believe it is a useful exercise to consider exploring, as a counternarrative, an emerging area within computing that necessitates a lack of transparency-deceptive AI. The newly evolving area of research pertains to the creation (intentionally or not) of AI agents that learn to deceive humans and other AI agents. Here we define deception as “the process by which actions are chosen to manipulate beliefs so as to take advantage of the erroneous inferences” [3] and we use this interchangeably with “lying”. While there may be physically designed aspects of deception in embodied agents, such as the anthropomorphism and zoomorphism of robots [4], [5], here we wish to focus on deception related to utterances and actions of AI agents. On its surface, the idea of deceptive AI agents may not readily seem beneficial; however, there exists added effort to create AI agents that are able to be integrated socially within our societies. Seeing as deception is a foundational part of many human and animal groups, some argue that giving AI agents the ability to learn to deceive is necessary and inevitable for them to truly interact effectively [6], [7]. In fact, it has been found that deception can be an emergent behavior when training systems on human data [8]-thus strengthening the notion that behaving deceptively is a part of what it means to interact with humans. Moreover, prior research has shown that AI deception, rather than transparent truthfulness, can lead to better outcomes in human-robot interactions [9]–[11]. However, deception does of course have obvious drawbacks including an erosion of trust [12]–[15] and decreasing desired reutilization [12], [15]. Because of these negative aspects, and the clear possibly of malicious usage, some suggest the need for entirely truthful agents [16]. However, due to the infancy and lack of knowledge of the effects (short and long term) of deception within human-AI agent interaction, it is currently not possible to definitively determine the lasting implications of either encouraging or banning the practice. Given that transparency and explainability are in contention with deception, while also neither of the ideas are entirely beneficial nor detrimental, this presents important nuance when determining ethical and regulatory considerations of how AI agents should behave [17]. As such, the goal of this work is to present AI deception as a counternarrative to balance transparency and explainability with other considerations to spur discussions on how to be proactive, rather than reactive, to unforeseen consequences of our choices when designing AI systems that interact with humans.",0.03697183098591549
166,Defining a classification system for augmentation technology in socio-technical terms,I. Pedersen; A. H. Duin,ieee,10.1109/ISTAS52410.2021.9629174,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9629174,"This short paper provides a means to classify augmentation technologies to reconceptualize them as sociotechnical, discursive and rhetorical phenomena, rather than only through technological classifications. It identifies a set of value systems that constitute augmentation technologies within discourses, namely, the intent to enhance, automate, and build efficiency. This short paper makes a contribution to digital literacy surrounding augmentation technology emergence, as well as the more specific area of AI literacy, which can help identify unintended consequences implied at the design stages of these technologies.",0.03571428571428571
167,Responsible and Regulatory Conform Machine Learning for Medicine: A Survey of Challenges and Solutions,E. Petersen; Y. Potdevin; E. Mohammadi; S. Zidowitz; S. Breyer; D. Nowotka; S. Henn; L. Pechmann; M. Leucker; P. Rostalski; C. Herzog,ieee,10.1109/ACCESS.2022.3178382,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9783196,"Machine learning is expected to fuel significant improvements in medical care. To ensure that fundamental principles such as beneficence, respect for human autonomy, prevention of harm, justice, privacy, and transparency are respected, medical machine learning systems must be developed responsibly. Many high-level declarations of ethical principles have been put forth for this purpose, but there is a severe lack of technical guidelines explicating the practical consequences for medical machine learning. Similarly, there is currently considerable uncertainty regarding the exact regulatory requirements placed upon medical machine learning systems. This survey provides an overview of the technical and procedural challenges involved in creating medical machine learning systems responsibly and in conformity with existing regulations, as well as possible solutions to address these challenges. First, a brief review of existing regulations affecting medical machine learning is provided, showing that properties such as safety, robustness, reliability, privacy, security, transparency, explainability, and nondiscrimination are all demanded already by existing law and regulations—albeit, in many cases, to an uncertain degree. Next, the key technical obstacles to achieving these desirable properties are discussed, as well as important techniques to overcome these obstacles in the medical context. We notice that distribution shift, spurious correlations, model underspecification, uncertainty quantification, and data scarcity represent severe challenges in the medical context. Promising solution approaches include the use of large and representative datasets and federated learning as a means to that end, the careful exploitation of domain knowledge, the use of inherently transparent models, comprehensive out-of-distribution model testing and verification, as well as algorithmic impact assessments.",0.03543307086614173
168,Professional Perception Shift of Digital Society Values among IT Students (Results of Empirical Research),P. P. Deriugin; E. V. Strogetskaya; O. S. Bannova,ieee,10.1109/ComSDS58064.2023.10130432,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10130432,"The methodological principles of the study are the ideas of H. Innis and M. McLuhan about the role of mass media in the formation of modern society, where a person's access to information - working with big data and participating in the production of information - is the main factor in the shift in the perception of values. The shift in the perception of the values of the digital society in our understanding is the transformation of the ideas of IT specialists about significant phenomena that arise as a result of their involvement in the process of producing and analyzing information. Involvement in the production of information can be considered in several ways, for example, as the creation of information content, or as the creation of mechanisms, software, devices providing the creation of tools for the production and analysis of information. Shifts in the perception of information, in our opinion, are determined by the nature of the attitude to information and depend on the professional orientation of the respondents. The accumulation and growth of contradictions in the perception of values between people of different professional orientations constitutes an urgent social problem of stratification in a digital society. The hypothesis was that the nature of involvement in the information process will have a diverse effect on the nature of shifts in the perception of the values of the digital society, which will reveal features of these shifts as caused by the specifics of professional training. The object of the study was the 3rd-year students of the Faculty of Journalism (96.7% of the general population) and the Faculty of Computer Technologies and Informatics (94.3%). The subject of the study is the peculiarities of the shift in the perception of digital information by students of the IT specialty in comparison with students of the humanities. The purpose of the study is to identify and study the shift in the perception of the values of the digital society among students of IT specialties as caused by the peculiarities of professional training. The results of the study revealed relevant characteristics of the shift in the perception of the values among students of IT specialties: firstly, the shift in the values of the digital society in comparison with the values of past years; secondly, a number of different stages in the formation of such a shift; thirdly, the separation of understanding of “companionship” and “communication”; fourthly, the peculiarities of the perception of IT tools rather as a means (for journalists) and as a goal of activity (for IT specialists); fifthly, the presence of a set of shifts in understanding the importance of such characteristics of IT activities as ethics, responsibility, accessibility, security and a number of others; sixth, minor shifts in understanding the role of the IT space as a potential means of self-education, typical for students of both groups. The empirical study has confirmed the presence of a shift in the perception of the values of the digital society among students of IT specialties as caused by the peculiarities of their professional training.",0.03543307086614173
169,Universal Domain Adaptation for Remote Sensing Image Scene Classification,Q. Xu; Y. Shi; X. Yuan; X. X. Zhu,ieee,10.1109/TGRS.2023.3235988,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10043671,"The domain adaptation (DA) approaches available to date are usually not well suited for practical DA scenarios of remote sensing image classification since these methods (such as unsupervised DA) rely on rich prior knowledge about the relationship between label sets of source and target domains, and source data are often not accessible due to privacy or confidentiality issues. To this end, we propose a practical universal DA (UniDA) setting for remote sensing image scene classification that requires no prior knowledge on the label sets. Furthermore, a novel UniDA method without source data is proposed for cases when the source data are unavailable. The architecture of the model is divided into two parts: the source data generation stage and the model adaptation stage. The first stage estimates the conditional distribution of source data from the pretrained model using the knowledge of class separability in the source domain and then synthesizes the source data. With this synthetic source data in hand, it becomes a UniDA task to classify a target sample correctly if it belongs to any category in the source label set or mark it as “unknown” otherwise. In the second stage, a novel transferable weight that distinguishes the shared and private label sets in each domain promotes the adaptation in the automatically discovered shared label set and recognizes the “unknown” samples successfully. Empirical results show that the proposed model is effective and practical for remote sensing image scene classification, regardless of whether the source data are available or not. The code is available at https://github.com/zhu-xlab/UniDA.",0.03529411764705882
170,A Recommender System that safeguards the user privacy through Federated Learning,I. Guillén; R. Sánchez-Corcuera; D. Casado-Mansilla,ieee,10.23919/SpliTech52315.2021.9566466,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9566466,"Nowadays, there are more and more legal and ethical limitations when it comes to managing personal data. This is a serious problem for recommender systems (RS) or similar aplications since personal data (e.g. socioeconomic, demographics, behavioural, etc.) are the most useful for generating tailored correlations and predictions. To cope with this issue, this work proposes a recommender system that safeguards the user privacy by using a Federated Learning approach (FL). To this end, this article takes as the baseline an already existing centralized RS that uses all the data from users in a clear manner. This baseline RS is based on Factor Machines and it aims to employ persuasion strategies adapted to the user to increase energy awareness and change their consumption habits in the work environment. In order to test the performance of the FL-based distributed RS, the real dataset used (N=678) have been separated into four subsets mimicking a segmentation by country of origin (Austria, UK, Spain and Greece). Each country can create an artificial intelligence model suitable for its users that will be sent to a central server where the aggregation of models will take place and the improved global model will be returned back to each country. The simulation of this FL strategy is performed with four Raspberry Pi's reflecting each country and an NVIDIA Jetson Nano is used as the aggregation server. The generated model not only increases the privacy of the users as no raw data travels to the central server but also improves the reliability of the recommendations.",0.03529411764705882
171,Deep Connection: Making Virtual Reality Artworks with Medical Scan Data,M. Oliver; G. J. Joynes; K. Punithakumar; P. Seres,ieee,10.1109/VISAP52981.2021.00011,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622912,"Deep Connection is an installation and virtual reality (VR) artwork made using full body 3D and 4D magnetic resonance (MR) scan datasets. When the user enters Deep Connection, they see a scanned body lying prone in mid-air. The user can walk around the body and inspect it, lie underneath and walk through it. The user can dive inside and see its inner workings, its lungs, spine, brain. The user can take hold of the figure’s outstretched hand: holding the hand triggers the 4D dataset, making the heart beat and lungs breathe. When the user lets go the hand, the heart stops beating and the lungs stop breathing. Deep Connection creates a scenario where an embodied human becomes the companion for a virtual body. This paper maps the conceptual and theoretical framework for Deep Connection such as virtual intimacy and digitally mediated companionship. It also reflects on working with scanned bodies more generally in virtual reality by discussing transparency, the cyberbody versus the data body, as well as data privacy and data ethics. The paper also explains the technical and procedural aspects of the Deep Connection project with respect to acquiring scan data for the creation of virtual reality artworks.",0.035175879396984924
172,"Designing the UVA Open Data Initiative: Increasing Engagement for Students, Faculty, Staff Members, and Other Stakeholders",R. Ranjan; K. Lekan; V. Bhaip,ieee,10.1109/SIEDS52267.2021.9483750,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9483750,"Open data, the distribution of universally available datasets, fosters transparency and accountability to serve the stakeholders of a community. Universities act as hubs of innovation and discovery where any individual can collaborate and freely explore new ideas in their endeavors to better the world. At many universities, including the University of Virginia (UVA), the incongruous communication of data between all stakeholders, and most especially its lack of clarity to students, contributes to student disengagement that threatens to compromise the vision of a transparent and effective university. Open data initiatives at colleges remain an underused tool to target campus improvement and to empower the next generation of civic-minded student leaders. This paper seeks to explore the strengths and needed improvements in current open data principles and projects throughout cities and colleges in the United States. Herein the authors will develop a framework for building an open data initiative at the University of Virginia through evaluating the best practices from similar projects. This research will directly lead into a student-led initiative to develop the Open Data Platform at UVA and will form the foundation of the principles and lessons to be applied at UVA and other similar open data projects elsewhere.",0.035175879396984924
173,Machine vs. human agents in moral dilemmas: evidence from EEG and behavioral data,F. Cassioli; D. Crivelli; M. Balconi,ieee,10.1109/ICECCME55909.2022.9988331,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9988331,"The future involvement of automated technology in morally-charged decisions is an ethical challenge with relevant consequences. In this study, a task composed of moral dilemmas was employed to assess how participants (n= 34) would evaluate the morality, the consciousness, the responsibility, the intentionality, and the emotional impact of the agent (human vs. machine) and the type of behavior (action vs. inaction). Reaction times (RTs) and electroencephalography (delta, theta, beta, alpha, gamma bands) data were also gathered. Data showed that participants apply different moral rules based on the agent factor, considering humans more moral, responsible, and conscious. The evaluation of the emotional impact derived from human actions was perceived as more severe. Moreover, increased gamma power was found when assessing the intentionality and emotional impact of machines. Higher beta power in the right frontal and frontocentral areas was detected when evaluating the machine's produced emotional impact. An increased right temporal activation was detected when evaluating human agent's emotional impact. Lastly, an alpha desynchronization occurred when evaluating the responsibility of the inaction behavior in the left occipital area. These results might be interpreted as the applications of moral schemata depending on the involved agent, with a possible asymmetry effect in moral judgment.",0.035
174,Detecting Discrimination Risk in Automated Decision-Making Systems with Balance Measures on Input Data,M. Mecati; A. Vetrò; M. Torchiano,ieee,10.1109/BigData52589.2021.9671443,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671443,"Bias in the data used to train decision-making systems is a relevant socio-technical issue that emerged in recent years, and it still lacks a commonly accepted solution. Indeed, the ""bias in-bias out"" problem represents one of the most significant risks of discrimination, which encompasses technical fields, as well as ethical and social perspectives. We contribute to the current studies of the issue by proposing a data quality measurement approach combined with risk management, both defined in ISO/IEC standards. For this purpose, we investigate imbalance in a given dataset as a potential risk factor for detecting discrimination in the classification outcome: specifically, we aim to evaluate whether it is possible to identify the risk of bias in a classification output by measuring the level of (im)balance in the input data. We select four balance measures (the Gini, Shannon, Simpson, and Imbalance ratio indexes) and we test their capability to identify discriminatory classification outputs by applying such measures to protected attributes in the training set. The results of this analysis show that the proposed approach is suitable for the goal highlighted above: the balance measures properly detect unfairness of software output, even though the choice of the index has a relevant impact on the detection of discriminatory outcomes, therefore further work is required to test more in-depth the reliability of the balance measures as risk indicators. We believe that our approach for assessing the risk of discrimination should encourage to take more conscious and appropriate actions, as well as to prevent adverse effects caused by the ""bias in-bias out"" problem.",0.03488372093023256
175,Mixed-Method Long-Term Robot Usage: Older Adults' Lived Experience of Social Robots,A. K. Ostrowski; C. Breazeal; H. W. Park,ieee,10.1109/HRI53351.2022.9889488,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9889488,"In the past two decades, human-robot interaction (HRI) researchers have increasingly deployed autonomous and reliable robots long-term in various social contexts including the home. Our work provides a mixed-method approach for analyzing older adults' long-term robot usage data patterns combining quantitative data of robot usage logs with qualitative descriptions from participants' own experience. Overall, this provides a fuller picture to how older adults use and experience social robots in their homes. Our work involves a robot hosting period for at least a month (up to 12 months) in older adults' homes with an experience debrief session held a month into the robot hosting time period. We propose reflections on the novelty effect with respect to older adults' usage data and highlight feelings of guilt, the robot's proactivity and movement, meeting (or not meeting) user expectations, and the robot's persona as key aspects of the hosting experience that promoted usage or non-usage. Finally, we provide design guidelines for structuring future mixed-method long-term robot usage studies being mindful of ethical considerations in this space.",0.03488372093023256
176,Risk assessment tools on trial: Lessons learned for “Ethical AI” in the criminal justice system,N. Chugh,ieee,10.1109/ISTAS52410.2021.9629143,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9629143,"In 2018, the Supreme Court decision of Ewert v Canada confirmed that risk assessment tools such as the psychopathy checklists used by Correctional Services of Canada (CSC), failed to account for cultural heritage of the offender, specifically Indigeneity and the impact of colonialism on Canada’s Aboriginal communities. A further review of Canadian case-law post-Ewert reveals that Canadian courts continue their reliance on risk assessment tools despite the critiques from the legal community and from the Supreme Court of Canada. This paper reviews lessons learned from the Canadian experience of Ewert’s challenge of risk assessment tools and to highlight ethical concerns that are being considered in the implementation of artificial intelligence in the criminal justice system.",0.034782608695652174
177,CG-Net: Conditional GIS-Aware Network for Individual Building Segmentation in VHR SAR Images,Y. Sun; Y. Hua; L. Mou; X. X. Zhu,ieee,10.1109/TGRS.2020.3043089,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321533,"Object retrieval and reconstruction from very-high-resolution (VHR) synthetic aperture radar (SAR) images are of great importance for urban SAR applications, yet highly challenging due to the complexity of SAR data. This article addresses the issue of individual building segmentation from a single VHR SAR image in large-scale urban areas. To achieve this, we introduce building footprints from geographic information system (GIS) data as a complementary information and propose a novel conditional GIS-aware network (CG-Net). The proposed model learns multilevel visual features and employs building footprints to normalize the features for predicting building masks in the SAR image. We validate our method using a high-resolution spotlight TerraSAR-X image collected over Berlin. Experimental results show that the proposed CG-Net effectively brings improvements with variant backbones. We further compare two representations of building footprints, namely, complete building footprints and sensor-visible footprint segments, for our task, and conclude that the use of the former leads to better segmentation results. Moreover, we investigate the impact of inaccurate GIS data on our CG-Net, and this study shows that CG-Net is robust against positioning errors in the GIS data. In addition, we propose an approach of ground truth generation of buildings from an accurate digital elevation model (DEM), which can be used to generate large-scale SAR image data sets. The segmentation results can be applied to reconstruct 3-D building models at level-of-detail (LoD) 1, which is demonstrated in our experiments.",0.034334763948497854
178,Market Dynamics and Regulation of a Crowd-Sourced AI Marketplace,P. Dhamange; S. Soni; V. Sridhar; S. Rao,ieee,10.1109/ACCESS.2022.3171254,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9765494,"As usage of artificial intelligence (AI) technologies across industries increases, there is a growing need for creating large marketplaces to host and transact good-quality data sets to train AI algorithms. Our study analyzes the characteristics of such an oligopsony crowdsourced AI Marketplace (AIM) that has a large number of producers and few consumers who transact data sets as per their expectations of price and quality. Using agent-based modeling (ABM), we incorporate heterogeneity in agent attributes and self-learning by the agents that are reflective of real-world marketplaces. Our research augments the existing studies on the effect of and reputation systems in such market places. Extensive simulations using ABM indicate that ratings of the data sets as a feedback mechanism plays an important role in improving the quality of said data sets, and hence the reputations of producers. While such marketplaces are evolving, regulators have started enacting varying rules to oversee the appropriate functioning of such marketplaces, to minimize market distortions. In one of the first such studies, we integrate regulatory interventions in a marketplace model to analyze the impacts of various types of regulations on the functioning of an AIM. Our results indicate that very stringent regulatory measures negatively affect the production of quality data sets in the marketplace. On the other hand, regulatory oversight along with a ratings-based feedback mechanism improves the functioning of an AIM, and hence is recommended for governments and policy makers to adopt.",0.03375527426160337
179,Challenges of Artificial Intelligence in Medicine,N. Nasir; M. Alshabi; N. Al-Yateem; S. A. Rahman; M. A. Subu; H. H. Hijazi; F. R. Ahmed; J. M. Dias; A. Al Marzouqi; M. Y. Alkhawaldeh; M. Eid AbuRuz; A. R. Saifan,ieee,10.1109/COMPSAC57700.2023.00219,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10197035,"Medical technologies bolstered by AI are quickly developing into viable options for actual clinical use. Wearable, smartphones, and other mobile monitoring sensors are producing vast amounts of data that can be processed by deep learning algorithms in a variety of medical settings. Patients are eager for augmented medicine to be implemented because it will give them more control over their care and allow them to receive more tailored treatment, but doctors are hesitant to embrace the shift because they are not equipped to deal with the resulting changes in clinical practice. In addition, this phenomenon raises the questions of whether or not these cutting-edge tools should be validated by conventional clinical trials, whether or not medical schools should update their curricula to reflect the rise of digital medicine, and whether or not the ethics of constant connected monitoring should be taken into account. The purpose of this paper is to explore the current research literature and offer a holistic view of the implications of well-established clinical applications of artificial intelligence on medical professionals, hospitals, medical schools, and bioethics.",0.033707865168539325
180,Empirical analysis of fairness-aware data segmentation,S. Okura; T. Mohri,ieee,10.1109/ICDMW58026.2022.00029,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10031167,"Fairness in machine learning is a research area that is recently established, for mitigating bias of unfair models that treat unprivileged people unfavorably based on protected attributes. We want to take an approach for mitigating such bias based on the idea of data segmentation, that is, dividing data into segments where people should be treated similarly. Such an approach should be useful in the sense that the mitigation process itself is explainable for cases that similar people should be treated similarly. Although research on such cases exists, the question of effectiveness of data segmentation itself, however, remains to be answered. In this paper, we answer this question by empirically analyzing the experimental results of data segmentation by using two datasets, i.e., the UCI Adult dataset and the Kaggle ‘Give me some credit’ (gmsc) dataset. We empirically show that (1) fairness can be controllable during training models by the way of dividing data into segments; more specifically, by selecting the attributes and setting the number of segments for adjusting statistics such as statistical parity of the segments and mutual information between the attributes, etc. (2) the effects of data segmentation is dependent on classifiers, and (3) there exist weak trade-offs between fairness and accuracy with regard to data segmentation.",0.03365384615384615
181,Network on Privacy-Aware Audio-and Video-Based Applications for Active and Assisted Living: GoodBrother Project,N. Sklavos; M. Pantopoulou; F. Florez-Revuelta,ieee,10.1109/DSD57027.2022.00105,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9996851,"Active and Assisted Living (AAL) systems have a purpose to improve the lives of older or impaired people in various aspects. However, the use of equipment for data acquisition in these systems can be considered intrusive in some cases. Although de-identification may provide the needed protection to some extent, it is not always preferred, as it could affect the quality and utility of any obtained data. It is therefore crucial to establish methodologies for protecting the privacy of those monitored and thus affected by AAL systems. The purpose of GoodBrother is to a) analyze any issues arising from the use of monitoring AAL systems, regarding the users' privacy; b) establish proper guidelines for the use of these systems; c) develop privacy-aware methodologies for data handling; d) increase the systems' robustness and reliability; e) create databases to use towards benchmarking. Each one of these objectives are handled by separate interdisciplinary working groups.",0.033112582781456956
182,Visualization of Interval Regression for Facilitating Data and Model Insight,S. Kabir; C. Wagner,ieee,10.1109/FUZZ-IEEE55066.2022.9882717,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9882717,"With growing significance of interval-valued data, interest in artificial intelligence methods tailored to this data type is similarly increasing across a range of application domains. Here, regression, i.e., the modelling of the association between interval-valued variables has been shown to be both challenging and rewarding. Beyond the mathematical challenges, fundamentals, such as the visualization of regression models, are not similarly available for interval-valued data, limiting both accessibility and utility of resulting models. Recently, the Interval Regression Graph (IRG) was introduced, providing a powerful visualization tool for interval-valued regression models. In this paper, we demonstrate the IRG in a practical data-science application, showing how it can rapidly highlight powerful insights of data. Specifically, we focus on consumer characteristics, analyzing potential relationships between their demographic characteristics and their product purchase intentions. We conclude with a brief outlook on the potential and remaining challenges of leveraging interval-valued data using fuzzy systems and artificial intelligence more broadly.",0.032679738562091505
183,Corrections to “Blending Query Strategy of Active Learning for Imbalanced Data”,G. Kim; C. D. Yoo,ieee,10.1109/ACCESS.2022.3210356,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9932028,"In the above article [1], the following corrections are necessary. 1)In Table 4, all notions of “MC-Drop-B” are corrected to “MC-Drop-BMP.”2)“Statistical significannces of all experiments are examined” is corrected to “Statistical significance of each experiments is examined.”3)In Appendix II-D, “Shapiro test” is correct to ‘Shapiro-Wilk test.”  In addition, we would like to add the following acknowledgment: The authors appreciate the constructive discussions with Jaewon Lee (M.S. of KAIST), and the cooperation with researchers working on the project [Development and Study of AI Technologies to Inexpensively Conform to Evolving Policy on Ethics].",0.03260869565217391
184,Multisensor Data Fusion for Cloud Removal in Global and All-Season Sentinel-2 Imagery,P. Ebel; A. Meraner; M. Schmitt; X. X. Zhu,ieee,10.1109/TGRS.2020.3024744,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9211498,"The majority of optical observations acquired via spaceborne Earth imagery are affected by clouds. While there is numerous prior work on reconstructing cloud-covered information, previous studies are, oftentimes, confined to narrowly defined regions of interest, raising the question of whether an approach can generalize to a diverse set of observations acquired at variable cloud coverage or in different regions and seasons. We target the challenge of generalization by curating a large novel data set for training new cloud removal approaches and evaluate two recently proposed performance metrics of image quality and diversity. Our data set is the first publically available to contain a global sample of coregistered radar and optical observations, cloudy and cloud-free. Based on the observation that cloud coverage varies widely between clear skies and absolute coverage, we propose a novel model that can deal with either extreme and evaluate its performance on our proposed data set. Finally, we demonstrate the superiority of training models on real over synthetic data, underlining the need for a carefully curated data set of real observations. To facilitate future research, our data set is made available online.",0.032432432432432434
185,Learning About People's Attitude Towards Food Available in India and Its Implications for Fair AI-based Systems,H. C. Joshi; U. Yadav; B. Srivastava; R. M. Singh,ieee,10.1109/ICDMW58026.2022.00128,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10031102,"One of the popular notions of fairness from ethics literature envisages that a human requester of products or services should experience equal access to their choices regardless of their background. With food being essential to human survival and core to any economy, the domain has attracted a number of Artificial Intelligence (AI) techniques applied to tasks like food recommendation, recipe creation and food-oriented wellness. We want to explore if such concerns of fairness are appropriate here since food choices have an impact on an individual's health, personal finance and other aspects of life, and thus, any AI introduced here should be responsibly evaluated for not only performance but also non-functional requirements like their impact on users. As a first step towards that goal, in this paper, we want to understand people's perception towards food with respect to their background, and use this as the context to evaluate food-based AI systems in future. Therefore, we conduct the first-of-its-kind survey on perception about food available in India at educational institutes from participants who may associate themselves with different regions within and outside India. We find that users have unequal access to food from different regions today and this may be considered unfair by existing group fairness definitions. Further, we find that many food choices transcend regions, a majority of people prefer food outside their own regions and that usage of digital tools for food is on the rise. The results suggest that AI developers can provide broader and fairer (equal) access by using a mixed strategy of food choices that transcend regions (exploit food data) and also choosing new choices that are region-specific (explore food) dependent on user's regional association.",0.03237410071942446
186,"Evaluation of Conversational Agents: Understanding Culture, Context and Environment in Emotion Detection",M. T. Teye; Y. M. Missah; E. Ahene; T. Frimpong,ieee,10.1109/ACCESS.2022.3153787,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9718284,"Valuable decisions and highly prioritized analysis now depend on applications such as facial biometrics, social media photo tagging, and human robots interactions. However, the ability to successfully deploy such applications is based on their efficiencies on tested use cases taking into consideration possible edge cases. Over the years, lots of generalized solutions have been implemented to mimic human emotions including sarcasm. However, factors such as geographical location or cultural difference have not been explored fully amidst its relevance in resolving ethical issues and improving conversational AI (Artificial Intelligence). In this paper, we seek to address the potential challenges in the usage of conversational AI within Black African society. We develop an emotion prediction model with accuracies ranging between 85% and 96%. Our model combines both speech and image data to detect the seven basic emotions with a focus on also identifying sarcasm. It uses 3-layers of the Convolutional Neural Network in addition to a new Audio-Frame Mean Expression (AFME) algorithm and focuses on model pre-processing and post-processing stages. In the end, our proposed solution contributes to maintaining the credibility of an emotion recognition system in conversational AIs.",0.03208556149732621
187,"Sketching an AI Marketplace: Tech, Economic, and Regulatory Aspects",A. Kumar; B. Finley; T. Braud; S. Tarkoma; P. Hui,ieee,10.1109/ACCESS.2021.3050929,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319656,"Artificial intelligence shows promise for solving many practical societal problems in areas such as healthcare and transportation. However, the current mechanisms for AI model diffusion such as Github code repositories, academic project webpages, and commercial AI marketplaces have some limitations; for example, a lack of monetization methods, model traceability, and model auditabilty. In this work, we sketch guidelines for a new AI diffusion method based on a decentralized online marketplace. We consider the technical, economic, and regulatory aspects of such a marketplace including a discussion of solutions for problems in these areas. Finally, we include a comparative analysis of several current AI marketplaces that are already available or in development. We find that most of these marketplaces are centralized commercial marketplaces with relatively few models.",0.032
188,A Deep Dive on Business Intelligence Systems and Infrastructure using Cloud Environment,V. Kumar; Himanshu; A. K. Rawat; N. S. Kumar,ieee,10.1109/INCET51464.2021.9456369,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9456369,"Business intelligence is a computer technology used to identify, obtain and analyze business data for example revenue, products, costs, sales revenue etc. However, this type of trajectory creates closed data that requires significant time to get an idea of everything the user needs. Despite its shortcomings Business Intelligence (BI) has been able to generate fast data that could take a long time to research, making it an ideal tool for tracking emerging markets and markets in the community. Business Intelligence (BI) is an umbrella term that combines software with the development of Information systems and makes available the required information for any company. Most agree that BI works by capturing, storing, understanding and analyzing unprocessed data and making information accessible to it to improve business performance.",0.031746031746031744
189,The IEEE Global Initiative on Ethics of Extended Reality (XR) Report--Extended Reality (XR) Ethics in Medicine,J. Evans,ieee,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9714059,"Extended Reality (XR) for medical use cases is proving to be beneficial to both patients and healthcare professionals as well as all other stakeholders throughout the healthcare industry. Healthcare is one of the largest industries to adopt XR technology. Some of the XR use-cases include helping surgeons better perform surgeries, immersing patients and healthcare professionals in medical information and education, and training all within XR environments. This report highlights the need for an ethical framework that is evolved from best practices throughout medical and technological fields to help ensure safe and equitable usage of the technology.",0.03125
190,Toward Accountable and Explainable Artificial Intelligence Part One: Theory and Examples,M. M. Khan; J. Vice,ieee,10.1109/ACCESS.2022.3207812,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9895234,"Like other Artificial Intelligence (AI) systems, Machine Learning (ML) applications cannot explain decisions, are marred with training-caused biases, and suffer from algorithmic limitations. Their eXplainable Artificial Intelligence (XAI) capabilities are typically measured in a two-dimensional space of explainability and accuracy ignoring the accountability aspects. During system evaluations, measures of comprehensibility, predictive accuracy and accountability remain inseparable. We propose an Accountable eXplainable Artificial Intelligence (AXAI) capability framework for facilitating separation and measurement of predictive accuracy, comprehensibility and accountability. The proposed framework, in its current form, allows assessing embedded levels of AXAI for delineating ML systems in a three-dimensional space. The AXAI framework quantifies comprehensibility in terms of the readiness of users to apply the acquired knowledge and assesses predictive accuracy in terms of the ratio of test and training data, training data size and the number of false-positive inferences. For establishing a chain of responsibility, accountability is measured in terms of the inspectability of input cues, data being processed and the output information. We demonstrate applying the framework for assessing the AXAI capabilities of three ML systems. The reported work provides bases for building AXAI capability frameworks for other genres of AI systems.",0.03125
191,27 Years and 81 Million Opportunities Later: Investigating the Use of Email Encryption for an Entire University,C. Stransky; O. Wiese; V. Roth; Y. Acar; S. Fahl,ieee,10.1109/SP46214.2022.9833755,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9833755,"Email is one of the main communication tools and has seen significant adoption in the past decades. However, emails are sent in plain text by default and allow attackers easy access. Users can protect their emails by end-to-end encrypting them using tools such as S/MIME or PGP.Although PGP had already been introduced in 1991, it is a commonly held belief that email encryption is a niche tool that has not seen widespread adoption to date. Previous user studies identified ample usability issues with email encryption such as key management and user interface challenges, which likely contribute to the limited success of email encryption.However, so far ground truth based on longitudinal field data is missing in the literature. Towards filling this gap, we measure the use of email encryption based on 27 years of data for 37,089 users at a large university. While attending to ethical and data privacy concerns, we were able to analyze the use of S/MIME and PGP in 81,612,595 emails.We found that only 5.46% of all users ever used S/MIME or PGP. This led to 0.06% encrypted and 2.8% signed emails. Users were more likely to use S/MIME than PGP by a factor of six. We saw that using multiple email clients had a negative impact on signing as well as encrypting emails and that only 3.36% of all emails between S/MIME users who had previously exchanged certificates were encrypted on average.Our results imply that the adoption of email encryption is indeed very low and that key management challenges negatively impact even users who have set up S/MIME or PGP previously.",0.030303030303030304
192,Variational Counterfactual Prediction under Runtime Domain Corruption,H. Wen; T. Chen; L. K. Chai; S. Sadiq; J. Gao; H. Yin,ieee,10.1109/TKDE.2023.3321893,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10271745,"To date, various neural methods have been proposed for causal effect estimation based on observational data, where a default assumption is the same distribution and availability of variables at both training and inference (i.e., runtime) stages. However, distribution shift (i.e., domain shift) could happen during runtime, and bigger challenges arise from the impaired accessibility of variables. This is commonly caused by increasing privacy and ethical concerns, which can make arbitrary variables unavailable in the entire runtime data and imputation impractical. We term the co-occurrence of domain shift and inaccessible variables runtime domain corruption, which seriously impairs the generalizability of a trained counterfactual predictor. To counter runtime domain corruption, we subsume counterfactual prediction under the notion of domain adaptation. Specifically, we upper-bound the error w.r.t. the target domain (i.e., runtime covariates) by the sum of source domain error and inter-domain distribution distance. In addition, we build an adversarially unified variational causal effect model, named VEGAN, with a novel two-stage adversarial domain adaptation scheme to reduce the latent distribution disparity between treated and control groups first, and between training and runtime variables afterwards. We demonstrate that VEGAN outperforms other state-of-the-art baselines on individual-level treatment effect estimation in the presence of runtime domain corruption on benchmark datasets.",0.029411764705882353
193,PrivPAS: A real time Privacy-Preserving AI System and applied ethics,H. B. S. S; V. Agarwal; S. Ghosh; G. Ramena; S. Kumar; B. R. K. Raja,ieee,10.1109/ICSC52841.2022.00010,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9736272,"With 3.78 billion social media users worldwide in 2021 (48% of the human population), almost 3 billion images are shared daily. At the same time, a consistent evolution of smartphone cameras has led to a photography explosion with 85% of all new pictures being captured using smartphones. However, lately, there has been an increased discussion of privacy concerns when a person being photographed is unaware of the picture being taken or has reservations about the same being shared. These privacy violations are amplified for people with disabilities, who may find it challenging to raise dissent even if they are aware. Such unauthorized image captures may also be misused to gain sympathy by third-party organizations, leading to a privacy breach. Privacy for people with disabilities has so far received comparatively less attention from the AI community. This motivates us to work towards a solution to generate privacy-conscious cues for raising awareness in smartphone users of any sensitivity in their viewfinder content. To this end, we introduce PrivPAS (A real time Privacy-Preserving AI System) a novel framework to identify sensitive content. Additionally, we curate and annotate a dataset to identify and localize accessibility markers and classify whether an image is sensitive to a featured subject with a disability. We demonstrate that the proposed lightweight architecture, with a memory footprint of a mere 8.49MB, achieves a high mAP of 89.52% on resource-constrained devices. Furthermore, our pipeline, trained on face anonymized data. achieves an F1-score of 73.1%.",0.02880658436213992
194,The Enactive and Interactive Dimensions of AI: Ingenuity and Imagination Through the Lens of Art and Music,M. Sato; J. McKinney,ieee,10.1162/artl_a_00376,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10301978,"Dualisms are pervasive. The divisions between the rational mind, the physical body, and the external natural world have set the stage for the successes and failures of contemporary cognitive science and artificial intelligence.1 Advanced machine learning (ML) and artificial intelligence (AI) systems have been developed to draw art and compose music. Many take these facts as calls for a radical shift in our values and turn to questions about AI ethics, rights, and personhood. While the discussion of agency and rights is not wrong in principle, it is a form of misdirection in the current circumstances. Questions about an artificial agency can only come after a genuine reconciliation of human interactivity, creativity, and embodiment. This kind of challenge has both moral and theoretical force. In this article, the authors intend to contribute to embodied and enactive approaches to AI by exploring the interactive and contingent dimensions of machines through the lens of Japanese philosophy. One important takeaway from this project is that AI/ML systems should be recognized as powerful tools or instruments rather than as agents themselves.",0.02824858757062147
195,Towards providing explanations for robot motion planning,M. Brandão; G. Canal; S. Krivić; D. Magazzeni,ieee,10.1109/ICRA48506.2021.9562003,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9562003,"Recent research in AI ethics has put forth explainability as an essential principle for AI algorithms. However, it is still unclear how this is to be implemented in practice for specific classes of algorithms—such as motion planners. In this paper we unpack the concept of explanation in the context of motion planning, introducing a new taxonomy of kinds and purposes of explanations in this context. We focus not only on explanations of failure (previously addressed in motion planning literature) but also on contrastive explanations—which explain why a trajectory A was returned by a planner, instead of a different trajectory B expected by the user. We develop two explainable motion planners, one based on optimization, the other on sampling, which are capable of answering failure and constrastive questions. We use simulation experiments and a user study to motivate a technical and social research agenda.",0.027972027972027972
196,AI and Stochastic Terrorism – Should it be done?,B. Kemper,ieee,10.1109/ISSREW55968.2022.00091,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9985190,"The use of Artificial Intelligence and Machine Learning technology may seem to be the tools needed to combat media-inspired “lone wolf attacks” by implementing the concept of “stochastic terrorism,” targeting harmful media influences. Machine Learning is in current use to sort through social media data to assess hate speech. Artificial Intelligence is in current use to interpret the data and trends processed by Machine Learning for tasks such as finding criminal networks. The question becomes “can stochastic terrorism be proven” and “should this be implemented.” Labeling someone as a “terrorist,” regardless of any modifier for the term, tags the person or group for severe, potentially lethal, response by the government and the community. Criminal accusation cannot ethically be done casually or without sufficient cause. Due to documented problems with bias in all aspects of the issue, using these computational tools to establish legal causation between media statements by pundits, politicians, or others and the violence of “lone wolf” actors would not meet the requirements of US jurisprudence or the ethical principles for Artificial Intelligence of being explainable, transparent, and responsible.",0.027777777777777776
197,Human-Machine Duality: What’s Next in Cognitive Aspects of Artificial Intelligence?,A. N. Raikov; M. Pirani,ieee,10.1109/ACCESS.2022.3177657,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9780404,"The goal of the paper is to find means for the unification of human-machine duality in collective behavior of people and machines, by conciliating approaches that proceed in opposite directions. The first approach proceeds top-down from non-formalizable, cognitive, uncaused, and chaotic human consciousness towards purposeful and sustainable human-machine interaction. The second approach proceeds bottom-up from intelligent machines towards high-end computing and is based on formalizable models leveraging multi-agent architectures. The resulting work reviews the extent, the merging points, and the potential of hybrid artificial intelligence frameworks that accept the idea of strong artificial intelligence. These models concern the pairing of connectionist and cognitive architectures, conscious and unconscious actions, symbolic and conceptual realizations, emergent and brain-based computing, and automata and subjects. The special authors’ convergent methodology is considered, which is based on the integration of inverse problem-solving on topological spaces, cognitive modelling, quantum field theory, category theory methods, and holonic approaches. It aims to a more purposeful and sustainable human-machine interaction in form of algorithms or requirements, rules of strategic conversations or network brainstorming, and cognitive semantics. The paper addresses the reduction of the impact of AI development on ethics violation. The findings delivered are used to provide perspectives on the shaping of societal, ethical, and normative aspects in the symbiosis between humans and machines. Implementations in real practice are represented.",0.02727272727272727
198,"Social Media Harms as a Trilemma: Asymmetry, Algorithms, and Audacious Design Choices",M. Cheong,ieee,10.1109/ISTAS55053.2022.10227099,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10227099,"Social media has expanded in its use, and reach, since the inception of early social networks in the early 2000s. Increasingly, users turn to social media for keeping up to date with current affairs and information. However, social media is increasingly used to promote disinformation and cause harm. In this contribution, I argue that as information (eco)systems, social media sites are vulnerable from three aspects, each corresponding to the classical 3-tier architecture in information systems: asymmetric networks (data tier); algorithms powering the supposed personalisation for the user experience (application tier); and adverse or audacious design of the user experience and overall information ecosystem (presentation tier) - which can be summarised as the 3 A’s. Thus, the open question remains: how can we ‘fix’ social media? I will unpack suggestions from various allied disciplines- from philosophy to data ethics to social psychology - in untangling the 3A’s above.",0.027210884353741496
199,Co-evolutionary hybrid intelligence,K. Krinkin; Y. Shichkina; A. Ignatyev,ieee,10.1109/DCNA53427.2021.9587002,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9587002,Artificial intelligence is one of the drivers of modern technological development. The current approach to the development of intelligent systems is data centric. It has several limitations: it is fundamentally impossible to collect data for modeling complex objects and processes; training neural networks requires huge computational and energy resources; solutions are not explainable. The article discusses an alternative approach to the development of artificial intelligence systems based on the human-machine hybridization and their co-evolution.,0.02702702702702703
200,"The IEEE Global Initiative on Ethics of Extended Reality (XR) Report--Social and Multi-User Spaces in VR: Trolling, Harassment, and Online Safety",Mangina; Eleni,ieee,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9650825,"The scope of this report is the exploration of ethics-related issues in terms of virtual clones and the right to your identity; the aim is to initiate expert-driven, multidiscipline analysis of the evolving XR Ethics requirements, with a vision to propose solutions, technologies, and standards in future updates. The set of recommendations within this report will hopefully contribute to industry conceptualization of socio-technological issues, highlight concreted recommendations, and lay the groundwork for future technical-standardization activities.",0.02666666666666667
201,"Good Intentions, Bad Inventions: How Employees Judge Pervasive Technologies in the Workplace",M. Constantinides; D. Quercia,ieee,10.1109/MPRV.2022.3217408,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9969460,"Pervasive technologies combined with powerful AI have been recently introduced to enhance work productivity. Yet, some of these technologies are judged to be invasive. To identify which ones, we should understand how employees tend to judge these technologies. We considered 16 technologies that track productivity, and conducted a study in which 131 crowdworkers judged these scenarios. We found that a technology was judged to be right depending on the following three aspects of increasing importance. That is, whether the technology: 1) was currently supported by existing tools; 2) did not interfere with work or was fit for purpose; and 3) did not cause any harm or did not infringe on any individual rights. Ubicomp research currently focuses on how to design better technologies by making them more accurate, or by increasingly blending them into the background. It might be time to design better ubiquitous technologies by unpacking AI ethics as well.",0.026490066225165563
202,Chat Bot Concept for a Social Pain Reliever,W. Wunderlich,ieee,10.1109/ICECET52533.2021.9698554,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9698554,"Communication is the key issue and essential for any success of any artificial intelligence (AI) based social systems, as customers will only accept such systems, when they can act like humans and provide supporting help for them. Social pain is a form of loneliness, which can be partly relieved by talking to people in a chatroom. In this paper we describe the concept of a chatbot how to respond to incoming messages. The concept was evaluated from experience of a chatroom attached to a system of live web cameras. The results show that the response needs to be separated into criteria based on ethics versus those of undetermined social dilemmas. Implications for further mid- or long-term applications are discussed.",0.025210084033613446
203,SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data,F. Boutros; M. Huber; P. Siebke; T. Rieber; N. Damer,ieee,10.1109/IJCB54206.2022.10007961,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10007961,"Recent deep face recognition models proposed in the literature utilized large-scale public datasets such as MS-Celeb-1M and VGGFace2 for training very deep neural networks, achieving state-of-the-art performance on mainstream benchmarks. Recently, many of these datasets, e.g., MS-Celeb-1M and VGGFace2, are retracted due to credible privacy and ethical concerns. This motivates this work to propose and investigate the feasibility of using a privacy-friendly synthetically generated face dataset to train face recognition models. Towards this end, we utilize a class-conditional generative adversarial network to generate class-labeled synthetic face images, namely SFace. To address the privacy aspect of using such data to train a face recognition model, we provide extensive evaluation experiments on the identity relation between the synthetic dataset and the original authentic dataset used to train the generative model. Our reported evaluation proved that associating an identity of the authentic dataset to one with the same class label in the synthetic dataset is hardly possible. We also propose to train face recognition on our privacy-friendly dataset, SFace, using three different learning strategies, multi-class classification, label-free knowledge transfer, and combined learning of multi-class classification and knowledge transfer. The reported evaluation results on five authentic face benchmarks demonstrated that the privacy-friendly synthetic dataset has a high potential to be used for training face recognition models, achieving, for example, a verification accuracy of 91.87% on LFW using multi-class classification and 99.13% using the combined learning strategy. The training code and the synthetic face image dataset are publicly released11https://github.com/fdbtrs/SFace-Privacy-friendly-and-Accurate-Face-Recognition-using-Synthetic-Data.",0.02459016393442623
204,Virtual Reality Data for Predicting Mental Health Conditions,V. Chitale; D. Playne; H. -N. Liang; N. Baghaei,ieee,10.1109/ISMAR-Adjunct57072.2022.00011,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974469,"Mental health conditions pose a significant challenge worldwide. Recently, virtual reality (VR) has gained tremendous popularity and has emerged as a promising technological alternative for addressing a variety of mental health conditions. Virtual reality simulates real-world experiences and generates a large amount of virtual data from participants interacting within the virtual world. Harnessing this VR data is key to better understanding participant behaviour and potentially revealing behaviour correlates of mental health conditions. The discovery of such correlates can enable researchers to design and develop targeted VR scenarios or applications for predicting, monitoring, or improving the therapeutic outcomes for mental health conditions. As a result, in this paper, we propose a novel method of using virtual reality data for predicting the presence of mental health conditions.",0.024
205,AI Ethics and Data Privacy compliance,D. Banciu; C. E. Cîrnu,ieee,10.1109/ECAI54874.2022.9847510,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9847510,"Throughout history, technological evolution has generated less desired side effects with impact on society. In the field of IT&C, there are ongoing discussions about the role of robots within economy, but also about their impact on the labour market. In the case of digital media systems, we talk about misinformation, manipulation, fake news, etc. Issues related to the protection of the citizen's life in the face of technology began more than 25 years ago; In addition to the many messages such as “the citizen is at the center of concern” or, “privacy must be respected”, transmitted through various channels of different entities or companies in the field of ICT, the EU has promoted a number of legislative and normative documents to protect citizens' rights and freedoms.",0.023809523809523808
206,Real-Time 3D Facial Tracking via Cascaded Compositional Learning,J. Lou; X. Cai; J. Dong; H. Yu,ieee,10.1109/TIP.2021.3065819,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9381646,"We propose to learn a cascade of globally-optimized modular boosted ferns (GoMBF) to solve multi-modal facial motion regression for real-time 3D facial tracking from a monocular RGB camera. GoMBF is a deep composition of multiple regression models with each is a boosted ferns initially trained to predict partial motion parameters of the same modality, and then concatenated together via a global optimization step to form a singular strong boosted ferns that can effectively handle the whole regression target. It can explicitly cope with the modality variety in output variables, while manifesting increased fitting power and a faster learning speed comparing against the conventional boosted ferns. By further cascading a sequence of GoMBFs (GoMBF-Cascade) to regress facial motion parameters, we achieve competitive tracking performance on a variety of in-the-wild videos comparing to the state-of-the-art methods which either have higher computational complexity or require much more training data. It provides a robust and highly elegant solution to real-time 3D facial tracking using a small set of training data and hence makes it more practical in real-world applications. We further deeply investigate the effect of synthesized facial images on training non-deep learning methods such as GoMBF-Cascade for 3D facial tracking. We apply three types synthetic images with various naturalness levels for training two different tracking methods, and compare the performance of the tracking models trained on real data, on synthetic data and on a mixture of data. The experimental results indicate that, i) the model trained purely on synthetic facial imageries can hardly generalize well to unconstrained real-world data, ii) involving synthetic faces into training benefits tracking in some certain scenarios but degrades the tracking model's generalization ability. These two insights could benefit a range of non-deep learning facial image analysis tasks where the labelled real data is difficult to acquire.",0.02348993288590604
207,Artificial Intelligence serving National Security: the Spanish case,M. Cousido-González; D. Palacios-Alonso,ieee,10.1109/MECO55406.2022.9797172,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9797172,"In this paper, which is part of a work in progress, we want to analyse and underline the contradiction that arises in the societies of knowledge between the opacity of most AI systems and the transparency that, as a tool for good governance, is been looked for by the most progressive political, social and economic leaders. On the one hand, the risks and threats for the principles of good governance (among them, transparency) derived from the use of AI by governments in sensitive areas such as that of National Security. While AI is to make it easier and more efficient the work of Security Forces, our democracies will become weaker and less credible if the protection of our rights and principles becomes lower than it is thanks to these AI systems, with a risk for autocracies to arise. Thus, our goal should be to produce National Security AI systems that are ethic and legal in a moment of history in which transparency is considered essential for good governance. On the other hand, the use of new disruptive technologies to protect State secrets only makes it more and more difficult to monitor the policies of our governments. The fact is that transparency becomes a reality by exercising the right of access to public information. If we are not allowed to properly monitor our leaders, as a matter of fact protected by smart shields such as those AI systems, we would have taken one step back. Our aims would be carefully identifying the threats to our principles and rights, in the first place, and, secondly suggesting the ethic and legal traits of AI systems to be considered by policymakers that are currently amending State secrets regulations In the case of Spain, a lack of coherence pervades the corresponding legislation, if we take into account that the Official Secrets Law is dated in 1968, nothing to do with the last National Strategy of Security (2021). The lack of consistency between old regulations and new disruptive AI in Spain claims for quick and deep updating.",0.02346041055718475
208,Measuring and Mitigating Bias in AI-Chatbots,H. Beattie; L. Watkins; W. H. Robinson; A. Rubin; S. Watkins,ieee,10.1109/ICAA52185.2022.00023,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9763613,"The use of artificial intelligence (AI) to train conversational chatbots in the nuances of human interactions raises the concern of whether chatbots will demonstrate prejudice similar to that of humans, and thus require bias training. Ideally, a chatbot is void of racism, sexism, or any other offensive speech, however several well-known public instances indicate otherwise (e.g., Microsoft Taybot).In this paper, we explore the mechanisms of how open source conversational chatbots can learn bias, and we investigate potential solutions to mitigate this learned bias. To this end, we developed the Chatbot Bias Assessment Framework to measure bias in conversational chatbots, and then we devised an approach based on counter-stereotypic imagining to reduce this bias. This approach is non-intrusive to the chatbot, since it does not require altering any AI code or deleting any data from the original training dataset.",0.021739130434782608
209,"The Right to Be Forgotten in Artificial Intelligence: Issues, Approaches, Limitations and Challenges",J. L. Lobo; S. Gil-Lopez; J. Del Ser,ieee,10.1109/CAI54212.2023.00085,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10195023,"The Right To Be Forgotten is widely conceived as a fundamental principle of the human being. It has become a subject of capital importance in domains where sensitive information is collected from individuals, requiring the provision of monitoring, governance and audit tools to control where such information is used. Artificial Intelligence models are not an exception to this statement: since they are learned from data, this fundamental right should allow individuals to have their personal information erased from AI-based systems. However, the application of this right is not straightforward: what does erasing mean in the context of a model learned from data? Is it just a matter of removing the concerned data and retraining the models? This manuscript provides a brief overview of these and more issues, proposing a desiderata for technical advances noted in this direction, and outlining research directions for prospective studies.",0.020833333333333332
210,Reflections on Cultural Teaching Modes of Specialty Courses Based on Principal Component Analysis by SPSS,P. Zhang; J. Liang; D. Wang; H. Lui,ieee,10.1109/ICAIE53562.2021.00054,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534566,"By collecting and analyzing the data with SPSS, this paper mainly discusses the ideological and cultural teaching modes and methods of specialty courses. Taking the course of ""fluid mechanics and pump"" as an example data, a route for the implementation of the curriculum education is presented by Principal Component Analysis. According to the data from online survey, the current problems in the ideological and cultural education work in the academies are firstly analyzed, the point that the specialty courses teaching work need to keep up with the rapid development of science and technology in the new era. Secondly, to better carry out cultural education for students, the specialty course education ideas and methods of academies are discussed and designed. This research ideas and conclusions of this paper maybe can provide some useful references to the ideological and political education of the professional courses in academies.",0.020689655172413793
211,Identifying and Addressing Ethical Challenges in Recommender Systems,E. Karakolis; P. F. Oikonomidis; D. Askounis,ieee,10.1109/IISA56318.2022.9904386,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9904386,"Simultaneously with the internet and the artificial intelligence technologies evolution, recommender systems have also evolved and their use has been established across the spectrum of digital life. All content, (information, people, objects etc.) which we process, buy or study, reaches us through a recommender system filter. After all, internet browsing would be impossible without them, since information overload would paralyze any attempt. Nevertheless, many concerning issues identified over the last few years have - with more or less certainty - been connected with the recommender systems activity. Issues of privacy, personal data, fairness and transparency, but also issues concerning personal identity and the proper functioning of society and democracy have risen. In the publication at hand, the recommender systems technology is analyzed with a focus on the different techniques and effectiveness measures employed to address the aforementioned issues. Furthermore, different problematic sides of recommender systems operations are identified and categorized, and a measure of a recommender system’s criticality is developed. Different case studies are presented, under the perspective of criticality, based on the proposed measure. Finally, a series of regulatory actions is proposed. The goal of the latter is the betterment of the systems’ function and the harmonization of their progress with social prosperity.",0.0196078431372549
212,SEN12MS-CR-TS: A Remote-Sensing Data Set for Multimodal Multitemporal Cloud Removal,P. Ebel; Y. Xu; M. Schmitt; X. X. Zhu,ieee,10.1109/TGRS.2022.3146246,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9691348,"About half of all optical observations collected via spaceborne satellites are affected by haze or clouds. Consequently, cloud coverage affects the remote-sensing practitioner’s capabilities of a continuous and seamless monitoring of our planet. This work addresses the challenge of optical satellite image reconstruction and cloud removal by proposing a novel multimodal and multitemporal data set called SEN12MS-CR-TS. We propose two models highlighting the benefits and use cases of SEN12MS-CR-TS: First, a multimodal multitemporal 3-D convolution neural network that predicts a cloud-free image from a sequence of cloudy optical and radar images. Second, a sequence-to-sequence translation model that predicts a cloud-free time series from a cloud-covered time series. Both approaches are evaluated experimentally, with their respective models trained and tested on SEN12MS-CR-TS. The conducted experiments highlight the contribution of our data set to the remote-sensing community as well as the benefits of multimodal and multitemporal information to reconstruct noisy information. Our data set is available at https://patrickTUM.github.io/cloud_removal.",0.019230769230769232
213,Early Warning and Prevention of non-Compliance of Internal Control Information Disclosure based on data Mining,N. Liu; L. Wang,ieee,10.1109/ICAIBD51990.2021.9459079,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9459079,"High quality internal control information disclosure can promote the healthy development of the capital market. This paper selects the Shanghai and Shenzhen A-share listed companies in 2017 as the research object, and selects the data of corporate finance, corporate governance, investor protection, market and executive characteristics and incentives to construct an early warning index system with the combination of financial and non-financial indicators, and uses Bayesian classification, Logistic regression, decision tree and K-proximity learning to predict the non-compliance behavior of internal control information disclosure. The study finds that after feature attribute selection, the prediction accuracy of non-compliance behavior is significantly improved, the highest is logistic regression model; secondly, it is found that non-financial information contributes more than financial information in the prediction process. Therefore, the integrity and self-discipline management of the main body of the enterprise, the external maintenance of high standards of professional ethics, and all-round efforts can jointly build and share a high-quality benign capital market environment.",0.018867924528301886
214,Data Mining Technique for Prediction System of Heart Disease Using Associative Classifications,M. S. Salman; N. N. Shila; K. Hasan; P. Ahmed; M. Keya; S. A. Khushbu; S. R. H. Noori,ieee,10.1109/ICCCNT51525.2021.9579825,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9579825,"In this study, several aspects of the human body have been focused upon. This paper attempts to cast light on pre-and post-pathological conditions, man-machine interactions, human mindset, and ethics of AI. The paper emphasizes the cultural impacts of overeating, profuse drinking, and smoking habits. It uplifts the basic necessity of growing awareness schemes. Patients are seeking treatment in health care centers with the following serious pathological conditions and complications (We exclude the COVID-19 pandemic because it has been adequately publicized by media and press): Heart Attack, Stroke Cancer, Fatty liver & liver cirrhosis. Because of being the leading causes of sudden death prediction of heart attack is very important. Our main focus is to determine the best machine learning method. With optimal parameters, we evaluate the Dataset. Model Accuracy for the heart Attack Machine Learning Model was the highest for the Logistic Regression mode land it was 93.41%. On the contrary, the accuracy for Linear Regression Model was 60.10% which was the least.",0.018404907975460124
215,Intelligent Control of Automated Microelectronic Production Lines Based on Artificial Intelligence,H. Zhang,ieee,10.1109/ICAISC58445.2023.10200046,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10200046,"Artificial intelligence is currently the most popular technology. With the advent of the era of big data, information technology based on artificial intelligence has become a new type of technology capable of most of the human labor force. Its scope of application is mainly in the comprehensive processing of improving efficiency, and those companies that need to improve efficiency do need corresponding technical support. Through artificial intelligence technology, the production line can analyze and predict the production process, so as to optimize and upgrade the production process. At the same time, intelligent production lines can also realize real-time monitoring and analysis of production data through big data analysis technology, thereby improving the reliability and stability of the production process. Automated control and optimization adjustments can also be realized in the production process. Through the intelligent control system, the production line can automatically complete the processing, assembly, testing and other work of the product, and the production process and process parameters can be automatically adjusted according to the production situation, so as to realize the autonomy and intelligence of the production process. This article first introduces the basic framework of artificial intelligence in detail, then applies artificial intelligence to the research of intelligent control of automated microelectronics production lines, conducts data tests on the overall efficiency, and finally uses questionnaires on the production personnel of the waterline and the overall efficiency of the company. It can be shown that artificial intelligence is of great help to improve the efficiency of production lines. Therefore, making good use of artificial intelligence is a very worthy topic for the research of intelligent control of automated microelectronics production lines.",0.01824817518248175
216,Joint and Progressive Subspace Analysis (JPSA) With Spatial–Spectral Manifold Alignment for Semisupervised Hyperspectral Dimensionality Reduction,D. Hong; N. Yokoya; J. Chanussot; J. Xu; X. X. Zhu,ieee,10.1109/TCYB.2020.3028931,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256351,"Conventional nonlinear subspace learning techniques (e.g., manifold learning) usually introduce some drawbacks in explainability (explicit mapping) and cost effectiveness (linearization), generalization capability (out-of-sample), and representability (spatial–spectral discrimination). To overcome these shortcomings, a novel linearized subspace analysis technique with spatial–spectral manifold alignment is developed for a semisupervised hyperspectral dimensionality reduction (HDR), called joint and progressive subspace analysis (JPSA). The JPSA learns a high-level, semantically meaningful, joint spatial–spectral feature representation from hyperspectral (HS) data by: 1) jointly learning latent subspaces and a linear classifier to find an effective projection direction favorable for classification; 2) progressively searching several intermediate states of subspaces to approach an optimal mapping from the original space to a potential more discriminative subspace; and 3) spatially and spectrally aligning a manifold structure in each learned latent subspace in order to preserve the same or similar topological property between the compressed data and the original data. A simple but effective classifier, that is, nearest neighbor (NN), is explored as a potential application for validating the algorithm performance of different HDR approaches. Extensive experiments are conducted to demonstrate the superiority and effectiveness of the proposed JPSA on two widely used HS datasets: 1) Indian Pines (92.98%) and 2) the University of Houston (86.09%) in comparison with previous state-of-the-art HDR methods. The demo of this basic work (i.e., ECCV2018) is openly available at https://github.com/danfenghong/ECCV2018_J-Play.",0.018018018018018018
217,‘Emerging proxies’ in information-rich machine learning: a threat to fairness?,A. J. McLoughney; J. M. Paterson; M. Cheong; A. Wirth,ieee,10.1109/ETHICS57328.2023.10155045,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155045,"Anti-discrimination law in many jurisdictions effectively bans the use of race and gender in automated decision-making. For example, this law means that insurance companies should not explicitly ask about legally protected attributes, e.g., race, in order to tailor their premiums to particular customers. In legal terms, indirect discrimination occurs when a generally neutral rule or variable is used, but significantly negatively affects one demographic group. An emerging example of this concern is inclusion of proxy variables in Machine Learning (ML) models, where neutral variables are predictive of protected attributes. For example, postcodes or zip codes are representative of communities, and therefore racial demographics and social-economic class; i.e., a traditional example of ‘redlining’ pre-dating modern automated techniques [1]. The law struggles with proxy variables in machine learning: indirect discrimination cases are difficult to bring to court, particularly because finding substantial evidence that shows the indirect discrimination to be unlawful is difficult [2]. With more complex machine-learning models being developed for automated decision making, e.g., random forests or state-of-the-art deep neural networks, more data points on customers are accumulated [1], from a wide variety of sources. With such rich data, ML models can produce multiple interconnected correlations - such as that found in single neurons in a neural network, or single decision trees in a random forest - which are predictive of protected attributes, akin to traditional uses of discrete proxy variables. In this poster, we introduce the concept of ""emerging proxies"", that are a combination of several variables, from which the ML model could infer the protected attribute(s) of the individuals in the dataset. This concept differs from the traditional concept of proxies because rather than addressing a single proxy variable, a distribution of interconnected proxies would have to be addressed. Our contribution is to provide evidence for the capacity of complex ML models to identify protected attributes through the correlation of other variables. This correlation is not made explicitly through a discrete one to one relationship between variables, but through a many-to-one relationship. This contribution complements concerns raised in legal analyses of automated decision-making about proxies in ML models leading to indirect discrimination [3]. Our contribution shows that if an ML model contains “emerging proxies” for a protected attribute, the distribution of proxies will be a roadblock when attempting to de-bias the model, limiting the pathways available for addressing potential discrimination caused by the ML model.",0.017676767676767676
218,The IEEE Global Initiative on Ethics of Extended Reality (XR) Report -- Who Owns Our Second Lives: Virtual Clones and the Right to your Identity,,ieee,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622233,"This paper discusses different aspects and issues that arise when identity corresponds to and overlaps with the identity of actual humans. The arguments mostly concern identities in virtual reality since that is where we, as researchers and developers, have the most experience and empirical data. However, most of the argument should be applicable to augmented reality applications as well.",0.01694915254237288
219,Biomass Estimation and Uncertainty Quantification From Tree Height,Q. Song; C. M. Albrecht; Z. Xiong; X. X. Zhu,ieee,10.1109/JSTARS.2023.3271186,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10141562,"We propose a tree-level biomass estimation model approximating allometric equations by LiDAR data. Since tree crown diameter estimation is challenging from spaceborne LiDAR measurements, we develop a model to correlate tree height with biomass on the individual-tree levels employing a Gaussian process regressor. In order to validate the proposed model, a set of 8342 samples on tree height, trunk diameter, and biomass has been assembled. It covers seven biomes globally present. We reference our model to four other models based on both, the Jucker data and our own dataset. Although our approach deviates from standard biomass–height–diameter models, we demonstrate the Gaussian process regression model as a viable alternative. In addition, we decompose the uncertainty of tree biomass estimates into the model- and fitting-based contributions. We verify the Gaussian process regressor has the capacity to reduce the fitting uncertainty down to below 5%. Exploiting airborne LiDAR measurements and a field inventory survey on the ground, a stand-level (or plot-level) study confirms a low relative error of below 1% for our model. The data used in this study are available at https://github.com/zhu-xlab/BiomassUQ.",0.016666666666666666
220,Patch-Level Unsupervised Planetary Change Detection,S. Saha; X. X. Zhu,ieee,10.1109/LGRS.2021.3130862,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9627685,"Change detection (CD) is critical for analyzing data collected by planetary exploration missions, e.g., for identification of new impact craters. However, CD is still a relatively new topic in the context of planetary exploration. Sheer variation of planetary data makes CD much more challenging than in the case of Earth observation (EO). Unlike CD for EO, patch-level decision is preferred in planetary exploration as it is difficult to obtain perfect pixelwise alignment/coregistration between the bi-temporal planetary images. Lack of labeled bi-temporal data impedes supervised CD. To overcome these challenges, we propose an unsupervised CD method that exploits a pretrained feature extractor to obtain bi-temporal deep features that are further processed using global max-pooling to obtain patch-level feature description. Bi-temporal patch-level features are further analyzed based on difference to determine whether a patch is changed. Additionally, a self-supervised method is proposed to estimate the decision boundary between the changed and unchanged patches. Experimental results on three planetary CD datasets from two different planetary bodies (Mars and Moon) demonstrate that the proposed method often outperforms supervised planetary CD methods. Code is available at https://gitlab.lrz.de/ai4eo/cd/-/tree/main/planetaryCDUnsup.",0.016483516483516484
221,Moral Reinforcement Learning Using Actual Causation,T. Herlau,ieee,10.1109/ICCCR54399.2022.9790262,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9790262,"Reinforcement learning systems will to a greater and greater extent make decisions that significantly impact the well-being of humans, and it is therefore essential that these systems make decisions that conform to our expectations of morally good behavior. The morally good is often defined in causal terms, as in whether one's actions have in fact caused a particular outcome, and whether the outcome could have been anticipated. We propose an online reinforcement learning method that learns a policy under the constraint that the agent should not be the cause of harm. This is accomplished by defining cause using the theory of actual causation and assigning blame to the agent when its actions are the actual cause of an undesirable outcome. We conduct experiments on a toy ethical dilemma in which a natural choice of reward function leads to clearly undesirable behavior, but our method learns a policy that avoids being the cause of harmful behavior, demonstrating the soundness of our approach. Allowing an agent to learn while observing causal moral distinctions such as blame, opens the possibility to learning policies that better conform to our moral judgments.",0.016042780748663103
222,Exploring the Reactions of Early Users of ChatGPT to the Tool using Twitter Data: Sentiment and Topic Analyses,A. Tounsi; S. Elkefi; S. L. Bhar,ieee,10.1109/IC_ASET58101.2023.10150870,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10150870,"Recently, large language models have gained considerable interest due to their impressive performance on different tasks. OpenAl's ChatGPT is a revolutionary language model that has quickly become popular among early adopters. Many users have gone so far as to call it a disruptive technology in many different domains. Its large, pre-trained model provides powerful capabilities already being applied to various use cases. Gaining an understanding of the thoughts and feelings of those who are quick to embrace new technologies is essential, as it can offer valuable insights into the technology's potential successes, failures, and other characteristics. In this paper, a mixed-method study was developed using 463,983 tweets from early ChatGPT users. We first apply topic modeling to identify the maj or topics and then conduct an extensive qualitative sentiment analysis. We observed that most people were pleased with the tool, but some expressed apprehension about its potential ethical and legal implications. After its launch, however, the fears were largely alleviated as people began to use it and recognize its benefits for personal and business purposes. It is important to be aware of any new technology's possible drawbacks and use it responsibly.",0.015706806282722512
223,AI Ethics for Sustainable Development Goals,A. M. Astobiza; M. Toboso; M. Aparicio; D. López,ieee,10.1109/MTS.2021.3056294,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9445792,"We live in an era where problems are global in scale (e.g., climate change) and solutions must also be coordinated on a global scale in the international context. The 2030 agenda for sustainable development goals (SDGs) was ratified in 2015 as a continuation of the millennium development goals (MDGs). In this sense, the SDGs, as MDGs were in their day, are a global mechanism that urges governments to coordinate to address global problems. At the core of the SDGs is “to achieve a better and more sustainable future for all.” The SDGs consist in a series of 17 goals with 169 targets which, for the first time, identify the fight against poverty as a necessity for sustainable development. The SDGs consider the ecological, social, and economic dimensions as interdependent for sustainable development. With the progress and advances of artificial intelligence (AI) technologies, many researchers are exploring the possibility of their use to tackle societal problems. This is what many people nowadays call “AI for social good” (AI4SG). The concept behind AI4SG is very simple: AI-powered systems and capabilities applied to improve public welfare [1]. Although there are different forms of classification of AI4SG initiatives (in terms of data, modeling, or decision-making) “projects addressing AI4SG vary significantly” [2] and the AI behind these projects may have been designed for the “good” but, in practice, it could end up going “bad.” More importantly, not everyone would agree on what is a good result. The main motivation for any application of the AI4SG is to solve social problems.",0.01568627450980392
224,Learning Invariant Patterns Based on a Convolutional Neural Network and Big Electroencephalography Data for Subject-Independent P300 Brain-Computer Interfaces,W. Gao; T. Yu; J. -G. Yu; Z. Gu; K. Li; Y. Huang; Z. L. Yu; Y. Li,ieee,10.1109/TNSRE.2021.3083548,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9440400,"A brain-computer interface (BCI) measures and analyzes brain activity and converts this activity into computer commands to control external devices. In contrast to traditional BCIs that require a subject-specific calibration process before being operated, a subject-independent BCI learns a subject-independent model and eliminates subject-specific calibration for new users. However, building subject-independent BCIs remains difficult because electroencephalography (EEG) is highly noisy and varies by subject. In this study, we propose an invariant pattern learning method based on a convolutional neural network (CNN) and big EEG data for subject-independent P300 BCIs. The CNN was trained using EEG data from a large number of subjects, allowing it to extract subject-independent features and make predictions for new users. We collected EEG data from 200 subjects in a P300-based spelling task using two different types of amplifiers. The offline analysis showed that almost all subjects obtained significant cross-subject and cross-amplifier effects, with an average accuracy of more than 80%. Furthermore, more than half of the subjects achieved accuracies above 85%. These results indicated that our method was effective for building a subject-independent P300 BCI, with which more than 50% of users could achieve high accuracies without subject-specific calibration.",0.015544041450777202
225,Bayesian propensity score matching in automotive embedded software engineering,Y. Liu; D. I. Mattos; J. Bosch; H. H. Olsson; J. Lantz,ieee,10.1109/APSEC53868.2021.00031,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9712142,"Randomised field experiments, such as A/B testing, have long been the gold standard for evaluating the value that new software brings to customers. However, running randomised field experiments is not always desired, possible or even ethical in the development of automotive embedded software. In the face of such restrictions, we propose the use of the Bayesian propensity score matching technique for causal inference of observational studies in the automotive domain. In this paper, we present a method based on the Bayesian propensity score matching framework, applied in the unique setting of automotive software engineering. This method is used to generate balanced control and treatment groups from an observational online evaluation and estimate causal treatment effects from the software changes, even with limited samples in the treatment group. We exemplify the method with a proof-of-concept in the automotive domain. In the example, we have a larger control (Nc = 1100) fleet of cars using the current software and a small treatment fleet (Nt = 38), in which we introduce a new software variant. We demonstrate a scenario that shipping of a new software to all users is restricted, as a result, a fully randomised experiment could not be conducted. Therefore, we utilised the Bayesian propensity score matching method with 14 observed covariates as inputs. The results show more balanced groups, suitable for estimating causal treatment effects from the collected observational data. We describe the method in detail and share our configuration. Furthermore, we discuss how can such a method be used for online evaluation of new software utilising small groups of samples.",0.01532567049808429
226,Multitarget Domain Adaptation for Remote Sensing Classification Using Graph Neural Network,S. Saha; S. Zhao; X. X. Zhu,ieee,10.1109/LGRS.2022.3149950,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9706461,"Remote sensing deals with huge variations in geography, acquisition season, and a plethora of sensors. Considering the difficulty of collecting labeled data uniformly representing all scenarios, data-hungry deep learning models are often trained with labeled data in a source domain that is limited in the above-mentioned aspects. Domain adaptation (DA) methods can adapt such model for applying on target domains with different distributions from the source domain. However, most remote sensing DA methods are designed for single-target, thus requiring a separate target classifier to be trained for each target domain. To mitigate this, we propose multitarget DA in which a single classifier is learned for multiple unlabeled target domains. To build a multitarget classifier, it may be beneficial to effectively aggregate features from the labeled source and different unlabeled target domains. Toward this, we exploit coteaching based on the graph neural network that is capable of leveraging unlabeled data. We use a sequential adaptation strategy that first adapts on the easier target domains assuming that the network finds it easier to adapt to the closest target domain. We validate the proposed method on two different datasets, representing geographical and seasonal variation. Code is available at https://gitlab.lrz.de/ai4eo/da-multitarget-gnn/.",0.015306122448979591
227,Detox Loss: Fairness Constraints for Learning With Imbalanced Data,S. Nagpal; M. Singh; R. Singh; M. Vatsa,ieee,10.1109/TBIOM.2022.3222048,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9951384,"Recent studies have highlighted a major caveat in several popular deep learning based face recognition algorithms. Despite their high accuracy, they have shown to exhibit biased behavior by achieving sub-par performance on images belonging to different sub-groups. Such behavior can often lead to unfair predictions, thus presenting a need to develop fairer models with unprejudiced behavior. This research proposes Detox loss, a novel bias invariant feature learning loss function for learning unbiased models. The proposed loss can be used to: (i) learn fairer deep learning classifiers, and (ii) mitigate bias from existing pre-trained networks, especially in the challenging constraint of imbalanced training data with respect to a protected attribute. Conceptually, the Detox loss enforces that the learned features are distinguished based on the task label only, while eliminating any distinction based on the biasing-attribute. This is achieved by incorporating three fairness constraints while training with the traditional classification loss: (i) proposed Exclusion loss, (ii) proposed Inclusion loss, and (iii) proposed Feature-distillation loss. The efficacy of the Detox loss is demonstrated on two facial analysis tasks: (i) age-group prediction and (ii) gender prediction, under the protected attribute of ethnicity for learning fairer models and de-biasing existing models, with varying imbalanced training data distributions. Across two different protocols, three setups, and two tasks, the Detox loss obtains state of the art performance without the need of multi-labeled training data. For example, on the challenging Pilot Parliaments Benchmark (PPB) dataset, the Detox loss obtains a balanced accuracy and  $F_{1}$  score of 96.1% and 96.6%, as compared to the state-of-the-art performance of 94.1% and 93.6%, respectively.",0.015151515151515152
228,A Joint Framework Based on Accountable AI for Driving Behavior Assessment and Backtracking,Y. Gao; S. Zhang; J. Sun; S. Yu; T. Yamamoto; Z. Li; X. Li,ieee,10.1109/ITSC55140.2022.9922536,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9922536,"With the rapid development of Internet of Vehicles (IoV) technology, more vehicles are being equipped with terminals to enable them to be connected to the internet, which provides a new opportunity for the realization of safe driving as well as a new issue on how to assess and backtrack driving behavior by utilizing the On-Board Diagnostic (OBD) data. In this paper, we propose a novel framework to induce the concept of accountable AI to solve the above issue, where we propose a TOPSIS-sort Autoencoder method for the assessment of driving behavior and an interpretable Multiple Rule-based Local Surrogate Model (MuRLoS) to backtrack the driving behaviors, which can not only allow explainability of the assessment, but also make it possible to induce domain expert's knowledge to grant accountability both to the estimation result and to the explanation to convince drivers' behavior change. We evaluate the proposed framework based on 37,000 OBD data that were collected nation-wide and received 5,651 feedbacks from drivers. The results show the framework can provide an accurate driving assessment as well as trustworthy explanations that help the drivers to understand the risky driving behavior, thus leading their behavior to change towards safe driving in the future.",0.01507537688442211
229,Digital Influencer Factory: The Price of Word Authority,A. V. Gorodishchev; A. N. Gorodishcheva; G. P. Kovalev,ieee,10.1109/ComSDS58064.2023.10130358,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10130358,"The traditional process of sorting and selecting information has changed dramatically under the influence of information technology. Influencers have become the new authorities. Until recently, the creation of an influencer proceeded according to the classical scheme: idol - information - expertise - norm - reward/punishment - authority. However, CGI technologies have created a new phenomenon of digital influencers. CGI influencers engage the user's imagination and inspire awe (AWW Inc.). The source of the CGI influencer's power is their ability to utilize media literacy. CGI influencers are embedded in the process of media literacy formation as an authoritative opinion, but this can lead to a blockade of the processes of creative and critical thinking. The user can become dependent on the influencer, downshifting to the level of manual execution, and the influencer can become a new master.",0.014705882352941176
230,IEEE Ontological Standard for Ethically Driven Robotics and Automation Systems,,ieee,10.1109/IEEESTD.2021.9611206,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9611206,"A set of ontologies with different abstraction levels that contain concepts, definitions, axioms, and use cases that assist in the development of ethically driven methodologies for the design of robots and automation systems is established by this standard. It focuses on the robotics and automation domain without considering any particular applications and can be used in multiple ways, for instance, during the development of robotics and automation systems as a guideline or as a reference “taxonomy” to enable clear and precise communication among members from different communities that include robotics and automation, ethics, and correlated areas. Users of this standard need to have a minimal knowledge of formal logics to understand the axiomatization expressed in Common Logic Interchange Format. Additional information can be found at https://standards.ieee.org/industry-connections/ec/autonomous-systems.html. (The PDF of this standard is available in the IEEE GET program at https://ieeexplore.ieee.org/browse/standards/get-program/page/series?id=93)",0.014285714285714285
231,Individuality and Fairness in Public Health Surveillance Technology: A Survey of User Perceptions in Contact Tracing Apps,E. Hohma; R. Burnell; C. C. Corrigan; C. Luetge,ieee,10.1109/TTS.2022.3211073,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9906425,"Machine learning algorithms are playing an increasingly important role in public health measures, accelerated by the Covid-19 pandemic. It is therefore vital that machine learning algorithms are applied in ways that are generally considered fair. However, the question of how to define fairness in a public health context is still an open one. In this study, we investigated people’s attitudes towards two ways of defining fairness in the context of Covid-19 contact tracing apps. In the first, ‘high-individuality’ approach, the likelihood of an algorithm asking a person to self-isolate would depend on the person’s individual characteristics, such as their risk of spreading the virus through regular contacts. In the second ‘low individuality’ approach, these individual characteristics would not be used to come to a decision. For each approach, participants rated its fairness, overall quality, and their privacy concerns, and answered questions about basic psychological need satisfaction. Participants rated the high-individuality approach as fairer and better overall compared to the low-individuality approach, despite having greater privacy concerns. Further, we found a strong correlation between the participants’ fairness perceptions and their overall impression of the tracking tool. Together, these findings suggest that people prefer individualised approaches in some contexts and perceive them as fairer. However, policy makers should consider the privacy trade-off of employing such measures.",0.014018691588785047
232,Collection and Analysis of Narratives for a Values Charter of the Italian Society for Hospital Pharmacy,D. Saetta; L. Bellante; M. V. Lacaita; M. E. Faggiano; D. Scala; V. Franzoni,ieee,10.1109/WI-IAT55865.2022.00151,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10101875,"In recent years, the field of Narrative Pharmacy was introduced, which particularly addresses the pharmacist not only to guide a relationship of listening to and caring for the patient but also to strengthen and motivate toward the profession, improve relationships with colleagues, enhance the ability to teamwork, and understand emotions. In this paper, we report the analysis behind the construction of the Value Chart from the personal narratives of members of the Italian Society of Hospital Pharmacy. Each member’s subjective professional experiences and their own view of themselves within society were collected through a semi-structured interview. Personal thinking, including experiences, feelings, opinions, desires, and regrets was classified by objective methods, from which main concepts were extracted for the Value Chart. The feedback to the survey, including activities during the Covid-19 pandemic management, is classified according to the analytical methods of Kleinman, Frank, Bury and Launer-Robinson. Regarding sentiment analysis, the emotional and subjective context of the text provides an ideal baseline to validate the result. The analysis was implemented using neural networks trained on dictionaries and natural language (i.e., Tweets). The originality of the work lies in the fact that generally value charters are built on a Society’s values. In contrast, in this case, individual contributions were gathered to complement the ethical values on which the society is founded.",0.013761467889908258
233,Perspective on mHealth Concepts to Ensure Users’ Empowerment–From Adverse Event Tracking for COVID-19 Vaccinations to Oncological Treatment,J. D. Schwab; J. Schobel; S. D. Werle; A. Fürstberger; N. Ikonomi; R. Szekely; P. Thiam; R. Hühne; N. Jahn; R. Schuler; P. Kuhn; M. Holderried; F. Steger; M. Reichert; U. X. Kaisers; A. M. R. Kestler; T. Seufferlein; H. A. Kestler,ieee,10.1109/ACCESS.2021.3087315,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9448032,"Mobile applications have increasingly entered the healthcare sector. Besides being daily companions, so-called mHealth applications have the potential to enable individuals to collect data, document issues, and share them with healthcare professionals to better adjust medical treatment, side effects, or quality of life. While patient empowerment should be a paramount goal, the setup of these applications in a reliable and communication-effective way is under discussion. In particular, including mHealth applications in the clinical practice routine is crucial to boost their development. Security concerns are of utmost importance as such applications deal with personal data. Considering the sensitive nature of many of the involved data, a trustworthy transfer protocol to the respective health care providers is essential to convince potential users. On the same grounds, healthcare providers, which represent another major stakeholder, might be skeptical of utilizing mHealth applications. This issue is often not prioritized by app developers, and there is a multitude of apps lacking clear and transparent data transfer concepts with a focus on both security and usability. In the following, we present and discuss two different approaches for managing and reporting sensitive clinical information and their secure inter-sectoral transfer. Both use cases are currently implemented into clinical practice, and their applicability is under constant evaluation. Besides, to empower inter-sectoral communication, both approaches have been developed in close collaboration with healthcare providers to maximize both communication and effectiveness of the mHealth applications. Based on our work, we conclude that while mHealth applications can be important in many aspects of improving health care, there are often significant limitations of mHealth-based communication, which can hamper its integration in clinical settings. To overcome these limitations, we show how to apply and re-elaborate on existing security and communication strategies. Finally, we highlight how these approaches can strengthen both patient and healthcare professionals' empowerment.",0.013333333333333334
234,IEEE Standard for Transparent Employer Data Governance,,ieee,10.1109/IEEESTD.2021.9618905,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9618905,"Specific methodologies to help employers in accessing, collecting, storing, utilizing, sharing, and destroying employee data are described in this standard. Specific metrics and conformance criteria regarding these types of uses from trusted global partners and how third parties and employers can meet them are provided in this standard. Certification processes, success criteria, and execution procedures are not within the scope of this standard. (The PDF of this standard is available in the GET program at https://ieeexplore.ieee.org/browse/standards/get-program/page/series?id=93)",0.013157894736842105
235,An Advanced Dirichlet Prior Network for Out-of-Distribution Detection in Remote Sensing,J. Gawlikowski; S. Saha; A. Kruspe; X. X. Zhu,ieee,10.1109/TGRS.2022.3140324,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9668955,"Remote sensing deals with a plethora of sensors, a large number of classes/categories, and a huge variation in geography. Due to the difficulty of collecting labeled data uniformly representing all scenarios, data-hungry deep learning models are often trained with labeled data in a source domain that is limited in the above-mentioned aspects. However, during the test/inference phase, such deep learning models are often subjected to a distributional shift, also called out-of-distribution (OOD) samples, in the form of unseen classes, geographic differences, and multisensor differences. Deep learning models can behave in an unexpected manner when subjected to such distributional uncertainties. Vulnerability to OOD data severely reduces the reliability of deep learning models and trusting on such predictions in the absence of any reliability indicator may lead to wrong policy decisions or mishaps in time-bound remote sensing applications. Motivated by this, in this work, we propose a Dirichlet prior network-based model to quantify the distributional uncertainty of deep learning-based remote sensing models. The approach seeks to maximize the representation gap between the in-domain and OOD examples for better segregation of OOD samples at test time. Extensive experiments on several remote sensing image classification datasets demonstrate that the proposed model can quantify distributional uncertainty. To the best of our knowledge, this is the first work to elaborately study distributional uncertainty in context of remote sensing. The codes are publicly available at https://gitlab.lrz.de/ai4eo/Uncertainty/-/tree/main/DPN-RS.",0.013100436681222707
236,How Information Technology Literacy Moderated Factors Affecting Quality of Computer-Based Audit,A. S. Lin Lindawati; B. L. Handoko,ieee,10.1109/ICORIS56080.2022.10031571,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10031571,"The times require auditors to change, auditors no longer carry out the audit process using a manual system, but must switch to computer-based auditing. Especially in the era of the Covid-19 pandemic, which forced auditors to conduct remote audits, which of course had to be computerbased. Our research focuses on what factors can influence computer-based audit quality and what factors can moderate these factors. Our research uses independent variables, namely remote audit implementation, auditor performance and professionalism and in addition to using information technology literacy as a moderating variable. Our research is a quantitative study, using primary data distributed through questionnaires to auditors working in public accounting firms. For statistical data processing, we use the ordinary least square. The results of our study indicate that remote audit implementation, auditor performance and professionalism have a significant effect on computer-based audit quality and information technology literacy is able to moderate and strengthen the influence of these three variables.",0.01282051282051282
237,Dynamic Behavior of Threshold Voltage and  $\textit{I}_{\text{D}}$ – $\textit{V}_{\text{DS}}$  Kink in AlGaN/GaN HEMTs Due to Poole–Frenkel Effect,Z. Gao; C. D. Santi; F. Rampazzo; M. Saro; M. Fornasier; G. Meneghesso; M. Meneghini; A. Chini; G. Verzellesi; E. Zanoni,ieee,10.1109/TED.2023.3326781,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10302314,"The kink effect in field-effect transistors (FETs) consists in a sudden increase in drain current,  $\textit{I}_{\text{D}}$ , during a drain voltage sweep and leading to a higher  $\textit{I}_{\text{D}}$  saturation value. We report new experimental data concerning the dynamic behavior of the “kink” in AlGaN/GaN HEMTs and correlate them with deep levels. The results demonstrate the role of the Poole–Frenkel effect in determining the occurrence of the kink and identify the experimental conditions that make it observable.",0.012658227848101266
238,Breast Cancer Detection Using Multimodal Time Series Features From Ultrasound Shear Wave Absolute Vibro-Elastography,Y. Shao; H. S. Hashemi; P. Gordon; L. Warren; J. Wang; R. Rohling; S. Salcudean,ieee,10.1109/JBHI.2021.3103676,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9511105,"In shear wave absolute vibro-elastography (S-WAVE), a steady-state multi-frequency external mechanical excitation is applied to tissue, while a time-series of ultrasound radio-frequency (RF) data are acquired. Our objective is to determine the potential of S-WAVE to classify breast tissue lesions as malignant or benign. We present a new processing pipeline for feature-based classification of breast cancer using S-WAVE data, and we evaluate it on a new data set collected from 40 patients. Novel bi-spectral and Wigner spectrum features are computed directly from the RF time series and are combined with textural and spectral features from B-mode and elasticity images. The Random Forest permutation importance ranking and the Quadratic Mutual Information methods are used to reduce the number of features from 377 to 20. Support Vector Machines and Random Forest classifiers are used with leave-one-patient-out and Monte Carlo cross-validations. Classification results obtained for different feature sets are presented. Our best results (95% confidence interval, Area Under Curve = 95%±1.45%, sensitivity = 95%, and specificity = 93%) outperform the state-of-the-art reported S-WAVE breast cancer classification performance. The effect of feature selection and the sensitivity of the above classification results to changes in breast lesion contours is also studied. We demonstrate that time-series analysis of externally vibrated tissue as an elastography technique, even if the elasticity is not explicitly computed, has promise and should be pursued with larger patient datasets. Our study proposes novel directions in the field of elasticity imaging for tissue classification.",0.012448132780082987
239,Transdisciplinarity as a Learning Challenge: Student Experiences and Outcomes in an Innovative Course on Wearable and Collaborative Robotics,E. Kilic-Bebek; K. Nizamis; M. Vlutters; O. Bebek; Z. G. Karapars; R. Unal; D. Yilmaz; B. Ugurlu,ieee,10.1109/TE.2022.3229201,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9998574,"Contribution: This study provides evidence for the benefit of short online courses for the transdisciplinary competence development of graduate students. It shows the significant challenges students face while learning, and provides instructional recommendations to improve students’ learning quality and professionalism. Background: Developing wearable and collaborative robots require industry collaboration and transdisciplinary competence. Industry’s involvement in long-term programs is becoming infeasible, and the nature of transdisciplinary learning has not been explored to inform instructional practices. Intended Outcomes: This study aimed to provide instructional recommendations based on an in-depth examination of a diverse group of graduate students’ learning and teamwork experiences as well as outcomes in a 5-day online transdisciplinary course. Application Design: Thirty-one graduate students of engineering, industrial design, and health fields from four countries participated in online mixed-discipline instructional sessions and teams to address a real industry challenge. A mixed-methods approach was used to examine students’ experiences and learning outcomes based on a competence measure, session participation data, student journal entries, team progress reports, team elaboration visuals, and final team presentations. Findings: Students’ knowledge of industrial design, medical considerations, ethics and standards, effective teamwork, and self-regulated learning were increased. Students’ high motivation helped them deal with the challenges involved. Daily student journals, team reports, and visual elaboration tools were found to be beneficial for determining the challenges and learning quality. The observed student progress within five days is promising, making it worthwhile to further explore the benefits of short online courses for increasing graduates’ readiness and establishing university-industry collaborations in education.",0.01195219123505976
240,Noncontact Infant Apnea Detection for Hypoxia Prevention With a K-Band Biomedical Radar,L. Wen; S. Dong; Y. Wang; C. Gu; Z. Tang; Z. Liu; Y. Wang; J. Mao,ieee,10.1109/TBME.2023.3325468,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10287606,"Annually, a significant number of premature infants suffer from apnea, which can easily cause a drop in oxygen saturation levels, leading to hypoxia. However, infant cardiopulmonary monitoring using conventional methods often necessitates skin contact, and they are not suitable for long-term monitoring. This paper introduces a non-contact technique for infant cardiopulmonary monitoring and an adjustable apnea detection algorithm. These are developed using a custom-designed K-band continuous-wave biomedical radar sensor system, which features a DC-coupled adaptive digital tuning function. By using radar technology to detect chest motions without physical contact, it is feasible to extract significant biological information regarding an infant's respiration and heartbeat. The proposed algorithm utilizes an adaptively adjusted threshold and personalized apnea warning time to automatically measure the total number of apneic events and their respective durations. Experiments have been conducted in clinical environment, demonstrating that both the accurate cardiopulmonary signals and the apneas of varying durations can be effectively monitored using this method, which suggest that the proposed technique has potential applications both inside and outside of clinical settings.",0.011627906976744186
241,Endmember Bundle Extraction Based on Multiobjective Optimization,R. Liu; X. Zhu,ieee,10.1109/TGRS.2020.3037249,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9268973,"A number of endmember extraction methods have been developed to identify pure pixels in hyperspectral images (HSIs). The majority of them use only one spectrum to represent one kind of material, which ignores the spectral variability problem that particularly characterizes a HSI with high spatial resolution. Only a few algorithms have been developed to identify multiple endmembers representing the spectral variability within each class, called endmember bundle extraction (EBE). This article introduces multiobjective particle swarm optimization for the identification of multiple endmember spectra with variability. Unlike existing convex geometry-based EBE methods, which operate on a single geometry of the dataspace, the proposed method divides the observed data into subsets along the spectral dimension and simultaneously operates on multiple dataspaces to obtain candidate endmembers based on multiobjective particle swarm optimization. The candidate endmembers are then refined by spatial post-processing and sequential forward floating selection to produce the final result. Experiments are conducted on both synthetic and real hyperspectral data to demonstrate the effectiveness of the proposed method in comparison with several state-of-the-art methods.",0.011627906976744186
242,Detecting Changes by Learning No Changes: Data-Enclosing-Ball Minimizing Autoencoders for One-Class Change Detection in Multispectral Imagery,L. Mou; Y. Hua; S. Saha; F. Bovolo; L. Bruzzone; X. X. Zhu,ieee,10.1109/TGRS.2022.3200985,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870684,"Change detection is a long-standing and challenging problem in remote sensing. Very often, features about changes are difficult to model beforehand, thus making the collection of changed samples a challenging task. In comparison, it is much easier to collect numerous no-change samples. It is possible to define a change detection approach using only easily available annotated no-change samples, which we henceforth call one-class change detection. Autoencoder networks being trained on no-change data are natural candidates for addressing this task due to their superior performance when compared with other one-class classification models. However, the autoencoders usually suffer from the problem of overgeneralization, i.e., they tend to generalize too well, thus risking properly reconstructing changed samples. In this article, we propose a novel data-enclosing-ball minimizing autoencoder (DebM-AE) that is trained with dual objectives—a reconstruction error criterion and a minimum volume criterion. The network learns a compact latent space, where encodings of no-change samples have low intraclass variance, which as counterpart has the identification of changed instances. We conducted extensive experiments on three real-world datasets. Results demonstrate advantages of the proposed method over other competitors. We make our data and code publicly available (https://gitlab.lrz.de/ai4eo/reasoning/DebM-AE; https://github.com/lcmou/DebM-AE).",0.010416666666666666
243,A Taxonomy of Uncertainty Events in Visual Analytics,C. Gillmann; R. G. C. Maack; F. Raith; J. F. Pérez; G. Scheuermann,ieee,10.1109/MCG.2023.3299297,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10224065,"Visual analytics (VA) has become a standard tool to process and analyze data visually to generate novel insights. Unfortunately, each component can introduce uncertainty in the visual analytics process. These uncertainty events can originate from many effects and need to be differentiated. In this work, we propose a taxonomy of potential uncertainty events in the visual analytics cycle. Here, we structure the taxonomy along the components included in the visual analytics cycle. Based on this taxonomy, we provide a list of dependencies between these events. At last, we show how to use our taxonomy by providing a real-world example.",0.010101010101010102
244,Inter-Subject Domain Adaptation for CNN-Based Wrist Kinematics Estimation Using sEMG,T. Bao; S. A. R. Zaidi; S. Xie; P. Yang; Z. -Q. Zhang,ieee,10.1109/TNSRE.2021.3086401,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9446851,"Recently, convolutional neural network (CNN) has been widely investigated to decode human intentions using surface Electromyography (sEMG) signals. However, a pre-trained CNN model usually suffers from severe degradation when testing on a new individual, and this is mainly due to domain shift where characteristics of training and testing sEMG data differ substantially. To enhance inter-subject performances of CNN in the wrist kinematics estimation, we propose a novel regression scheme for supervised domain adaptation (SDA), based on which domain shift effects can be effectively reduced. Specifically, a two-stream CNN with shared weights is established to exploit source and target sEMG data simultaneously, such that domain-invariant features can be extracted. To tune CNN weights, both regression losses and a domain discrepancy loss are employed, where the former enable supervised learning and the latter minimizes distribution divergences between two domains. In this study, eight healthy subjects were recruited to perform wrist flexion-extension movements. Experiment results illustrated that the proposed regression SDA outperformed fine-tuning, a state-of-the-art transfer learning method, in both single-single and multiple-single scenarios of kinematics estimation. Unlike fine-tuning which suffers from catastrophic forgetting, regression SDA can maintain much better performances in original domains, which boosts the model reusability among multiple subjects.",0.010050251256281407
245,Noise Audits Improve Moral Foundation Classification,N. Mokhberian; F. R. Hopp; B. Harandizadeh; F. Morstatter; K. Lerman,ieee,10.1109/ASONAM55673.2022.10068681,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10068681,"Morality plays an important role in culture, identity, and emotion. Recent advances in natural language processing have shown that it is possible to classify moral values expressed in text at scale. Morality classification relies on human annotators to label the moral expressions in text, which provides training data to achieve state-of-the-art performance. However, these annotations are inherently subjective and some of the instances are hard to classify, resulting in noisy annotations due to error or lack of agreement. The presence of noise in training data harms the classifier's ability to accurately recognize moral foundations from text. We propose two metrics to audit the noise of annotations. The first metric is entropy of instance labels, which is a proxy measure of annotator disagreement about how the instance should be labeled. The second metric is the silhouette coefficient of a label assigned by an annotator to an instance. This metric leverages the idea that instances with the same label should have similar latent representations, and deviations from collective judgments are indicative of errors. Our experiments on three widely used moral foundations datasets show that removing noisy annotations based on the proposed metrics improves classification performance.11Our code can be found at: https://github.com/negar-mokhberian/noise-audits.",0.010050251256281407
246,SAR Tomography via Nonlinear Blind Scatterer Separation,Y. Wang; X. X. Zhu,ieee,10.1109/TGRS.2020.3022209,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9200699,"Layover separation has been fundamental to many synthetic aperture radar applications, such as building reconstruction and biomass estimation. Retrieving the scattering profile along the mixed dimension (elevation) is typically solved by inversion of the synthetic aperture radar (SAR) imaging model, a process known as SAR tomography. This article proposes a nonlinear blind scatterer separation method to retrieve the phase centers of the layovered scatterers, avoiding the computationally expensive tomographic inversion. We demonstrate that conventional linear separation methods, for example, principle component analysis (PCA), can only partially separate the scatterers under good conditions. These methods produce systematic phase bias in the retrieved scatterers due to the nonorthogonality of the scatterers' steering vectors, especially when the intensities of the sources are similar or the number of images is low. The proposed method artificially increases the dimensionality of the data using kernel PCA, hence mitigating the aforementioned limitations. In the processing, the proposed method sequentially deflates the covariance matrix using the estimate of the brightest scatterer from kernel PCA. Simulations demonstrate the superior performance of the proposed method over conventional PCA-based methods in various respects. Experiments using TerraSAR-X data show an improvement in height reconstruction accuracy by a factor of one to three, depending on the used number of looks.",0.00966183574879227
247,Self-Supervised Multisensor Change Detection,S. Saha; P. Ebel; X. X. Zhu,ieee,10.1109/TGRS.2021.3109957,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9538396,"Most change detection (CD) methods assume that prechange and postchange images are acquired by the same sensor. However, in many real-life scenarios, e.g., natural disasters, it is more practical to use the latest available images before and after the occurrence of incidence, which may be acquired using different sensors. In particular, we are interested in the combination of the images acquired by optical and synthetic aperture radar (SAR) sensors. SAR images appear vastly different from the optical images even when capturing the same scene. Adding to this, CD methods are often constrained to use only target image-pair, no labeled data, and no additional unlabeled data. Such constraints limit the scope of traditional supervised machine learning and unsupervised generative approaches for multisensor CD. The recent rapid development of self-supervised learning methods has shown that some of them can even work with only few images. Motivated by this, in this work, we propose a method for multisensor CD using only the unlabeled target bitemporal images that are used for training a network in a self-supervised fashion by using deep clustering and contrastive learning. The proposed method is evaluated on four multimodal bitemporal scenes showing change, and the benefits of our self-supervised approach are demonstrated. Code is available at https://gitlab.lrz.de/ai4eo/cd/-/tree/main/sarOpticalMultisensorTgrs2021.",0.00966183574879227
248,Exploring the potential for use of AI to help researchers improve their research funding relevance and performance,O. Spyroglou; C. Yildirim; A. Koumpis,ieee,10.1109/TransAI51903.2021.00025,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9565634,"Researchers and scientists face globally, and parallel to their core research activities, increased pressure to successfully lead or participate in fundraising activities. The field has been experiencing fierce competition with success rates of proposals falling dramatically down, while the complexity of the funding instruments and the need for acquiring a wide understanding of issues related to impacts, research priorities in connection to wider national and transnational (e.g. EU-wide) policy aspects, increases discomfort levels for the individual researchers and scientists. In the paper we suggest the use of transdisciplinary AI tools to support (semi-)automation of several steps of the application and proposal preparation processes. (Abstract)",0.009615384615384616
249,HTC-DC Net: Monocular Height Estimation From Single Remote Sensing Images,S. Chen; Y. Shi; Z. Xiong; X. X. Zhu,ieee,10.1109/TGRS.2023.3321255,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10294289,"Three-dimensional geoinformation is of great significance for understanding the living environment; however, 3-D perception from remote sensing data, especially on a large scale, is restricted, mainly due to the high costs of 3-D sensors such as light detection and ranging (LiDAR). To tackle this problem, we propose a method for monocular height estimation from optical imagery, which is currently one of the richest sources of remote sensing data. As an ill-posed problem, monocular height estimation requires well-designed networks for enhanced representations to improve the performance. Moreover, the distribution of height values is long-tailed with the low-height pixels, e.g., the background (BG), as the head, and thus, trained networks are usually biased and tend to underestimate building heights. To solve the problems, instead of formalizing the problem as a regression task, we propose HTC-DC Net following the classification–regression paradigm, with the head-tail cut (HTC) and the distribution-based constraints (DCs) as the main contributions. HTC-DC Net is composed of the backbone network as the feature extractor, the HTC-AdaBins module, and the hybrid regression process. The HTC-AdaBins module serves as the classification phase to determine bins adaptive to each input image. It is equipped with a vision transformer (ViT) encoder to incorporate local context with holistic information and involves an HTC to address the long-tailed problem in monocular height estimation for balancing the performances of foreground (FG) and BG pixels. The hybrid regression process does the regression via the smoothing of bins from the classification phase, which is trained via DCs. The proposed network is tested on three datasets of different resolutions, namely ISPRS Vaihingen (0.09 m), Data Fusion Contest 19 (DFC19) (1.3 m), and Global Building Height (GBH) (3 m). The experimental results show the superiority of the proposed network over existing methods by large margins. Extensive ablation studies demonstrate the effectiveness of each design component. The codes and trained models are published at https://github.com/zhu-xlab/HTC-DC-Net.",0.009584664536741214
250,Exploring Transformer and Multilabel Classification for Remote Sensing Image Captioning,H. Kandala; S. Saha; B. Banerjee; X. X. Zhu,ieee,10.1109/LGRS.2022.3198234,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9855519,"High-resolution remote sensing images are now available with the progress of remote sensing technology. With respect to popular remote sensing tasks, such as scene classification, image captioning provides comprehensible information about such images by summarizing the image content in human-readable text. Most existing remote sensing image captioning methods are based on deep learning-based encoder–decoder frameworks, using convolutional neural network or recurrent neural network as the backbone of such frameworks. Such frameworks show a limited capability to analyze sequential data and cope with the lack of captioned remote sensing training images. Recently introduced Transformer architecture exploits self-attention to obtain superior performance for sequence-analysis tasks. Inspired by this, in this work, we employ a Transformer as an encoder–decoder for remote sensing image captioning. Moreover, to deal with the limited training data, an auxiliary decoder is used that further helps the encoder in the training process. The auxiliary decoder is trained for multilabel scene classification due to its conceptual similarity to image captioning and capability of highlighting semantic classes. To the best of our knowledge, this is the first work exploiting multilabel classification to improve remote sensing image captioning. Experimental results on the University of California (UC)-Merced caption dataset show the efficacy of the proposed method. The implementation details can be found in https://gitlab.lrz.de/ai4eo/captioningMultilabel.",0.009478672985781991
251,Unsupervised Single-Scene Semantic Segmentation for Earth Observation,S. Saha; M. Shahzad; L. Mou; Q. Song; X. X. Zhu,ieee,10.1109/TGRS.2022.3174651,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9773162,"Earth observation data have huge potential to enrich our knowledge about our planet. An important step in many Earth observation tasks is semantic segmentation. Generally, a large number of pixelwise labeled images are required to train deep models for supervised semantic segmentation. On the contrary, strong intersensor and geographic variations impede the availability of annotated training data in Earth observation. In practice, most Earth observation tasks use only the target scene without assuming availability of any additional scene, labeled or unlabeled. Keeping in mind such constraints, we propose a semantic segmentation method that learns to segment from a single scene, without using any annotation. Earth observation scenes are generally larger than those encountered in typical computer vision datasets. Exploiting this, the proposed method samples smaller unlabeled patches from the scene. For each patch, an alternate view is generated by simple transformations, e.g., addition of noise. Both views are then processed through a two-stream network and weights are iteratively refined using deep clustering, spatial consistency, and contrastive learning in the pixel space. The proposed model automatically segregates the major classes present in the scene and produces the segmentation map. Extensive experiments on four Earth observation datasets collected by different sensors show the effectiveness of the proposed method. Implementation is available at https://gitlab.lrz.de/ai4eo/cd/-/tree/main/unsupContrastiveSemanticSeg.",0.009478672985781991
252,MultiScene: A Large-Scale Dataset and Benchmark for Multiscene Recognition in Single Aerial Images,Y. Hua; L. Mou; P. Jin; X. X. Zhu,ieee,10.1109/TGRS.2021.3110314,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9537917,"Aerial scene recognition is a fundamental research problem in interpreting high-resolution aerial imagery. Over the past few years, most studies focus on classifying an image into one scene category, while in real-world scenarios, it is more often that a single image contains multiple scenes. Therefore, in this article, we investigate a more practical yet underexplored task—multiscene recognition in single images. To this end, we create a large-scale dataset, called MultiScene, composed of 100 000 unconstrained high-resolution aerial images. Considering that manually labeling such images is extremely arduous, we resort to low-cost annotations from crowdsourcing platforms, e.g., OpenStreetMap (OSM). However, OSM data might suffer from incompleteness and incorrectness, which introduce noise into image labels. To address this issue, we visually inspect 14 000 images and correct their scene labels, yielding a subset of cleanly annotated images, named MultiScene-Clean. With it, we can develop and evaluate deep networks for multiscene recognition using clean data. Moreover, we provide crowdsourced annotations of all images for the purpose of studying network learning with noisy labels. We conduct experiments with extensive baseline models on both MultiScene-Clean and MultiScene to offer benchmarks for multiscene recognition in single images and learning from noisy labels for this task, respectively. To facilitate progress, we make our dataset and trained models available on https://gitlab.lrz.de/ai4eo/reasoning/multiscene.",0.009389671361502348
253,Revolutionizing Brain Tumour Prediction: A Pioneering GAN-based Framework for Synthetic Data Generation,G. Kumpatla; H. Veresi; B. S. P; S. Abhishek; A. T,ieee,10.1109/I-SMAC58438.2023.10290627,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10290627,"Medical analysis is a key component of contemporary healthcare since it helps doctors diagnose patients accurately to plan and track their treatments. Accurate identification of brain tumors is essential for doctors to treat patients swiftly and efficiently. This research investigates a novel approach to overcome the constraints imposed by scarce and sensitive medical data, generating synthetic images of brain tumors using Generative Adversarial Networks (GANs). The proposed method has the potential to enhance activities involving medical processing, which will aid in making diagnoses and formulating treatment plans. The preliminary findings demonstrate its potential relevance to a wider variety of medical processing tasks, demonstrating that this augmentation method yields significant benefits.",0.00909090909090909
254,Deep Learning Techniques in Estimating Ankle Joint Power Using Wearable IMUs,A. Barua; U. Zakia; C. Menon; X. Jiang,ieee,10.1109/ACCESS.2021.3085660,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9446169,"Estimating ankle joint power can be used to identify gait abnormalities, which is usually achieved by employing a complicated biomechanical model using heavy equipment settings. This paper demonstrates deep learning approaches to estimate ankle joint power from two Inertial Measurement Unit (IMU) sensors attached at foot and shank. The purpose of this study was to investigate deep learning models in estimating ankle joint power in practical scenarios, in terms of variance in walking speeds, reduced number of extracted features and inter-subject model adaption. IMU data was collected from nine healthy participants during five walking trials at different speeds on a force-plate-instrumented treadmill while an optical motion tracker was used as ground truth. Three state-of-the-art deep neural architectures, namely Long Short-Term Memory (LSTM), Convolutional Neural Network (CNN) and, fusion of CNN and LSTM (CNN-LSTM), were developed, trained, and evaluated in predicting ankle joint power by extracting few simple, meaningful features. The proposed architectures were found efficient and promising with higher estimation accuracies (correlation coefficient, R > 0.92 and adjusted R-squared value > 83%) and lower errors (mean squared error <; 0.06, and mean absolute error <; 0.13) in inter-participant evaluations. Performance evaluations among the three deep regressors showed that LSTM performed comparatively better. Lower standard deviations in mean squared error (0.029) and adjusted R-squared value (5.5%) proved the proposed model's efficiency for all participants.",0.008968609865470852
255,A Fully Connected Quantum Convolutional Neural Network for Classifying Ischemic Cardiopathy,U. Ullah; A. G. O. Jurado; I. D. Gonzalez; B. Garcia-Zapirain,ieee,10.1109/ACCESS.2022.3232307,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9999181,"The prevalence of heart diseases is rising quickly throughout the world, which has an impact on both the world economy and public health. According to the recent statistical survey reports, the increasing mortality rate is due to high blood pressure, high cholesterol, the use of tobacco, obesity, and an inconsistent pulse rate. It is difficult and time-consuming to investigate the various variations of these factors and their impact on Coronary Artery Disease (CAD). Therefore, it is necessary to use modern approaches to diagnose the disease early and minimize the mortality rate. The fields of machine learning and data mining have a wide research dimension and various novel techniques that could help in the prediction of CAD in its early stages and identify their patterns and behaviors in a huge amount of data. The results of such predictions will aid the clinical staff in decision making and early diagnosis. In such a scenario, we proposed a quantum version of the Fully Convolutional Neural Network (FCQ-CNN) for Ischemic Heart Disease (IHD) classification. The proposed model evaluates the quantum circuit-based technique that was inspired by convolutional neural networks, a very successful machine learning model. This method provides  $O(log (n))$  depth for  $n$  qubits, reducing the number of parameters and allowing for effective training and testing of real quantum devices. The model has been evaluated by considering the IHD dataset after the data has been cleaned and filtered through the Maximally Relevant Minimally Redundancy (MRMR) filter. For dimension reduction, a Support Vector Machine along with Recursive Feature Elimination (SVM-RFE) has been considered. Initially, the model is tested with 20% of the whole dataset and gets the promising results of a testing accuracy of 84.6% with a testing loss of 0.28. By taking into account the same optimal parameters, the proposed model outcomes are compared to those of the classical Optimized Convolution Neural Network (Optimized-CNN) and Fully Connected Neural Network (FCNN) models. Comparing the model’s competency to that of earlier published quantum models yields improvements in accuracy of 8.6%, 12.6%, 3.5%, and 1.8% respectively.",0.008746355685131196
256,Measuring Imbalance on Intersectional Protected Attributes and on Target Variable to Forecast Unfair Classifications,M. Mecati; M. Torchiano; A. Vetrò; J. C. d. Martin,ieee,10.1109/ACCESS.2023.3252370,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10058507,"Bias in software systems is a serious threat to human rights: when software makes decisions that allocate resources or opportunities, may disparately impact people based on personal traits (e.g., gender, ethnic group, etc.), systematically (dis)advantaging certain social groups. The cause is very often the imbalance of training data, that is, unequal distribution of data between the classes of an attribute. Previous studies showed that lower levels of balance in protected attributes are related to higher levels of unfairness in the output. In this paper we contribute to the current status of knowledge on balance measures as risk indicators of systematic discriminations by studying imbalance on two further aspects: the intersectionality among the classes of protected attributes, and the combination of the target variable with protected attributes. We conduct an empirical study to verify whether: i) it is possible to infer the balance of intersectional attributes from the balance of the primary attributes, ii) measures of balance on intersectional attributes are helpful to detect unfairness in the classification outcome, iii) the computation of balance on the combination of a target variable with protected attributes improves the detection of unfairness. Overall the results reveal positive answers, but not for every combination of balance measure and fairness criterion. For this reason, we recommend selecting the fairness and balance measures that are most suitable to the application context when applying our risk approach to real cases.",0.008620689655172414
257,Change Detection in Hyperdimensional Images Using Untrained Models,S. Saha; L. Kondmann; Q. Song; X. X. Zhu,ieee,10.1109/JSTARS.2021.3121556,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582825,"Deep transfer-learning-based change detection methods are dependent on the availability of sensor-specific pretrained feature extractors. Such feature extractors are not always available due to lack of training data, especially for hyperspectral sensors and other hyperdimensional images. Moreover models trained on easily available multispectral (RGB/RGB-NIR) images cannot be reused on such hyperdimensional images due to their irregular number of bands. While hyperdimensional images show large number of spectral bands, they generally show much less spatial complexity, thus reducing the requirement of large receptive fields of convolution filters. Recent works in the computer vision have shown that even untrained deep models can yield remarkable result in some tasks like super-resolution and surface reconstruction. This motivates us to make a bold proposition that untrained lightweight deep model, initialized with some weight initialization strategy, can be used to extract useful semantic features from bi-temporal hyperdimensional images. Based on this proposition, we design a novel change detection framework for hyperdimensional images by extracting bitemporal features using an untrained model and further comparing the extracted features using deep change vector analysis to distinguish changed pixels from the unchanged ones. We further use the deep change hypervectors to cluster the changed pixels into different semantic groups. We conduct experiments on four change detection datasets: three hyperspectral datasets and a hyperdimensional polarimetric synthetic aperture radar dataset. The results clearly demonstrate that the proposed method is suitable for change detection in hyperdimensional remote sensing data.",0.00847457627118644
258,A Classification Approach Based on Directed Acyclic Graph to Predict Locomotion Activities With One Inertial Sensor on the Thigh,V. Papapicco; B. Chen; M. Munih; A. Davalli; R. Sacchetti; E. Gruppioni; S. Crea; N. Vitiello,ieee,10.1109/TMRB.2021.3075096,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9410628,"Current state-of-the-art locomotion mode classifiers for controlling robotic lower-limb prostheses rely on multiple sensors to achieve high accuracy, prediction performance, and robustness to both speed changes and subject-specific gait patterns. However, multiple sensors placed on different body parts usually entail discomfort and poor usability for the user. This paper presents an intention detection method that relies on the features extracted from an inertial measurement unit worn on the thigh and an online phase estimator. The algorithm classifies the locomotion mode of the upcoming stride among the three modes of ground-level walking, stair ascent, and stair descent. A two-stage classification process first distinguishes between transient and steady-state strides and then classifies the locomotion mode of the impending stride based on directed acyclic graphs of binary classifiers. The classification is performed at 75% or 85% of the previous stride phase, respectively for steady-state and transient strides. Data were gathered from 10 healthy subjects and processed offline. Feature design and selection were based on the data of all subjects, while the classification performance was assessed by leave-one-subject-out cross-validation. Results presented a median recognition accuracy of 98.7% for steady-state strides and 95.6% for transitions, suggesting that the method was inherently robust to variations in gait cadence, since all of the features were phase-based and not dependent on fixed time intervals. These results inform the design of control strategies for active transfemoral prostheses able to predict the user’s locomotion intention during the next stride, using minimum sensors.",0.008264462809917356
259,Semi-Supervised Building Footprint Generation With Feature and Output Consistency Training,Q. Li; Y. Shi; X. X. Zhu,ieee,10.1109/TGRS.2022.3174636,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9773314,"Accurate and reliable building footprint maps are vital to urban planning and monitoring, and most existing approaches fall back on convolutional neural networks (CNNs) for building footprint generation. However, one limitation of these methods is that they require strong supervisory information from massive annotated samples for network learning. State-of-the-art semi-supervised semantic segmentation networks with consistency training can help deal with this issue by leveraging a large amount of unlabeled data, which encourages the consistency of model output on data perturbation. Considering that rich information is also encoded in feature maps, we propose to integrate the consistency of both features and outputs in the end-to-end network training of unlabeled samples, enabling to impose additional constraints. Prior semi-supervised semantic segmentation networks have established cluster assumption, in which the decision boundary should lie in the vicinity of low sample density. In this work, we observe that for building footprint generation, low-density regions are more apparent at the intermediate feature representations within the encoder than the encoder’s input or output. Therefore, we propose an instruction to assign the perturbation to the intermediate feature representations within the encoder, which considers the spatial resolution of input remote sensing imagery and the mean size of individual buildings in the study area. The proposed method is evaluated on three datasets with different resolutions: Planet dataset (3 m/pixel), Massachusetts dataset (1 m/pixel), and Inria dataset (0.3 m/pixel). Experimental results show that the proposed approach can well extract more complete building structures and alleviate omission errors.",0.008130081300813009
260,The Intervention of Moral Education Personalized Network Teaching Based on Information Technology,Y. Ran,ieee,10.1109/CIPAE53742.2021.00026,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9610479,"With the deepening of the new curriculum reform, the democratic equality between teachers and students, the need of students' personality development, the individualized classroom teaching of Ideological and moral character has become a very worthy of serious research. In the information explosion, the impact of information technology on educational reform is becoming more and more profound. It has become a national strategy to promote education modernization with information technology. The purpose of this paper is to build a personalized network teaching platform for moral education and promote the moral education information teaching. Based on the demand of moral education individualization in the view of big data, this paper constructs and realizes the moral education network teaching platform with personalized recommendation function. The whole system architecture is designed, the technical feasibility and data feasibility of realizing the system function are analyzed, and the difficulties of developing the system are determined. Learn and master various technical development schemes such as LDA document theme model and recommendation algorithm. According to the requirement analysis, the system function module is realized, the function and performance test of the system are completed, and the test results are analyzed. When the number of users is within 3000, the CPU utilization rate changes slowly, the utilization rate is within 10%, but more than 3000 people, the CPU utilization rate increases rapidly, and the performance of the system is obviously decreased. Because the limit of the number of users is 1000, the system can still meet the needs well.",0.008
261,Deep Learning-Based Automatic Segmentation for Reconstructing Vertebral Anatomy of Healthy Adolescents and Patients With Adolescent Idiopathic Scoliosis (AIS) Using MRI Data,M. Antico; J. P. Little; H. Jennings; G. Askin; R. D. Labrom; D. Fontanarosa; P. Pivonka,ieee,10.1109/ACCESS.2021.3084949,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9444363,"MRI is a non-ionising imaging modality that could be used as an alternative to Xray-based imaging methods to accurately assess the 3D morphology of the vertebral anatomy of scoliosis patients. However, a major caveat in utilising MRI is the significant amount of time required to manually segment the anatomy of interest. To overcome this limitation, we implemented a fully automatic method for the 3D segmentation of thoracic vertebrae, including vertebral body and posterior elements, of healthy adolescents and patients with Adolescent Idiopathic Scoliosis (AIS) using MRI data. 62 MRI scans were obtained from 3 healthy volunteers and 25 patients with AIS. A state-of-the-art deep-learning network for segmentation was trained using image patches of the apical vertebra (T7, T8, T9 or T10) extracted from 20 AIS patient MRIs. Ad-hoc data augmentation was adopted to represent the unlabeled vertebral levels in the dataset (T5-T6, T11-T12). The vertebral levels T5-T12 were then segmented for the remaining MRI datasets by feeding to the network the MRI patches generated by translating a window of fixed size and stride onto the MRI volume. The mean dice score coefficient for the AIS patient vertebral levels T5-T12 was of 87% ± 4.3%, which was comparable to the performance achieved by two experts. On average, 93% and 97% of the MRI segmented slices were considered clinically acceptable morphological reconstructions of AIS and healthy volunteer vertebrae, respectively. The proposed method can be considered as the first step towards more routine MRI-based imaging of AIS osseous deformities, reducing the cumulative exposure of young patients to ionising radiation.",0.0078125
262,The Use of Fuzzy Logic as Augmentation to Quantitative Analysis to Unleash Knowledge of Participants’ Uncertainty When Filling a Survey: Case of Cloud Computing,I. Kouatli,ieee,10.1109/TKDE.2020.2993326,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9093142,"Quantitative analysis is a solid, well established mathematical technique that can be used to analyze the result of survey(s) in a specific field. Survey analysis is usually based on the study of the effect of independent variables on a dependent variable. Although quantitative analysis can use an R-Squared value as a method to measure the strength of the relationship between the independent and dependent variables, it does not capture the effect of participants’ ambiguity when answering questionnaires. The source of such ambiguity stems from the process of completing the survey, whereby the respondent may have answered most of the independent questions with ease, but has difficulty in responding to the overall dependent question (or vice versa). The objective of this paper is to demonstrate the use of fuzzy logic as a mechanism to measure the uncertainty faced by participants when filling a questionnaire. Based on the participants’ responses to the independent variables, the proposed technique uses fuzzy logic inference to measure the subjectivity (qualitative aspect) of the participants’ response to the dependent variable. Beyond quantitative analysis, augmentation with such a fuzzy module can provide clearer picture to analysts when analyzing the survey results. In this paper, Cloud acceptance survey will be used as a vehicle to provide step-by-step explanation of the proposed augmentation technique to unleash the hidden knowledge in similar cases to cloud computing long survey questionnaire where participants may change their mind at the end of the survey causing uncertainty represented in discrepancy of the collected data. The proposed technique would only be valid for long surveys like the presented Cloud computing acceptability where uncertainty in the data is inevitable.",0.007352941176470588
263,Spatial Context Awareness for Unsupervised Change Detection in Optical Satellite Images,L. Kondmann; A. Toker; S. Saha; B. Schölkopf; L. Leal-Taixé; X. X. Zhu,ieee,10.1109/TGRS.2021.3130842,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9627707,"Detecting changes on the ground in multitemporal Earth observation data is one of the key problems in remote sensing. In this article, we introduce Sibling Regression for Optical Change detection (SiROC), an unsupervised method for change detection (CD) in optical satellite images with medium and high resolutions. SiROC is a spatial context-based method that models a pixel as a linear combination of its distant neighbors. It uses this model to analyze differences in the pixel and its spatial context-based predictions in subsequent time periods for CD. We combine this spatial context-based CD with ensembling over mutually exclusive neighborhoods and transitioning from pixel to object-level changes with morphological operations. SiROC achieves competitive performance for CD with medium-resolution Sentinel-2 and high-resolution Planetscope imagery on four datasets. Besides accurate predictions without the need for training, SiROC also provides a well-calibrated uncertainty of its predictions.",0.0070921985815602835
264,Information seeking behavior of Members of the Omani Parliament,S. S. A. Ambusaidi,ieee,10.1109/ACIT53391.2021.9677257,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9677257,"This study aims to investigate the information-seeking behavior of Members of the Omani Parliament in terms of their thoughts, perceptions, attitudes, motivations, techniques, preferences, ways, tools, and problems encountered by them towards accessing information. A qualitative approach was adopted for data collection by an open interview with MPs of Shura conical. This study has revealed that MPs of the council were looking for information for parliamentary work and they used internet searches, ask the staff of the information service department and search on government publications to obtain information. The result also showed The MPs prefer government sources to do their job, and they did not rely on the parliamentary library as a source of information. Besides, MPs facing some administrative challenges from the Government to obtain information. Finally, the study presented a set of recommendations for improving the information work in the Shura council.",0.006944444444444444
265,The Urban Coast Under Climate Change and Sea Level Rise: A Potential Hazard to the Ocean and an Ethical Challenge to Humanity,H. -P. Plag; K. Jones; D. Martin; R. Garello,ieee,10.23919/OCEANS44145.2021.9706118,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9706118,"Human presence in the coastal environment is rapidly growing, resulting in an equally rapid growth in construction, built environment, and consumer goods in the coastal zones. The coastal urban areas are receiving a growing fraction of the population migrating from rural into urban areas. As a result, most of today’s megacities are in the coastal zone or in flood plains of major rivers. This urbanization of the coastal zone is expected to continue for the foreseeable future. At the same time, the coastal zone is exposed to a changing spectrum of natural hazards originating in the atmosphere-ocean and terrestrial systems, including coastal flooding, storms and storm surges, river floods, tsunamis, and sea level rise. While considerable efforts are being made to increase resilience of the urban coast with respect to these hazards, little attention has been paid to future threats posed to the ocean and the marine biosphere by the human presence in the coastal zone. Large efforts are being made to reduce present impacts of human activities on the ocean and the marine biosphere. However, the future risks to the ocean associated with marine debris emerging from the urban coast built in the coastal zone at present is to a large extent overlooked. The way coastal urban areas are developed today creates a risk with potentially large harmful impacts on future generation. Efforts to transform the way urban coasts are developed so that the built environment is adapted to sea level rise and a changing hazard spectrum would help to bring present-day actions in line with our normative ethics. Developing internationally accepted rules for the abandonment of urban coasts that can not longer be defended against encroaching seas would ensure that the threats to the ocean, the marine biosphere and future generations are reduced.",0.006779661016949152
266,mToFNet: Object Anti-Spoofing with Mobile Time-of-Flight Data,Y. Jeong; D. Kim; J. Lee; M. Hong; S. Hwang; J. Choi,ieee,10.1109/WACV51458.2022.00305,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9706777,"In online markets, sellers can maliciously recapture others’ images on display screens to utilize as spoof images, which can be challenging to distinguish in human eyes. To prevent such harm, we propose an anti-spoofing method using the pairs of RGB images and depth maps provided by the mobile camera with a time-of-fight sensor. When images are recaptured on display screens, various patterns differing by the screens as known as the moiré patterns can be also captured in spoof images. These patterns lead the anti-spoofing model to be overfitted and unable to detect spoof images recaptured on unseen media. To avoid the issue, we build a novel representation model composed of two embedding models, which can be trained without considering the recaptured images. Also, we newly introduce mToF dataset, the largest and most diverse object anti-spoofing dataset, and the first to utilize the time-of-flight (ToF) data. Experimental results confirm that our model achieves robust generalization even across unseen domains.",0.006329113924050633
267,COVID-19 Detection Based on Image Regrouping and Resnet-SVM Using Chest X-Ray Images,C. Zhou; J. Song; S. Zhou; Z. Zhang; J. Xing,ieee,10.1109/ACCESS.2021.3086229,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9446895,"As the COVID-19 spread worldwide, countries around the world are actively taking measures to fight against the epidemic. To prevent the spread of it, a high sensitivity and efficient method for COVID-19 detection is necessary. By analyzing the COVID-19 chest X-ray images, a combination method of image regrouping and ResNet-SVM was proposed in this study. The lung region was segmented from the original chest X-ray images and divided into small pieces, and then the small pieces of lung region were regrouped into a regular image randomly. Furthermore the regrouped images were fed into the deep residual encoder block for feature extraction. Finally the extracted features were as input into support vector machine for recognition. The visual attention was introduced in the novel method, which paid more attention to the features of COVID-19 without the interference of shapes, rib and other related noises. The experimental results showed that the proposed method achieved 93% accuracy without large number of training data, outperformed the existing COVID-19 detection models.",0.006060606060606061
268,Uncertainty-Aware Multi-Dimensional Mutual Learning for Brain and Brain Tumor Segmentation,J. Zhao; Z. Xing; Z. Chen; L. Wan; T. Han; H. Fu; L. Zhu,ieee,10.1109/JBHI.2023.3274255,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10121596,"Existing segmentation methods for brain MRI data usually leverage 3D CNNs on 3D volumes or employ 2D CNNs on 2D image slices. We discovered that while volume-based approaches well respect spatial relationships across slices, slice-based methods typically excel at capturing fine local features. Furthermore, there is a wealth of complementary information between their segmentation predictions. Inspired by this observation, we develop an Uncertainty-aware Multi-dimensional Mutual learning framework to learn different dimensional networks simultaneously, each of which provides useful soft labels as supervision to the others, thus effectively improving the generalization ability. Specifically, our framework builds upon a 2D-CNN, a 2.5D-CNN, and a 3D-CNN, while an uncertainty gating mechanism is leveraged to facilitate the selection of qualified soft labels, so as to ensure the reliability of shared information. The proposed method is a general framework and can be applied to varying backbones. The experimental results on three datasets demonstrate that our method can significantly enhance the performance of the backbone network by notable margins, achieving a Dice metric improvement of 2.8% on MeniSeg, 1.4% on IBSR, and 1.3% on BraTS2020.",0.00558659217877095
269,Classifying Suicide-Related Content and Emotions on Twitter Using Graph Convolutional Neural Networks,A. M. Schoene; L. Bojanić; M. -Q. Nghiem; I. M. Hunt; S. Ananiadou,ieee,10.1109/TAFFC.2022.3221683,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955379,"Recent work in Natural Language Processing has increasingly focused on detecting suicidal intent in textual data, where the main aim is to detect expressions in a binary setting. However, previous research has shown that search results and other mentions of suicide online are not only limited to expressions of suicidal intent. Therefore, previously proposed algorithms and datasets might for example struggle to distinguish between suicidal intent of a user and suicide mentioned in a humorous context. In this article we introduce a new dataset called TWISCO, which proposes an alternative approach to classifying expressions of suicidality online. For this, we use a coding framework developed in Psychology to distinguish between different mentions of suicide. Next, we present a variety of machine and deep learning baselines in three different classification settings (text only, features only and text and features). Furthermore, we introduce a Feature GCN that improves performance over the GCN baseline. Finally, we investigate the hypothesis that feelings of dominance are correlated with users expressing their own suicidality. We provide an in-depth discussion of the trade-offs in classifying suicidal intent online.",0.0055248618784530384
270,HED-UNet: Combined Segmentation and Edge Detection for Monitoring the Antarctic Coastline,K. Heidler; L. Mou; C. Baumhoer; A. Dietz; X. X. Zhu,ieee,10.1109/TGRS.2021.3064606,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9383809,"Deep learning-based coastline detection algorithms have begun to outshine traditional statistical methods in recent years. However, they are usually trained only as single-purpose models to either segment land and water or delineate the coastline. In contrast to this, a human annotator will usually keep a mental map of both segmentation and delineation when performing manual coastline detection. To take into account this task duality, we, therefore, devise a new model to unite these two approaches in a deep learning model. By taking inspiration from the main building blocks of a semantic segmentation framework (UNet) and an edge detection framework (HED), both tasks are combined in a natural way. Training is made efficient by employing deep supervision on side predictions at multiple resolutions. Finally, a hierarchical attention mechanism is introduced to adaptively merge these multiscale predictions into the final model output. The advantages of this approach over other traditional and deep learning-based methods for coastline detection are demonstrated on a data set of Sentinel-1 imagery covering parts of the Antarctic coast, where coastline detection is notoriously difficult. An implementation of our method is available at https://github.com/khdlr/HED-UNet.",0.005405405405405406
271,Promoting the Sustainability of Blockchain in Web 3.0 and the Metaverse Through Diversified Incentive Mechanism Design,D. M. Doe; J. Li; N. Dusit; Z. Gao; J. Li; Z. Han,ieee,10.1109/OJCS.2023.3260829,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10078899,"This article explores the role of blockchains in the development of Web 3.0 and the Metaverse. The success of these technologies is dependent on the utilization of decentralized systems like blockchains, which can store and validate data on identities and reputations and facilitate the exchange of virtual assets. Full nodes, which store the entire blockchain state and validate all transactions, are essential for the decentralization and reliability of the network. However, operating a full node is resource-intensive and can be expensive. To tackle this challenge, we propose an incentive mechanism that utilizes contract-theoretic methods to economically motivate users to support the sustainability and growth of the blockchain network. Our contract design addresses the problem of information asymmetry (e.g., users' revenue-generating capabilities and efforts) between users and the blockchain network. Additionally, we recommend providing diverse incentives based on the user's revenue-generating capabilities and efforts to assist the blockchain network in funding incentives. Our experimental results demonstrate that our proposed mechanism increases the blockchain network's utility by $48.48\%-54.52\%$ and reduces the users' cost by $38.46\%-62.5\%$ compared with the state-of-the-art implementations such as Celo, Vipnode, and Pocket Network.",0.005405405405405406
272,MixNet: Physics Constrained Deep Neural Motion Prediction for Autonomous Racing,P. Karle; F. Török; M. Geisslinger; M. Lienkamp,ieee,10.1109/ACCESS.2023.3303841,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10214014,"Reliably predicting the motion of contestant vehicles surrounding an autonomous racecar is crucial for effective and performant ego-motion planning. Although highly expressive, deep neural networks are black-box models, making their usage challenging in this safety-critical applications of autonomous racing. On the other hand, physics-based models provide high safety guarantees for the predicted trajectory but lack accuracy. The method presented in this paper targets this trade-off. We introduce a method to predict the trajectories of opposing racecars with deep neural networks considering physical constraints to restrict the output and to improve its feasibility. We report the method’s performance against an LSTM-based encoder-decoder architecture on data acquired from multi-agent racing simulations. The proposed method outperforms the baseline model in prediction accuracy and robustness. Still, it fulfills quality guarantees of smoothness and consistency of the predicted trajectory and prevents out-of-track predictions. Thus, a robust real-world application of the model with high prediction accuracy is proven. The presented model was deployed on the racecar of the Technical University of Munich for the Indy Autonomous Challenge 2021. The code used in this research is available as open-source software at https://www.github.com/TUMFTM/MixNet.",0.005405405405405406
273,The Current Situation of Vocational College Students' Moral Orientation and Its Influencing Factors Based on the Different Population Variables,R. Fu; H. Wang; J. Zhao; X. Ge,ieee,10.1109/EIMSS53851.2021.00018,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9603713,"Objective: The paper is to understand the moral orientation and influencing factors of current vocational students, analyze the existing problems, and provide effective strategies for further education and guidance of vocational students. Methods: Questionnaire survey was carried out among students in a vocational college in Shandong Province by literature method and questionnaire survey method, and SPSS19.0 was used for data analysis. Results: (1) The vast majority of students (93.72%) had a clear criterion for understanding moral connotation, and female students were more objective, rational and accurate than male students ($\chi^{2}=19.162,\ \mathrm{P}=0.000 < 0.001$). (2) There is a certain cognitive bias in the understanding of social injustice, showing the coexistence of positive and negative confrontation, hope and compromise; some students think that social injustice “should be eliminated” (48.66%), while others think that social injustice “is an inevitable phenomenon and cannot be changed” (21.07%); some students thought that social injustice “can stimulate people and social progress” (28.1%), while others thought it “doesn't matter” (2.17%); and girls were more inclined to be fair, positive and just than boys ($\chi 2=11.878,\ \mathrm{P}=0.002 < 0.05$). (3) The vast majority of students (93.07%) can keep clear cognition; only a few students have perceptual and wrong cognition in the use of power tendency; and girls are more cautious and responsible than boys ($\chi^{2}=13.535,\, \mathrm{P}=0.004 < 0.05$). (4) In terms of moral accomplishment and behavior evaluation of college students, the overall situation is positive and rational, while a few are negative and pessimistic. And female students are more confident and positive than male students; in terms of judgments that affect moral quality and behavior, they were more objective and rational ($\chi^{2}=109.975, \mathrm{P}=0.000 < 0.001$); in terms of the understanding of “the overall moral decline of college students”, Student cadres of middle school students were higher than non-student cadres ($\chi^{2}=9.232, \mathrm{P}=0.026 < 0.05$) with “completely agree” and “somewhat agree”. (5) Students of different grades have significant differences in social justice, the use of personal power and the lack of morality in college students ($\mathrm{P} < 0.05$). Conclusion: The moral orientation of most vocational college students is objective, positive and rational. Population variables such as gender, grade and political status have a significant impact on the moral orientation of vocational college students. Therefore, targeted education and guidance should be strengthened.",0.005263157894736842
274,Pseudo Features-Guided Self-Training for Domain Adaptive Semantic Segmentation of Satellite Images,F. Zhang; Y. Shi; Z. Xiong; W. Huang; X. X. Zhu,ieee,10.1109/TGRS.2023.3281503,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10141556,"Semantic segmentation is a fundamental and crucial task that is of great importance to real-world satellite image-based applications. Yet a widely acknowledged issue that occurs when applying the semantic segmentation models to unseen scenery is that the model will perform much poorer than when it was applied to scenery similar to the training data. This phenomenon is usually termed as the domain shift problem. To tackle it, this article presents a self-training-based unsupervised domain adaptation (UDA) method. Different from the previous self-training approaches which focus on rectifying and improving the quality of the pseudo labels, we instead seek to exploit feature-level relation among neighboring pixels to structure and regularize the prediction of the adapted model. Based on the assumption that spatial topological relation is maintained despite the impact of the domain shift, we propose a novel self-training mechanism to perform DA by exploiting local relation in the feature space spanned by the teacher model, from which the pseudo labels are generated. Quantitative experiments on four different public benchmarks demonstrate that the proposed method can outperform the other UDA methods. Besides, analytical experiments also intuitively verify the proposed assumption. Codes will be publicly available at https://github.com/zhu-xlab/PFST.",0.005128205128205128
275,From Easy to Hard: Learning Language-Guided Curriculum for Visual Question Answering on Remote Sensing Data,Z. Yuan; L. Mou; Q. Wang; X. X. Zhu,ieee,10.1109/TGRS.2022.3173811,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9771224,"Visual question answering (VQA) for remote sensing scene has great potential in intelligent human–computer interaction system. Although VQA in computer vision has been widely researched, VQA for remote sensing data (RSVQA) is still in its infancy. There are two characteristics that need to be specially considered for the RSVQA task: 1) no object annotations are available in the RSVQA datasets, which makes it difficult for models to exploit informative region representation and 2) there are questions with clearly different difficulty levels for each image in the RSVQA task. Directly training a model with questions in a random order may confuse the model and limit the performance. To address these two problems, in this article, a multi-level visual feature learning method is proposed to jointly extract language-guided holistic and regional image features. Besides, a self-paced curriculum learning (SPCL)-based VQA model is developed to train networks with samples in an easy-to-hard way. To be more specific, a language-guided SPCL method with a soft weighting strategy is explored in this work. The proposed model is evaluated on three public datasets, and extensive experimental results show that the proposed RSVQA framework can achieve promising performance. Code will be available at https://gitlab.lrz.de/ai4eo/reasoning/VQA-easy2hard.",0.005076142131979695
276,Discerning Affect From Touch and Gaze During Interaction With a Robot Pet,X. L. Cang; P. Bucci; J. Rantala; K. E. MacLean,ieee,10.1109/TAFFC.2021.3094894,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9477021,"Practical affect recognition needs to be efficient and unobtrusive in interactive contexts. One approach to a robust realtime system is to sense and automatically integrate multiple nonverbal sources. We investigated how users’ touch, and secondarily gaze, perform as affect-encoding modalities during physical interaction with a robot pet, in comparison to more-studied biometric channels. To elicit authentically experienced emotions, participants recounted two intense memories of opposing polarity in Stressed-Relaxed or Depressed-Excited conditions. We collected data (N=30) from a touch sensor embedded under robot fur (force magnitude and location), a robot-adjacent gaze tracker (location), and biometric sensors (skin conductance, blood volume pulse, respiration rate). Cross-validation of Random Forest classifiers achieved best-case accuracy for combined touch-with-gaze approaching that of biometric results: where training and test sets include adjacent temporal windows, subject-dependent prediction was 94% accurate. In contrast, subject-independent Leave-One-participant-Out predictions resulted in 30% accuracy (chance 25%). Performance was best where participant information was available in both training and test sets. Addressing computational robustness for dynamic, adaptive realtime interactions, we analyzed subsets of our multimodal feature set, varying sample rates and window sizes. We summarize design directions based on these parameters for this touch-based, affective, and hard, realtime robot interaction application.",0.005076142131979695
277,Investigating the Cognitive Response of Brake Lights in Initiating Braking Action Using EEG,R. Palaniappan; S. Mouli; H. Bowman; I. McLoughlin,ieee,10.1109/TITS.2021.3091291,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9473062,"Half of all road accidents result from either lack of driver attention or from maintaining insufficient separation between vehicles. Collision from the rear, in particular, has been identified as the most common class of accident in the UK, and its influencing factors have been widely studied for many years. Rear-mounted stop lamps, illuminated when braking, are the primary mechanism to alert following drivers to the need to reduce speed or brake. This paper develops a novel brain response approach to measuring subject reaction to different brake light designs. A variety of off-the-shelf brake light assemblies are tested in a physical simulated driving environment to assess the cognitive reaction times of 22 subjects. Eight pairs of LED-based and two pairs of incandescent bulb-based brake light assemblies are used and electroencephalogram (EEG) data recorded. Channel Pz is utilised to extract the P3 component evoked during the decision making process that occurs in the brain when a participant decides to lift their foot from the accelerator and depress the brake. EEG analysis shows that both incandescent bulb-based lights are statistically slower to evoke cognitive responses than all tested LED-based lights. Between the LED designs, differences are evident, but not statistically significant, attributed to the significant amount of movement artifact in the EEG signal.",0.004761904761904762
278,Fairer Machine Learning Through the Hybrid of Multi-objective Evolutionary Learning and Adversarial Learning,S. Gui; Q. Zhang; C. Huang; B. Yuan,ieee,10.1109/IJCNN54540.2023.10191821,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10191821,"With growing concerns about the unwanted bias or discrimination in machine learning, a number of fairness-aware machine learning algorithms have been developed to mitigate bias in the prediction. Because the objectives of accuracy and fairness are antagonistic, it is hard to balance the trade-off between them. Recently, Multi-objective Evolutionary Learning (MOEL) framework has been proposed to train a set of Pareto models with the consideration of accuracy and fairness simultaneously. However, this framework prefers to train more accurate models rather than fairer models due to the lack of gradient in terms of fairness. In this paper, MOEL is enhanced through introducing Adversarial Learning (AL). The MOEL-AL framework aims to maximize a set of predictors' ability to predict true labels and minimize the ability of an adversarial network to predict the sensitive attributes from the predictors' output. Specifically, the adversarial network can be regarded as a proxy of the undifferentiable fairness metrics, so it is possible to propagate gradients in terms of both accuracy and fairness for the predictors during the back-propagation process. Besides, the adversarial strength for different predictors is adjusted dynamically according to their fairness metric. Compared with the state-of-the-art methods, experimental studies on seven well-known datasets show that our method can provide a set of fairer Pareto models with little drop on accuracy.",0.004651162790697674
279,Development and Evaluation of a Smartphone-Based Electroencephalography (EEG) System,A. D. Bateson; A. U. R. Asghar,ieee,10.1109/ACCESS.2021.3079992,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9430505,"The aim of the study was to design, develop and evaluate a general-purpose EEG platform which integrates with a smartphone. The target specification was a system with 19 EEG channels and data stored onto the smartphone via a Wi-Fi connection. The hardware was developed using three ADS1299 integrated circuits, and the game engine, Unity, was used to develop the smartphone app. An evaluation of the system was conducted using recordings of alpha waves during periods of eye closure in participants (Bland-Altman statistical comparison with a clinical grade EEG system). The smartphone was also used to deliver time-locked auditory stimuli using an oddball paradigm to evaluate the ability of the developed system to acquire event related potentials (ERP) during sitting and walking. No significant differences were found for the alpha wave peak amplitude, frequency and area under the curve for the intra-system (two consecutive periods of alpha waves) or inter-system (developed smartphone-based EEG system versus FDA-approved system) comparisons. ERP results showed the peak amplitude of the auditory P300 component to deviant tones was significantly higher when compared to standard tones for sitting and walking activities. It is envisaged that our general-purpose EEG system will encourage other researchers to design and build their own specific versions rather than being limited by the fixed features of commercial products.",0.004651162790697674
280,"Open Access Dataset, Toolbox and Benchmark Processing Results of High-Density Surface Electromyogram Recordings",X. Jiang; X. Liu; J. Fan; X. Ye; C. Dai; E. A. Clancy; M. Akay; W. Chen,ieee,10.1109/TNSRE.2021.3082551,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9438637,"We provide an open access dataset of High densitY Surface Electromyogram (HD-sEMG) Recordings (named “Hyser”), a toolbox for neural interface research, and benchmark results for pattern recognition and EMG-force applications. Data from 20 subjects were acquired twice per subject on different days following the same experimental paradigm. We acquired 256-channel HD-sEMG from forearm muscles during dexterous finger manipulations. This Hyser dataset contains five sub-datasets as: (1) pattern recognition (PR) dataset acquired during 34 commonly used hand gestures, (2) maximal voluntary muscle contraction (MVC) dataset while subjects contracted each individual finger, (3) one-degree of freedom (DoF) dataset acquired during force-varying contraction of each individual finger, (4) N-DoF dataset acquired during prescribed contractions of combinations of multiple fingers, and (5) random task dataset acquired during random contraction of combinations of fingers without any prescribed force trajectory. Dataset 1 can be used for gesture recognition studies. Datasets 2-5 also recorded individual finger forces, thus can be used for studies on proportional control of neuroprostheses. Our toolbox can be used to: (1) analyze each of the five datasets using standard benchmark methods and (2) decompose HD-sEMG signals into motor unit action potentials via independent component analysis. We expect our dataset, toolbox and benchmark analyses can provide a unique platform to promote a wide range of neural interface research and collaboration among neural rehabilitation engineers.",0.004545454545454545
281,Dependency Smells in JavaScript Projects,A. J. Jafari; D. E. Costa; R. Abdalkareem; E. Shihab; N. Tsantalis,ieee,10.1109/TSE.2021.3106247,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9519532,"Dependency management in modern software development poses many challenges for developers who wish to stay up to date with the latest features and fixes whilst ensuring backwards compatibility. Project maintainers have opted for varied, and sometimes conflicting, approaches for maintaining their dependencies. Opting for unsuitable approaches can introduce bugs and vulnerabilities into the project, introduce breaking changes, cause extraneous installations, and reduce dependency understandability, making it harder for others to contribute effectively. In this paper, we empirically examine evidence of recurring dependency management issues (dependency smells). We look at the commit data for a dataset of 1,146 active JavaScript repositories to catalog, quantify and understand dependency smells. Through a series of surveys with practitioners, we identify and quantify seven dependency smells with varying degrees of popularity and investigate why they are introduced throughout project history. Our findings indicate that dependency smells are prevalent in JavaScript projects with two or more distinct smells appearing in 80 percent of the projects, but they generally infect a minority of a project’s dependencies. Our observations show that the number of dependency smells tend to increase over time. Practitioners agree that dependency smells bring about many problems including security threats, bugs, dependency breakage, runtime errors, and other maintenance issues. These smells are generally introduced as developers react to dependency misbehaviour and the shortcomings of the npm ecosystem.",0.0045045045045045045
282,In-Group Bias in Deep Learning-Based Face Recognition Models Due to Ethnicity and Age,S. Nagpal; M. Singh; R. Singh; M. Vatsa; N. K. Ratha,ieee,10.1109/TTS.2023.3241010,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10032592,"Humans are known to favor other individuals who exist in similar groups as them, exhibiting biased behavior, which is termed as in-group bias. The groups could be formed on the basis of ethnicity, age, or even a favorite sports team. Taking cues from aforementioned observation, we inspect if deep learning networks also mimic this human behavior, and are affected by in-group and out-group biases. In this first of its kind research, the behavior of face recognition models is evaluated to understand if similar to humans, models also encode group-specific features for face recognition, along with where bias is encoded in these models. Analysis has been performed for two use-cases of bias: age and ethnicity in face recognition models. Thorough experimental evaluation leads us to several insights: (i) deep learning models focus on different facial regions for different ethnic groups and age groups, and (ii) large variation in face verification performance is also observed across different sub-groups for both known and our own trained deep networks. Based on the observations, a novel bias index is presented for evaluating a trained model’s level of bias. We believe that a better understanding of how deep learning models work and encode bias, along with the proposed bias index would enable researchers to address the challenge of bias in AI, and develop more robust and fairer algorithms for mitigating bias as well as developing fairer models.",0.004329004329004329
283,γ-Net: Superresolving SAR Tomographic Inversion via Deep Learning,K. Qian; Y. Wang; Y. Shi; X. X. Zhu,ieee,10.1109/TGRS.2022.3164193,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745947,"Synthetic aperture radar tomography (TomoSAR) has been extensively employed in 3-D reconstruction in dense urban areas using high-resolution SAR acquisitions. Compressive sensing (CS)-based algorithms are generally considered as the state-of-the art in super-resolving TomoSAR, in particular in the single look case. This superior performance comes at the cost of extra computational burdens, because of the sparse reconstruction, which cannot be solved analytically, and we need to employ computationally expensive iterative solvers. In this article, we propose a novel deep learning-based super-resolving TomoSAR inversion approach,  $\boldsymbol {\gamma }$ -Net, to tackle this challenge.  $\boldsymbol {\gamma }$ -Net adopts advanced complex-valued learned iterative shrinkage thresholding algorithm (CV-LISTA) to mimic the iterative optimization step in sparse reconstruction. Simulations show the height estimate from a well-trained  $\boldsymbol {\gamma }$ -Net approaches the Cramér-Rao lower bound (CRLB) while improving the computational efficiency by one to two orders of magnitude comparing to the first-order CS-based methods. It also shows no degradation in the super-resolution power comparing to the state-of-the-art second-order TomoSAR solvers, which are much more computationally expensive than the first-order methods. Specifically,  $\boldsymbol {\gamma }$ -Net reaches more than 90% detection rate in moderate super-resolving cases at 25 measurements at 6 dB SNR. Moreover, simulation at limited baselines demonstrates that the proposed algorithm outperforms the second-order CS-based method by a fair margin. Test on real TanDEM-X data with just six interferograms also shows high-quality 3-D reconstruction with high-density detected double scatterers.",0.004166666666666667
284,FuTH-Net: Fusing Temporal Relations and Holistic Features for Aerial Video Classification,P. Jin; L. Mou; Y. Hua; G. -S. Xia; X. X. Zhu,ieee,10.1109/TGRS.2022.3150917,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9709809,"Unmanned aerial vehicles (UAVs) are now widely applied to data acquisition due to its low cost and fast mobility. With the increasing volume of aerial videos, the demand for automatically parsing these videos is surging. To achieve this, current research mainly focuses on extracting a holistic feature with convolutions along both spatial and temporal dimensions. However, these methods are limited by small temporal receptive fields and cannot adequately capture long-term temporal dependencies that are important for describing complicated dynamics. In this article, we propose a novel deep neural network, termed Fusing Temporal relations and Holistic features for aerial video classification (FuTH-Net), to model not only holistic features but also temporal relations for aerial video classification. Furthermore, the holistic features are refined by the multiscale temporal relations in a novel fusion module for yielding more discriminative video representations. More specially, FuTH-Net employs a two-pathway architecture: 1) a holistic representation pathway to learn a general feature of both frame appearances and short-term temporal variations and 2) a temporal relation pathway to capture multiscale temporal relations across arbitrary frames, providing long-term temporal dependencies. Afterward, a novel fusion module is proposed to spatiotemporally integrate the two features learned from the two pathways. Our model is evaluated on two aerial video classification datasets, ERA and Drone-Action, and achieves the state-of-the-art results. This demonstrates its effectiveness and good generalization capacity across different recognition tasks (event classification and human action recognition). To facilitate further research, we release the code at https://gitlab.lrz.de/ai4eo/reasoning/futh-net.",0.004098360655737705
285,"Responsibility, Recourse, and Redress: A Focus on the Three R’s of AI Ethics",A. Gardner,ieee,10.1109/MTS.2022.3173342,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794766,"In August 2020, students took to the streets of London in a mass protest over their A-level results (that determine entry to university), chanting “F*ck the algorithm.” Their A-level grades had been determined by an algorithm that depended on past school performance, a system of teacher ratings, and for smaller student groups, the use of Centre Assessed Grades. Commendably Ofqual (the U.K. Government Office of Qualifications and Examinations Regulation) were transparent in their use of the algorithm so that affected stakeholders were informed of the algorithm’s existence and the key details of how it was developed. The design of the data set produced an algorithm with biased outputs, which hardcoded preexisting educational, policy, and societal biases. Due to the large numbers of students, the single “results day” output and the wider interests of schools, teachers, parents, and universities, the unfairness of the outcome was magnified. Add to this that the students were, by definition, academically proficient individuals, many of whom derived from privileged and supportive backgrounds, which meant that they had the awareness and capacity to challenge. Hence, the impact of this biased algorithm was not received silently and so it was hard to deny, deflect, and dismiss. However, this is not always the case, and many systems are deployed with similar biases and harmful outcomes but the impact is dissipated over time and individuals, and therefore not so immediately obvious and easy to challenge. This is particularly the case when the people impacted do not have the advantages that enabled the A-level students to challenge.",0.00390625
286,Deep Reinforcement Learning for Band Selection in Hyperspectral Image Classification,L. Mou; S. Saha; Y. Hua; F. Bovolo; L. Bruzzone; X. X. Zhu,ieee,10.1109/TGRS.2021.3067096,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9387453,"Band selection refers to the process of choosing the most relevant bands in a hyperspectral image. By selecting a limited number of optimal bands, we aim at speeding up model training, improving accuracy, or both. It reduces redundancy among spectral bands while trying to preserve the original information of the image. By now, many efforts have been made to develop unsupervised band selection approaches, of which the majorities are heuristic algorithms devised by trial and error. In this article, we are interested in training an intelligent agent that, given a hyperspectral image, is capable of automatically learning policy to select an optimal band subset without any hand-engineered reasoning. To this end, we frame the problem of unsupervised band selection as a Markov decision process, propose an effective method to parameterize it, and finally solve the problem by deep reinforcement learning. Once the agent is trained, it learns a band-selection policy that guides the agent to sequentially select bands by fully exploiting the hyperspectral image and previously picked bands. Furthermore, we propose two different reward schemes for the environment simulation of deep reinforcement learning and compare them in experiments. This, to the best of our knowledge, is the first study that explores a deep reinforcement learning model for hyperspectral image analysis, thus opening a new door for future research and showcasing the great potential of deep reinforcement learning in remote sensing applications. Extensive experiments are carried out on four hyperspectral data sets, and experimental results demonstrate the effectiveness of the proposed method. The code is publicly available.",0.00390625
287,Anomaly Detection in Aerial Videos With Transformers,P. Jin; L. Mou; G. -S. Xia; X. X. Zhu,ieee,10.1109/TGRS.2022.3198130,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9854892,"Unmanned aerial vehicles (UAVs) are widely applied for purposes of inspection, search, and rescue operations by the virtue of low-cost, large-coverage, real-time, and high-resolution data acquisition capacities. Massive volumes of aerial videos are produced in these processes, in which normal events often account for an overwhelming proportion. It is extremely difficult to localize and extract abnormal events containing potentially valuable information from long video streams manually. Therefore, we are dedicated to developing anomaly detection methods to solve this issue. In this article, we create a new dataset, named Drone-Anomaly, for anomaly detection in aerial videos. This dataset provides 37 training video sequences and 22 testing video sequences from seven different realistic scenes with various anomalous events. There are 87488 color video frames (51635 for training and 35853 for testing) with the size of 640  $\times640$  at 30 frames/s. Based on this dataset, we evaluate existing methods and offer a benchmark for this task. Furthermore, we present a new baseline model, anomaly detection with Transformers (ANDTs), which treats consecutive video frames as a sequence of tubelets, utilizes a Transformer encoder to learn feature representations from the sequence, and leverages a decoder to predict the next frame. Our network models normality in the training phase and identifies an event with unpredictable temporal dynamics as an anomaly in the test phase. Moreover, to comprehensively evaluate the performance of our proposed method, we use not only our Drone-Anomaly dataset but also another dataset. We will make our dataset and code publicly available. A demo video is available at https://youtu.be/ancczYryOBY. We make our dataset and code publicly available (https://gitlab.lrz.de/ai4eo/reasoning/drone-anomaly https://github.com/Jin-Pu/Drone-Anomaly).",0.003745318352059925
288,Severity Assessment of Social Anxiety Disorder Using Deep Learning Models on Brain Effective Connectivity,A. Al-Ezzi; N. Yahya; N. Kamel; I. Faye; K. Alsaih; E. Gunaseli,ieee,10.1109/ACCESS.2021.3089358,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9454451,"Neuroimaging investigations have proven that social anxiety disorder (SAD) is associated with aberrations in the connectivity of human brain functions. The assessment of the effective connectivity (EC) of the brain and its impact on the detection and medication of neurodegenerative pathophysiology is hence a crucial concern that needs to be addressed. Nevertheless, there are no clinically certain diagnostic biomarkers that can be linked to SAD. Therefore, investigating neural connectivity biomarkers of SAD based on deep learning models (DL) has a promising approach with its recent underlined potential results. In this study, an electroencephalography (EEG)-based detection model for SAD is constructed through directed causal influences combined with a deep convolutional neural network (CNN) and the long short-term memory (LSTM). The EEG data were classified by applying three different DL models, namely, CNN, LSTM, and CNN + LSTM to discriminate the severity of SAD (severe, moderate, mild) and healthy controls (HC) at different frequency bands (delta, theta, alpha, low beta, and high beta) in the default mode network (DMN) under resting-state condition. The DL model uses the EC features as input, which are derived from the cortical correlation within different EEG rhythms for certain cortical areas that are more susceptible to SAD. Experimental results revealed that the proposed model (CNN + LSTM) outperforms the other models in SAD recognition. For our dataset, the highest recognition accuracies of 92.86%, 92.86%, 96.43%, and 89.29%, specificities of 95.24%, 95.24%, 100%, and 90.91%, and sensitivities of 85.71%, 85.71%, 87.50%, and 83.33% were achieved by using CNN + LSTM model for severe, moderate, mild, and HC, respectively. The fundamental contribution of this analysis is the characterization of neural brain features using different DL models to categorize the severity of SAD, which can represent a potential biomarker for SAD.",0.003436426116838488
289,A Lesson From AI: Ethics Is Not an Imitation Game,G. Génova; V. M. Pelayo; M. R. G. Martín,ieee,10.1109/MTS.2022.3147531,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9731827,"The title of the 2014 movie The Imitation Game tells us the life of Alan Turing, especially his outstanding participation in the decipherment of the German messages encrypted with the Enigma machine in the Bletchley Park Complex [1], [2]. The expression “the imitation game” is from Turing himself: these are the first words of his 1950 article, Computing Machinery and Intelligence [3]. It is also the name of a game played by the Victorian aristocracy, which consisted in a blind exchange of handwritten messages to try to guess whether the interlocutor was a woman or a man.",0.0
290,COVID Down Under: where did Australia's pandemic apps go wrong?,S. Cohney; M. Cheong,ieee,10.1109/ETHICS57328.2023.10154912,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10154912,"Governments and businesses worldwide deployed a variety of technological measures to help prevent and track the spread of COVID-19. In Australia, these applications contained usability, accessibility, and security flaws that hindered their effectiveness and adoption. Australia, like most countries, has transitioned to treating COVID as endemic. However it is yet to absorb lessons from the technological issues with its approach to the pandemic. In this short paper we a) provide a systematization of the most notable events; b) identify and review different failure modes of these applications; and c) develop recommendations for developing apps in the face of future crises. Our work focuses on a single country. However, Australia's issues are particularly instructive as they highlight surprisingly pitfalls that countries should address in the face of a future pandemic.",0.0
291,The Design of Online Cluster Framework for Infectious Disease Nursing Courses in the Era of Big Data,X. -H. Yang,ieee,10.1109/ICESC54411.2022.9885606,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9885606,"Infectious disease nursing curriculum ideological and political is to combine the infectious disease nursing curriculum with the content of ideological and moral education, and organically combine the two in the practice of ideological and political education. The fundamental is morality, and the core is to cultivate people. The reform of ideological and political teaching of infectious disease nursing courses follows the characteristics of nursing humanistic care education, and explores new models of moral education for nursing students. Explore the ideological and political design of infectious disease nursing courses from the three aspects of teaching objectives, teaching content and teaching methods to achieve the purpose of establishing morality.",0.0
292,Vulnerability Assessment for Applications Security Through Penetration Simulation and Testing,P. Lachkov; L. Tawalbeh; S. Bhatt,ieee,10.13052/jwe1540-9589.2178,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10251051,"Cybersecurity threats and attacks are a critical concern for computing systems as general and specifically in web applications. There are many types and categories of cyberattacks on web applications. Many of these attacks are made possible due to existing vulnerabilities in the networking environments and platforms that host these web applications. So, the vulnerability assessment and attacks simulations on these networking platforms are of extreme importance to protect and secure the top web applications that play a prime role in our daily life. One of the widely used mechanisms to identify vulnerabilities and defend against different attacks on systems and networks is Penetration Testing. It allows us to simulate real-world attacks on a network or a single device to determine the susceptibility and impact of cybersecurity attacks. Pen testing aims to secure a system or network by performing a full-blown attack against it. Several techniques have been used for that, from port scanning, service, and operating system detection to network enumeration, creating specially crafted packets, and modifying software to exploit vulnerabilities. However, while it is used widely as a defensive technique, some attackers also employ it for malicious intentions utilizing available open-source penetration testing tools. Penetration testing on internal networks such as networks that connect IoT/sensors/web cameras, can be utilized to find vulnerabilities and fix them to secure the networks. In this research, we present a detailed discussion on penetration testing and its seven phases of action and provide a step-by-step procedure with instructions using various open-source tools to conduct penetration testing and vulnerability assessments of a network. We finally demonstrate the process and results of simulated attacks on our network within the testing environment. This research provides a comprehensive introduction to penetration testing and testbed through real-world attack simulation. The IT administrator or security enthusiast can utilize them to secure networks, devices, clients, servers, and applications while enhancing the overall organization's security.",0.0
293,Research on the Entry Point of Curriculum Ideology and Politics in the Teaching of Computer Programming,H. Li; M. Zhang; C. Li,ieee,10.1109/ICEKIM52309.2021.00069,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9479515,"Computer programming course is a wide range of computer language courses. In computer programming, mathematical algorithms are used to summarize the problems, simplify the relatively complex problems and summarize the rules, and then carry out further calculation and obtain the final results. They are widely used in embedded development, large desktop applications and game development, artificial intelligence and other fields. In college teaching, the teaching of computer programming language is popular and important. However the main goal in traditional teaching is to impart professional knowledge, complete the “teaching” part, but it often ignore the “education” link. In teaching process, we should take moral education as our goal, integrate the socialist core values, reform the teaching contents and methods. It will finally realize the organic combination of core values and professional courses. Combing with the requirements of Ideological and political curriculum, the starting point and integration methods of Ideological and political curriculum are discussed in this essay.",0.0
294,Measurement and Applications: Technology Enabling Aging in Place - The Supportive Smart Home,B. Wallace; F. Knoefel; R. Goubran; H. Sveistrup; N. Thomas,ieee,10.1109/MIM.2023.10238391,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10238391,"Most people as they age, wish to do so with as much independence as possible, to remain in their homes and communities with the health and social services required [1]. This is known as aging-in-place, and it has many benefits for the aging adult as they remain connected to the places and people they know. With aging-in-place, older adults are more likely to be socially, cognitively and physically active. For many healthcare systems, this can also be a benefit by delaying or avoiding institutional residential care with a subsequent reduction in system demand. Aging-in-place does not come without a cost or challenges as many aging adults need the support of formal and informal caregivers. For the latter, this tends to be family members [2].",0.0
295,A Deep Learning Localization Method for Measuring Abdominal Muscle Dimensions in Ultrasound Images,A. Saleh; I. H. Laradji; C. Lammie; D. Vazquez; C. A. Flavell; M. R. Azghadi,ieee,10.1109/JBHI.2021.3085019,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9444630,"Health professionals extensively use Two-Dimensional (2D) Ultrasound (US) videos and images to visualize and measure internal organs for various purposes including evaluation of muscle architectural changes. US images can be used to measure abdominal muscles dimensions for the diagnosis and creation of customized treatment plans for patients with Low Back Pain (LBP), however, they are difficult to interpret. Due to high variability, skilled professionals with specialized training are required to take measurements to avoid low intra-observer reliability. This variability stems from the challenging nature of accurately finding the correct spatial location of measurement endpoints in abdominal US images. In this paper, we use a Deep Learning (DL) approach to automate the measurement of the abdominal muscle thickness in 2D US images. By treating the problem as a localization task, we develop a modified Fully Convolutional Network (FCN) architecture to generate blobs of coordinate locations of measurement endpoints, similar to what a human operator does. We demonstrate that using the TrA400 US image dataset, our network achieves a Mean Absolute Error (MAE) of 0.3125 on the test set, which almost matches the performance of skilled ultrasound technicians. Our approach can facilitate next steps for automating the process of measurements in 2D US images, while reducing inter-observer as well as intra-observer variability for more effective clinical outcomes.",0.0
296,Gradient-Based Learning of Discrete Structured Measurement Operators for Signal Recovery,J. Sauder; M. Genzel; P. Jung,ieee,10.1109/JSAIT.2022.3221644,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9946400,"Countless signal processing applications include the reconstruction of signals from few indirect linear measurements. The design of effective measurement operators is typically constrained by the underlying hardware and physics, posing a challenging and often even discrete optimization task. While the potential of gradient-based learning via the unrolling of iterative recovery algorithms has been demonstrated, it has remained unclear how to leverage this technique when the set of admissible measurement operators is structured and discrete. We tackle this problem by combining unrolled optimization with Gumbel reparametrizations, which enable the computation of low-variance gradient estimates of categorical random variables. Our approach is formalized by GLODISMO (Gradient-based Learning of DIscrete Structured Measurement Operators). This novel method is easy-to-implement, computationally efficient, and extendable due to its compatibility with automatic differentiation. We empirically demonstrate the performance and flexibility of GLODISMO in several prototypical signal recovery applications, verifying that the learned measurement matrices outperform conventional designs based on randomization as well as discrete optimization baselines.",0.0
297,Trustworthy AI—Part 1,R. Mariani; F. Rossi; R. Cucchiara; M. Pavone; B. Simkin; A. Koene; J. Papenbrock,ieee,10.1109/MC.2022.3227683,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10042078,"To improve the trustworthiness of artificial intelligence systems, organizations should address the risks relevant to the use case whilst taking into account the stakeholders that interact directly or indirectly with the system.",0.0
298,UCDFormer: Unsupervised Change Detection Using a Transformer-Driven Image Translation,Q. Xu; Y. Shi; J. Guo; C. Ouyang; X. X. Zhu,ieee,10.1109/TGRS.2023.3305334,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10251124,"Change detection (CD) by comparing two bitemporal images is a crucial task in remote sensing. With the advantages of requiring no cumbersome labeled change information, unsupervised CD has attracted extensive attention in the community. However, existing unsupervised CD approaches rarely consider the seasonal and style differences incurred by the illumination and atmospheric conditions in multitemporal images. To this end, we propose a CD with a domain shift setting for remote sensing images. Furthermore, we present a novel unsupervised CD method using a lightweight transformer, called UCDFormer. Specifically, a transformer-driven image translation composed of a lightweight transformer and a domain-specific affinity weight is first proposed to mitigate domain shift between two images with real-time efficiency. After image translation, we can generate the difference map between the translated before-event image and the original after-event image. Then, a novel reliable pixel extraction module is proposed to select significantly changed/unchanged pixel positions by fusing the pseudochange maps of fuzzy c-means clustering and adaptive threshold. Finally, a binary change map is obtained based on these selected pixel pairs and a binary classifier. Experimental results on different unsupervised CD tasks with seasonal and style changes demonstrate the effectiveness of the proposed UCDFormer. For example, compared with several other related methods, UCDFormer improves performance on the Kappa coefficient by more than 12%. In addition, UCDFormer achieves excellent performance for earthquake-induced landslide detection when considering large-scale applications. The code is available at https://github.com/zhu-xlab/UCDFormer.",0.0
299,IEEE Standard for Transparency of Autonomous Systems,,ieee,10.1109/IEEESTD.2022.9726144,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9726144,"Measurable, testable levels of transparency, so that autonomous systems can be objectively assessed, and levels of compliance determined, are described in this standard. (The PDF of this standard is available in the IEEE GET program at https://ieeexplore.ieee.org/browse/standards/get-program/page/series?id=93)",0.0
300,Fostering students’ engineering competence by adopting augmented reality: a proposed randomized controlled trial study,B. Sichterman; M. Verstappen; A. Bonnes; D. Ter Haar; S. van Ginkel,ieee,10.1109/AIVR56993.2022.00055,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10024441,"Developing students’ engineering competence is an essential objective in engineering education. However, delivering effective and just-in-time instruction is under pressure due to the need to offer personalized learning and the existence of trainer shortages in the engineering sector. Recent developments in educational technology allow alternative innovative sources, such as Augmented Reality (AR), to imitate real-life situations and to offer learning activities which supports students to practice their skills in a safe environment. However, limited experimental studies have been reported that provide insights into the impact of AR-based learning activities on students’ development of engineering competence in comparison to traditional teaching approaches. Therefore, this proposed experimental study aims to investigate the effect of an AR-based learning activity, which involves solving the malfunction of an air handling unit, on students’ development of engineering competence. This experimental condition will be compared to traditional teaching approaches, consisting of an identical learning task including books and written exercises. Additionally, cognitive load, intrinsic motivation and students’ perceptions towards the learning task and learning environment are included, seeing that these aspects are considered to be crucial intermediate variables in learning processes. Results of this study provide insights in the effectivity of AR-based learning environments in engineering education supporting students’ hands-on experience, while releasing the pressure on resources such as industrial devices and staffing.",0.0
301,A Deep Active Contour Model for Delineating Glacier Calving Fronts,K. Heidler; L. Mou; E. Loebel; M. Scheinert; S. Lefèvre; X. X. Zhu,ieee,10.1109/TGRS.2023.3296539,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10195954,"Choosing how to encode a real-world problem as a machine learning task is an important design decision in machine learning. The task of the glacier calving front modeling has often been approached as a semantic segmentation task. Recent studies have shown that combining segmentation with edge detection can improve the accuracy of calving front detectors. Building on this observation, we completely rephrase the task as a contour tracing problem and propose a model for explicit contour detection that does not incorporate any dense predictions as intermediate steps. The proposed approach, called “Charting Outlines by Recurrent Adaptation” (COBRA), combines convolutional neural networks (CNNs) for feature extraction and active contour (AC) models for delineation. By training and evaluating several large-scale datasets of Greenland’s outlet glaciers, we show that this approach indeed outperforms the aforementioned methods based on segmentation and edge-detection. Finally, we demonstrate that explicit contour detection has benefits over pixel-wise methods when quantifying the models’ prediction uncertainties. The project page containing the code and animated model predictions can be found at https://khdlr.github.io/COBRA/.",0.0
302,Adaptive Switching Control Based on Dynamic Zero-Moment Point for Versatile Hip Exoskeleton Under Hybrid Locomotion,Y. Miao; X. Wang; S. Wang; R. Li,ieee,10.1109/TIE.2022.3229343,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9994725,"In this article, an adaptive switching controller based on the dynamic zero-moment point for versatile hip exoskeleton is proposed. The linear finite hysteretic state machine is designed to recognize hybrid motion phases. The torque planning strategy based on dynamic zero-moment point is deployed to obtain assistant torque adaptively under different locomotion. Experiments are carried out to verify the performance of the controller, confirming the stability and accuracy of the motion phase recognition, which also demonstrates excellent kinematic performance. The net metabolic rate can be reduced by 6.93% while wearing the versatile hip exoskeleton walking. The integrated surface electromyography can be reduced by 54.8% while wearing the exoskeleton lifting objects. Compared with existing research, the performance of the proposed controller has significant advantages. The proposed controller is capable of multiple types of locomotion, including flat walking, stair climbing, and lifting heavy objects with low complexity and energy consumption.",0.0
303,Fairness Under Feature Exemptions: Counterfactual and Observational Measures,S. Dutta; P. Venkatesh; P. Mardziel; A. Datta; P. Grover,ieee,10.1109/TIT.2021.3103206,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9508964,"With the growing use of machine learning algorithms in highly consequential domains, the quantification and removal of disparity in decision making with respect to protected attributes, such as gender, race, etc., is becoming increasingly important. While quantifying disparity is essential, sometimes the needs of a business (e.g., hiring) may require the use of certain features that are critical in a way that any disparity that can be explained by them might need to be exempted. For instance, in hiring a software engineer for a safety-critical application, a coding-test score may be a critical feature that is weighed strongly in the decision even if it introduces disparity, whereas other features, such as name, zip code, or reference letters may be used to improve decision-making, but only to the extent that they do not add disparity. In this work, we propose a novel information-theoretic decomposition of the total disparity (a quantification inspired from counterfactual fairness) into two components: a non-exempt component which quantifies the part of the disparity that cannot be accounted for by the critical features, and an exempt component which quantifies the remaining disparity. This decomposition is important: it allows one to check if the disparity arose purely due to the critical features (inspired from the business necessity defense of disparate impact law) and also enables selective removal of the non-exempt component of disparity if desired. We arrive at this decomposition through canonical examples that lead to a set of desirable properties (axioms) that any measure of non-exempt disparity should satisfy. We then demonstrate that our proposed counterfactual measure of non-exempt disparity satisfies all of them. Our quantification bridges ideas of causality, Simpson's paradox, and a body of work from information theory called Partial Information Decomposition (PID). We also obtain an impossibility result showing that no observational measure of non-exempt disparity can satisfy all of the desired properties, which leads us to relax our goals and examine alternative observational measures that satisfy only some of these properties. We perform case studies to show how one can audit existing models as well as train new models while reducing non-exempt disparity.",0.0
304,The Milestones of IEEE TIV: The Best Associate Editors and George N. Saridis Best Papers Awards,F. -Y. Wang,ieee,10.1109/TIV.2022.3227617,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9991940,Presents the recipients of ITSS society awards.,0.0
305,Basis Pursuit Denoising via Recurrent Neural Network Applied to Super-Resolving SAR Tomography,K. Qian; Y. Wang; P. Jung; Y. Shi; X. X. Zhu,ieee,10.1109/TGRS.2022.3221185,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9969379,"Finding sparse solutions of underdetermined linear systems commonly requires the solving of  $L_{1}$  regularized least-squares minimization problem, which is also known as the basis pursuit denoising (BPDN). They are computationally expensive since they cannot be solved analytically. An emerging technique known as deep unrolling provided a good combination of the descriptive ability of neural networks, explainable, and computational efficiency for BPDN. Many unrolled neural networks for BPDN, e.g., learned iterative shrinkage thresholding algorithm and its variants, employ shrinkage functions to prune elements with small magnitude. Through experiments on synthetic aperture radar tomography (TomoSAR), we discover the shrinkage step leads to unavoidable information loss in the dynamics of networks and degrades the performance of the model. We propose a recurrent neural network (RNN) with novel sparse minimal gated units (SMGUs) to solve the information loss issue. The proposed RNN architecture with SMGUs benefits from incorporating historical information into optimization and, thus, effectively preserves full information in the final output. Taking TomoSAR inversion as an example, extensive simulations demonstrated that the proposed RNN outperforms the state-of-the-art deep learning-based algorithm in terms of super-resolution power and generalization ability. It achieved 10%–20% higher double-scatterer detection rate and is less sensitive to phase and amplitude ratio difference between scatterers. Test on real TerraSAR-X spotlight images also shows the high-quality 3-D reconstruction of the test site.",0.0
306,Change Detection Meets Visual Question Answering,Z. Yuan; L. Mou; Z. Xiong; X. X. Zhu,ieee,10.1109/TGRS.2022.3203314,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9901476,"The Earth’s surface is continually changing, and identifying changes plays an important role in urban planning and sustainability. Although change detection techniques have been successfully developed for many years, these techniques are still limited to experts and facilitators in related fields. In order to provide every user with flexible access to change information and help them better understand land-cover changes, we introduce a novel task: change detection-based visual question answering (CDVQA) on multitemporal aerial images. In particular, multitemporal images can be queried to obtain high-level change-based information according to content changes between two input images. We first build a CDVQA dataset, including multitemporal image–question–answer triplets using an automatic question–answer generation method. Then, a baseline CDVQA framework is devised in this work, and it contains four parts: multitemporal feature encoding, multitemporal fusion, multimodal fusion, and answer prediction. In addition, we also introduce a change enhancing module to multitemporal feature encoding, aiming at incorporating more change-related information. Finally, the effects of different backbones and multitemporal fusion strategies are studied on the performance of CDVQA task. The experimental results provide useful insights for developing better CDVQA models, which are important for future research on this task. The dataset will be available at https://github.com/YZHJessica/CDVQA.",0.0
307,Building Footprint Generation Through Convolutional Neural Networks With Attraction Field Representation,Q. Li; L. Mou; Y. Hua; Y. Shi; X. X. Zhu,ieee,10.1109/TGRS.2021.3109844,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9538384,"Building footprint generation is a vital task in a wide range of applications, including, to name a few, land use management, urban planning and monitoring, and geographical database updating. Most existing approaches addressing this problem fall back on convolutional neural networks (CNNs) to learn semantic masks of buildings. However, one limitation of their results is blurred building boundaries. To address this, we propose to learn attraction field representation for building boundaries, which is capable of providing an enhanced representation power. Our method comprises two elemental modules: an Img2AFM module and an AFM2Mask module. More specifically, the former aims at learning an attraction field representation conditioned on an input image, which is capable of enhancing building boundaries and suppressing the background. The latter module predicts segmentation masks of buildings using the learned attraction field map. The proposed method is evaluated on three datasets with different spatial resolutions: the ISPRS dataset, the INRIA dataset, and the Planet dataset. From experimental results, we find that the proposed framework can well preserve geometric shapes and sharp boundaries of buildings, which brings significant improvements over other competitors. The trained model and code are available at https://github.com/lqycrystal/AFM_building.",0.0
308,Personality and Emotion in Strong-Story Narrative Planning,A. Shirvani; S. G. Ware; L. J. Baker,ieee,10.1109/TG.2022.3227220,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9971749,"Believable characters are core elements of a coherent story. Qualities that make story characters more believable include goals, beliefs, personality, and emotion. We propose computational models of emotion and personality by adapting the OCC model of emotion and the Five Factor personality model. Our models are formulated into multi-agent strong-story narrative planning with the promise of being highly reusable and domain independent. We evaluate these models using multiple human subject studies. We show that our model's reasoning about character emotions matches the expectations of human readers, and using our emotion model, we can generate a larger set of stories than precedent narrative planners. We also demonstrate that human readers can perceive and recognize the personalities of story characters through their consistent behavior generated by our model. Our final experiment supports that human readers significantly find the behavior generated by our models of emotion and personality more believable than behavior that lacks either or both.",0.0
309,To Honor our Heroes: Analysis of the Obituaries of Australians Killed in Action in WWI and WWII,M. Cheong; M. Alfano,ieee,10.1109/ICPR48806.2021.9413145,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9413145,"Obituaries represent a prominent way of expressing the human universal of grief. According to philosophers, obituaries are a ritualized way of evaluating both individuals who have passed away and the communities that helped to shape them. The basic idea is that you can tell what it takes to count as a good person of a particular type in a particular community by seeing how persons of that type are described and celebrated in their obituaries. Obituaries of those killed in conflict, in particular, are rich repositories of communal values, as they reflect the values and virtues that are admired and respected in individuals who are considered to be heroes in their communities. In this paper, we use natural language processing techniques to map the patterns of values and virtues attributed to Australian military personnel who were killed in action during World War I and World War II. Doing so reveals several clusters of values and virtues that tend to be attributed together. In addition, we use named entity recognition and geotagging the track the movements of these soldiers to various theatres of the wars, including North Africa, Europe, and the Pacific.",0.0
310,Mitigating Unfairness via Evolutionary Multiobjective Ensemble Learning,Q. Zhang; J. Liu; Z. Zhang; J. Wen; B. Mao; X. Yao,ieee,10.1109/TEVC.2022.3209544,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9902997,"In the literature of mitigating unfairness in machine learning (ML), many fairness measures are designed to evaluate predictions of learning models and also utilized to guide the training of fair models. It has been theoretically and empirically shown that there exist conflicts and inconsistencies among accuracy and multiple fairness measures. Optimizing one or several fairness measures may sacrifice or deteriorate other measures. Two key questions should be considered: 1) how to simultaneously optimize accuracy and multiple fairness measures and 2) how to optimize all the considered fairness measures more effectively. In this article, we view the mitigating unfairness problem as a multiobjective learning problem, considering the conflicts among fairness measures. A multiobjective evolutionary learning framework is used to simultaneously optimize several metrics (including accuracy and multiple fairness measures) of ML models. Then, ensembles are constructed based on the learning models in order to automatically balance different metrics. Empirical results on eight well-known datasets demonstrate that compared with the state-of-the-art approaches for mitigating unfairness, our proposed algorithm can provide decision makers with better tradeoffs among accuracy and multiple fairness metrics. Furthermore, the high-quality models generated by the framework can be used to construct an ensemble to automatically achieve a better tradeoff among all the considered fairness metrics than other ensemble methods.",0.0
311,Gated Relational Encoder-Decoder Model for Target-Oriented Opinion Word Extraction,T. Kang; S. Kim; H. Yun; H. Lee; K. Jung,ieee,10.1109/ACCESS.2022.3228835,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9982601,"Target-Oriented Opinion Word Extraction (TOWE) is a challenging information extraction task that aims to find the opinion words corresponding to given opinion targets in text. To solve TOWE, it is important to consider the surrounding words of opinion words as well as the opinion targets. Although most existing works have captured the opinion target using Deep Neural Networks (DNNs), they cannot effectively utilize the local context, i.e. relationship among surrounding words of opinion words. In this work, we propose a novel and powerful model for TOWE, Gated Relational target-aware Encoder and local context-aware Decoder (GRED), which dynamically leverages the information of the opinion target and the local context. Intuitively, the target-aware encoder catches the opinion target information, and the local context-aware decoder obtains the local context information from the relationship among surrounding words. Then, GRED employs a gate mechanism to dynamically aggregate the outputs of the encoder and the decoder. In addition, we adopt a pretrained language model Bidirectional and Auto-Regressive Transformer (BART), as the structure of GRED to improve the implicit language knowledge. Extensive experiments on four benchmark datasets show that GRED surpasses all the baseline models and achieves state-of-the-art performance. Furthermore, our in-depth analysis demonstrates that GRED properly leverages the information of the opinion target and the local context for extracting the opinion words.",0.0
312,DimCL: Dimensional Contrastive Learning for Improving Self-Supervised Learning,T. Nguyen; T. X. Pham; C. Zhang; T. M. Luu; T. Vu; C. D. Yoo,ieee,10.1109/ACCESS.2023.3236087,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10014996,"Self-supervised learning (SSL) has gained remarkable success, for which contrastive learning (CL) plays a key role. However, the recent development of new non-CL frameworks has achieved comparable or better performance with high improvement potential, prompting researchers to enhance these frameworks further. Assimilating CL into non-CL frameworks has been thought to be beneficial, but empirical evidence indicates no visible improvements. In view of that, this paper proposes a strategy of performing CL along the dimensional direction instead of along the batch direction as done in conventional contrastive learning, named Dimensional Contrastive Learning (DimCL). DimCL aims to enhance the feature diversity, and it can serve as a regularizer to prior SSL frameworks. DimCL has been found to be effective, and the hardness-aware property is identified as a critical reason for its success. Extensive experimental results reveal that assimilating DimCL into SSL frameworks leads to performance improvement by a non-trivial margin on various datasets and backbone architectures.",0.0
313,On the Effectiveness of BGP Hijackers That Evade Public Route Collectors,A. Milolidakis; T. Bühler; K. Wang; M. Chiesa; L. Vanbever; S. Vissicchio,ieee,10.1109/ACCESS.2023.3261128,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10078883,"Routing hijack attacks have plagued the Internet for decades. After many failed mitigation attempts, recent Internet-wide BGP monitoring infrastructures relying on distributed route collection systems, called route collectors, give us hope that future monitor systems can quickly detect and ultimately mitigate hijacks. In this paper, we investigate the effectiveness of public route collectors with respect to future attackers deliberately engineering longer hijacks to avoid being recorded by route collectors. Our extensive simulations (and attacks we device) show that monitor-based systems may be unable to observe many carefully crafted hijacks diverting traffic from thousands of ASes. Hijackers could predict whether their attacks would propagate to some BGP feeders (i.e., monitors) of public route collectors. Then, manipulate BGP route propagation so that the attack never reaches those monitors. This observation remains true when considering plausible future Internet topologies, with more IXP links and up to 4 times more monitors peering with route collectors. We then evaluate the feasibility of performing hijacks not observed by route collectors in the real-world. We experiment with two classifiers to predict the monitors that are dangerous to report the attack to route collectors, one based on monitor proximities (i.e., shortest path lengths) and another based on Gao-Rexford routing policies. We show that a proximity-based classifier could be sufficient for the hijacker to identify all dangerous monitors for hijacks announced to peer-to-peer neighbors. For hijacks announced to transit networks, a Gao-Rexford classifier reduces wrong inferences by  $\ge 91\%$  without introducing new misclassifications for existing dangerous monitors.",0.0
314,Joint Path Alignment Framework for 3D Human Pose and Shape Estimation From Video,J. W. Hong; S. Yoon; J. Kim; C. D. Yoo,ieee,10.1109/ACCESS.2023.3271285,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10109716,"3D human pose and shape estimation (3D-HPSE) from video aims to generate sequence of 3D mesh that depict human body in the video. Current deep learning based 3D-HPSE networks that takes video input have focused on improving temporal consistency among sequence of 3D joints by supervising acceleration error between predicted and ground-truth human motion. However, these methods overlooked the geometric misalignments of persistent discrepancy between geometric paths drawn by sequence of predicted joints and that of ground-truth joints. To this end, we propose Joint Path Alignment (JPA) framework, a model-agnostic approach that mitigates geometric misalignments by introducing Temporal Procrustes Alignment Regularization (TPAR) loss that performs group-wise sequence learning of joint movement paths. Unlike previous methods that rely solely on per-frame supervision for accuracy, our framework adds sequence-level accuracy supervision with TPAR loss by performing Procrustes analysis on the geometric paths drawn by sequences of predicted joints. Our experiments show that JPA framework advances the network to exceed the previous state-of-the-art performances on benchmark datasets in both per-frame accuracy and video smoothness metric.",0.0
315,THE Benchmark: Transferable Representation Learning for Monocular Height Estimation,Z. Xiong; W. Huang; J. Hu; X. X. Zhu,ieee,10.1109/TGRS.2023.3311764,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10251159,"Generating 3-D city models rapidly is crucial for many applications. Monocular height estimation (MHE) is one of the most efficient and timely ways to obtain large-scale geometric information. However, existing works focus primarily on training and testing models using unbiased datasets, which does not align well with real-world applications. Therefore, we propose a new benchmark dataset to study the transferability of height estimation models in a cross-dataset setting. To this end, we first design and construct a large-scale benchmark dataset for cross-dataset transfer learning on the height estimation task. This benchmark dataset includes a newly proposed large-scale synthetic dataset, a newly collected real-world dataset, and four existing datasets from different cities. Next, a new experimental protocol, few-shot cross-dataset transfer, is designed. Furthermore, in this article, we propose a scale-deformable convolution (SDC) module to enhance the window-based Transformer for handling the scale-variation problem in the height estimation task. Experimental results have demonstrated the effectiveness of the proposed methods in traditional and cross-dataset transfer settings. The datasets and codes are publicly available at https://mediatum.ub.tum.de/1662763 and https://thebenchmarkh.github.io/.",0.0
316,Concerns in the Blurred Divisions Between Medical and Consumer Neurotechnology,A. Y. Paek; J. A. Brantley; B. J. Evans; J. L. Contreras-Vidal,ieee,10.1109/JSYST.2020.3032609,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9298858,"Neurotechnology has traditionally been central to the diagnosis and treatment of neurological disorders. While these devices have initially been utilized in clinical and research settings, recent advancements in neurotechnology have yielded devices that are more portable, user friendly, and less expensive. These improvements allow laypeople to monitor their brain waves and interface their brains with external devices. Such improvements have led to the rise of wearable neurotechnology that is marketed to the consumer. While many of the consumer devices are marketed for innocuous applications, such as use in video games, there is potential for them to be repurposed for medical uses. How do we manage neurotechnologies that skirt the line between medical and consumer applications and what can be done to ensure consumer safety? Here, we characterize neurotechnology based on medical and consumer applications and summarize currently marketed uses of consumer-grade wearable headsets. We lay out concerns that may arise due to the similar claims associated with both medical and consumer devices, the possibility of consumer devices being repurposed for medical uses, and the potential for medical uses of neurotechnology to influence commercial markets related to employment and self-enhancement.",0.0
