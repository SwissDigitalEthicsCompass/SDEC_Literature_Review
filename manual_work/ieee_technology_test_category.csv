,Unnamed: 0.2,Category,Unnamed: 0.1,Unnamed: 0,Title,Publication Title,Volume,Issue,DOI,Authors,Publication Year,URL,Type,Abstract,Keywords,Author Affiliations,Date Added To Xplore,Unnamed: 13,Unnamed: 14,Start Page,End Page,ISSN,ISBNs,Funding Information,IEEE Terms,INSPEC Controlled Terms,INSPEC Non-Controlled Terms,Mesh_Terms,Article Citation Count,Reference Count,License,Online Date,Publisher,Eligibility_Abstract_Score,Eligibility_Keywords_Score,Eligibility_Title_Score,Eligibility_Score
0,0.0,technology,0.0,0.0,An Integrated Framework for Ethical and Sustainable Digitalization,2021 Eighth International Conference on eDemocracy & eGovernment (ICEDEG),,,10.1109/ICEDEG52154.2021.9530972,I. Wallimann-Helmer; L. Terán; E. Portmann; H. Schübel; J. Pincay,2021.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9530972,IEEE Conferences,"Dynamically developing digitization initiatives among public institutions and private companies necessitate a balanced approach to digital ethics. Several frameworks and legal regulations have been adopted to clarify and define the various ethical challenges in digital contexts. These initiatives often accentuate one of three components: data security, data governance, or digital strategy. However, an integrated approach is required to meet the current demand for an ethical and sustainable approach to digitalization and address the growing number of challenges occurring in handling data and related peripheral components. This paper develops the concept of an integrated framework to incorporate all relevant aspects of digital ethics by combining three categories of digital contexts: law and regulations, ethics and justice, and environmental sustainability. The core of this integrated framework, the Fribourg sustainable digital ethics framework (FSDEF), consists of two boundary conditions of sustainable development: social thresholds of justice and ecological planetary boundaries. It also incorporates numerous other frameworks and standards, including value-based engineering and IEEE standards.",Digital ethics;sustainability;corporate digital responsibility,"UniFR_ESH Institute, University of Fribourg, Fribourg, Switzerland; Human-IST Insitute, University of Fribourg, Fribourg, Switzerland; Human-IST Insitute, University of Fribourg, Fribourg, Switzerland; UniFR_ESH Institute, University of Fribourg, Fribourg, Switzerland; Human-IST Insitute, University of Fribourg, Fribourg, Switzerland",13 Sep 2021,,,156.0,162.0,2573-1998,978-1-6654-2512-4,,Ethics;Law;Data security;Green products;Companies;IEEE Standards;Regulation,data governance;environmental factors;ethical aspects;IEEE standards;law;public administration;security of data;sustainable development,sustainable digitalization;digitization initiatives;legal regulations;data security;data governance;digital strategy;peripheral components;justice;environmental sustainability;Fribourg sustainable digital ethics framework;sustainable development;ethical digitalization;data handling;law;regulations;ethics;FSDEF;value-based engineering;IEEE standards;public institutions;private companies,,2.0,20.0,IEEE,13 Sep 2021,IEEE,0.1925465838509316,1.25,0.375,0.2505032957755626
1,1.0,technology,1.0,1.0,AI Ethics in Smart Healthcare,IEEE Consumer Electronics Magazine,12,4.0,10.1109/MCE.2022.3220001,S. Pasricha,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9940606,IEEE Magazines,"This article reviews the landscape of ethical challenges of integrating artificial intelligence (AI) into smart healthcare products, including medical electronic devices. Differences between traditional ethics in the medical domain and emerging ethical challenges with AI-driven healthcare are presented, particularly as they relate to transparency, bias, privacy, safety, responsibility, justice, and autonomy. Open challenges and recommendations are outlined to enable the integration of ethical principles into the design, validation, clinical trials, deployment, monitoring, repair, and retirement of AI-based smart healthcare products.",,"Colorado State University, Fort Collins, CO, USA",6 Jun 2023,,,12.0,20.0,2162-2256,,National Science Foundation(grant numbers:CNS-2132385); ,Artificial intelligence;Ethics;Medical services;Medical diagnostic imaging;Consumer electronics;Behavioral sciences;Safety,artificial intelligence;ethical aspects;health care,AI ethics;AI-based smart healthcare products;AI-driven healthcare;artificial intelligence;ethical principles;medical domain;medical electronic devices,,,38.0,IEEE,7 Nov 2022,IEEE,0.2,0.0,0.6,0.217339312406577
2,2.0,technology,2.0,2.0,The Concept of Ethical Digital Identities,2022 IEEE/ACM 1st International Workshop on Software Engineering for Responsible Artificial Intelligence (SE4RAI),,,10.1145/3526073.3527586,E. Cioroaica; B. Buhnova; F. Jacobi; D. Schneider,2022.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9808646,IEEE Conferences,"Dynamic changes within the cyberspace are greatly impacting human lives and our societies. Emerging evidence indicates that without an ethical overlook on technological progress, intelligent solutions created to improve and enhance our lives can easily be turned against humankind. In complex AI-socio-technical ecosystems where humans, AI (Artificial Intelligence) and systems interact without a common language for building trust, this paper introduces a methodological concept of Ethical Digital Identities for supporting the ethical evaluation of intelligent digital assets.",Ethics;Morality;Engineering;AI;Trust;Process;Architecture,"Fraunhofer IESE, Kaiserslautern, Germany; Masaryk University, Brno, Czech Republic; Formitas AG, Aachen, Germany; Fraunhofer IESE, Kaiserslautern, Germany",30 Jun 2022,,,17.0,20.0,,978-1-4503-9319-5,,Ethics;Conferences;Ecosystems;Buildings;Cyberspace;Artificial intelligence;Software engineering,artificial intelligence;ethical aspects;social aspects of automation,dynamic changes;cyberspace;impacting human lives;emerging evidence;technological progress;intelligent solutions;AI-socio-technical ecosystems;artificial intelligence;methodological concept;ethical evaluation;intelligent digital assets;ethical digital identities,,,29.0,,30 Jun 2022,IEEE,0.1948051948051948,0.0,0.8333333333333334,0.2171066113373806
3,3.0,technology,3.0,3.0,Ethical Framework Associated with AI,Societal Responsibility of Artificial Intelligence: Towards an Ethical and Eco-responsible AI,,,10.1002/9781119831808.ch3,,2021.0,https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9823054.pdf&bkn=9820928&pdfType=chapter,Wiley Data and Cybersecurity eBook Chapters,"Ethics is a bridge between the innate and the acquired for our social behaviors and our intelligence. The ethics charter promotes the construction of an environmental ethic by introducing fundamental ethical principles that apply to the organization as well as to managers and employees. This charter aims to give all actors involved in artificial intelligence (AI) the ethical, legal and technical foundations useful and necessary for the design, implementation and correct use. The development of AI requires us to invent new knowledge, new know‐how and new ways of living with these new technologies. The chapter focuses on the five stages of ethics, namely ethics of data, ethics of systems, ethics of algorithms, ethics of practice and ethics of decisions. A notable complexity in the health field lies in the direct use by users, without the intervention of health personnel, of certain applications or devices using AI on health data or collecting health data.",,,,,,91.0,165.0,,9781119831792,,Ethics;Artificial intelligence;Medical services;Companies;Technological innovation;Standards organizations;Law,,,,,,,12 Jul 2022,Wiley,0.1830065359477124,0.0,0.8,0.2051518646674356
4,4.0,technology,4.0,4.0,Proposed Model of Work Ethics in Artificial Intelligence and Emerging Digital Technologies,2022 ASU International Conference in Emerging Technologies for Sustainability and Intelligent Systems (ICETSIS),,,10.1109/ICETSIS55481.2022.9888900,S. H. Aldulaimi; M. M. Abdeldayem; M. Y. Abo Keir; M. Abdelhakim,2022.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9888900,IEEE Conferences,"The digital revolution witnessed by human civilization and technological development increases the degree of complexity and takes global dimensions, with many challenges and ethical problems. This research deals with digital ethics from a philosophical side, which must be taken into consideration in light of the reign of the digital age in order to solve and avoid emerging ethical problems. The research draws attention to the need to think beyond the facts and theories related to the current standards for the formation of moral awareness. That calls for and emphasizes the need to spread the culture of information and ethics. The findings of this paper led to propose a practical model to imagine the formation of the ethical model in the digital era consisting of several factors.",Work Ethics;Emerging Digital Technologies;Artificial Intelligence;Literature review,"College of Administrative Sciences, Applied Science University, Bahrain; College of Administrative Sciences Applied Science University (ASU), Bahrain; College of Administrative Sciences, Applied Science University (ASU), Kingdom of Bahrain; Canadian University, Dubai, UAE",26 Sep 2022,,,337.0,345.0,,978-1-6654-6919-7,,Ethics;Humanities;Technological innovation;Philosophical considerations;Standards organizations;Organizations;Cultural differences,artificial intelligence;ethical aspects;professional aspects;social aspects of automation,artificial intelligence;digital age;digital era;digital ethics;digital revolution;emerging digital technologies;ethical model;ethical problems;global dimensions;human civilization;technological development;work ethics,,,30.0,IEEE,26 Sep 2022,IEEE,0.1666666666666666,0.3333333333333333,0.3333333333333333,0.1966701352757544
5,6.0,technology,6.0,6.0,AI Ethics Impact Assessment based on Requirement Engineering,2022 IEEE 30th International Requirements Engineering Conference Workshops (REW),,,10.1109/REW56159.2022.00037,I. Nitta; K. Ohashi; S. Shiga; S. Onodera,2022.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9920150,IEEE Conferences,"This paper proposes a methodology for evaluating the ethical impact of artificial intelligence (AI) systems on people and society based on AI ethics guidelines. The ethical impact of AI has been recognized as a social issue, and countries and organizations have formulated principles and guidelines on AI ethics, and laws and regulations will be enforced in Europe. Because these principles and guidelines are written in terms of philosophy and law, AI service providers, developers, and business users have the challenge of how they should practice the principles and guidelines to their AI systems. To address this challenge, we first analyzed cases of ethical problems caused by AI in the past and assumed that ethical problems could be linked to interactions between components of AI systems and stakeholders related to such systems. On the basis of this assumption, we then developed a methodology to comprehensively extract the ethical risks that an AI system poses. This methodology consists of two approaches. The first approach is to develop an AI ethics model that embodies ethics guidelines as necessary requirements for ethical AI systems and correlates these requirements with interactions. The second approach is an impact assessment process that uses the AI ethics models to extract ethical risks for individual AI systems. In this paper, we discuss the details of this methodology and show the results of an initial validation to verify the above assumption and the ease of the impact assessment process.",AI ethics;AI governance;responsible AI;impact assessment;risk-based approach,"Fujitsu Limited, Kawasaki, Japan; Fujitsu Limited, Kawasaki, Japan; Fujitsu Limited, Kawasaki, Japan; Fujitsu Limited, Kawasaki, Japan",20 Oct 2022,,,152.0,161.0,2770-6834,978-1-6654-6000-2,Stanford University; ,Ethics;Philosophical considerations;Conferences;Europe;Organizations;Regulation;Requirements engineering,artificial intelligence;ethical aspects,artificial intelligence systems;AI ethics guidelines;AI service providers;ethical risks;ethical AI systems;AI ethics impact assessment;requirement engineering,,2.0,27.0,IEEE,20 Oct 2022,IEEE,0.1841004184100418,0.1666666666666666,0.375,0.1902169701992332
6,7.0,technology,7.0,7.0,Exploring Approaches to Artificial Intelligence Governance: From Ethics to Policy,"2023 IEEE International Symposium on Ethics in Engineering, Science, and Technology (ETHICS)",,,10.1109/ETHICS57328.2023.10155067,D. Kim; Q. Zhu; H. Eldardiry,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155067,IEEE Conferences,"There has been a trend among various stakeholders for AI governance, such as the government, industry, and academia, that advocates for a shift from AI ethics to AI policy. In this paper, we briefly introduce the motivation for such a change and two complementary reports about AI ethics policy development to help AI ethics researchers operationalize abstract AI ethics principles into actionable policy items. We also discuss the implications of the policy approach to AI governance for training the next generation of AI professionals.",AI Governance;AI Policy;AI Ethics;Responsible AI;AI Education,"Department of Engineering Education, Virginia Tech, Blacksburg, USA; Department of Engineering Education, Virginia Tech, Blacksburg, USA; Department of Computer Science, Virginia Tech, Blacksburg, USA",23 Jun 2023,,,1.0,5.0,,978-1-6654-5713-2,,Training;Industries;Ethics;Government;Market research;Stakeholders;Artificial intelligence,artificial intelligence;ethical aspects,abstract AI ethics principles;actionable policy items;AI ethics policy development;AI ethics researchers;AI governance;AI policy;AI professionals;artificial intelligence governance;government;policy approach,,,21.0,IEEE,23 Jun 2023,IEEE,0.1904761904761904,0.1666666666666666,0.2,0.1894747899159664
7,8.0,technology,8.0,8.0,Ethical Chatbot Design for Reducing Negative Effects of Biased Data and Unethical Conversations,2021 International Conference on Platform Technology and Service (PlatCon),,,10.1109/PlatCon53246.2021.9680760,J. Bang; S. Kim; J. W. Nam; D. -G. Yang,2021.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680760,IEEE Conferences,"AI technology is being introduced into various public and private service domains, transforming existing computing systems or creating new ones. While AI technologies can provide benefits to humans and society, the unexpected consequences (e.g., malfunctions) of AI systems can cause social losses. For this reason, research on ethical design for the development of AI-based systems is becoming important. In this paper, from existing studies on AI ethics, general guidelines such as transparency, explainability, predictability, accountability, fairness, privacy, and control for the ethical design of AI systems are reviewed. And, based on the ethical design guidelines, we discuss ethical design to reduce the negative effects of biased data and unethical dialogues in AI-based conversational chatbots.",conversational chatbot;ethical design;framework,"Electronics and Telecommunications Research Institute, Daejun, Republic of Korea; Ewha Womans University, Seoul, Republic of Korea; University of Science and Technology, Daejun, Republic of Korea; University of Science and Technology, Daejun, Republic of Korea",20 Jan 2022,,,1.0,5.0,,978-1-6654-1766-2,Korean National Police Agency; ,Ethics;Privacy;Systematics;Chatbots;Social factors;Stakeholders;Artificial intelligence,artificial intelligence;data privacy;ethical aspects;expert systems;law administration;natural language processing;software agents;virtual reality,ethical chatbot design;biased data;unethical conversations;AI technology;public service domains;private service domains;existing computing systems;AI systems;AI-based systems;AI ethics;privacy;ethical design guidelines;AI-based conversational chatbots,,7.0,33.0,IEEE,20 Jan 2022,IEEE,0.1842105263157894,0.0,0.3076923076923077,0.1874553779461243
8,9.0,technology,9.0,9.0,Why Do Companies Employ Prohibited Unethical Artificial Intelligence Practices?,IEEE Transactions on Engineering Management,PP,99.0,10.1109/TEM.2023.3258686,M. Méndez-Suárez; M. d. l. M. de Obesso; O. C. Márquez; C. M. Palacios,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10084347,IEEE Early Access Articles,"In this article, we investigate the previously unstudied reasons why companies use prohibited artificial intelligence (AI) applications and are punished with large fines under the European General Data Protection Regulation (GDPR). Investigating and understanding why companies engage in such severe AI ethical malpractices is essential to correct them as they seriously jeopardize the future development of AI. Based on a sample of 34 companies, out of which 23 were sanctioned under GDPR due to severe violations of AI ethical principles and using fuzzy-set qualitative comparative analysis, this study demonstrates that to be an AI ethical company and comply with the GDPR regulation, it is necessary to have an AI ethical statement, have a very strong concern for information cybersecurity, and have to be based in a country considered ethical or monitor with care the behavior of the firm in countries with lower ethical standards. As a theoretical contribution, although some authors argue that AI ethical principles are useless, the present research introduces a new theoretical perspective by demonstrating cause–effect relationships between business configurations and AI ethical failures. In addition, the results have an important managerial relevance because they show that lack of an AI ethical statement is the most relevant condition that led to ethical misbehaviors.",Artificial intelligence (AI) ethics;General Data Protection Regulation (GDPR) compliance;fuzzy-set qualitative comparative analysis (fsQCA);prohibited ai practices,"ESIC University, ESIC Business and Marketing School, Madrid, Spain; ESIC University, ESIC Business and Marketing School, Madrid, Spain; ESIC University, ESIC Business and Marketing School, Madrid, Spain; ESIC University, ESIC Business and Marketing School, Madrid, Spain",,,,1.0,10.0,1558-0040,,ESIC University(grant numbers:1-M-2017); ,Ethics;Companies;Artificial intelligence;Regulation;Behavioral sciences;Security;General Data Protection Regulation,,,,3.0,,IEEE,28 Mar 2023,IEEE,0.1941747572815534,0.2,0.0,0.1853137404945239
9,10.0,technology,10.0,10.0,Big Data in Business and Ethical Challenges,2021 International Conference on Information Management and Technology (ICIMTech),1,,10.1109/ICIMTech53080.2021.9534963,N. Zulkarnain; M. Anshari; M. Hamdan; M. Fithriyah,2021.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534963,IEEE Conferences,"Organizations have been adopting Big Data for various purposes and its presence becomes more significant than ever in any public or private sector. However, this adoption comes with its own challenges. Organizations may face or deal with ethical challenges on how they get and utilized data. Because data appears to be easily accessible, ethical compliance in the use of social media data cannot be overlooked. The goal of this research is to see how the phenomena of big data might make ethical decisions more difficult for organizations. This research was built on recent literature reviews, and the discussion intended to examine the extent Big Data application intercepts business ethics, especially on collecting customer data. Hence, Organizations must have transparent policies on big data applications and good practices to promote an ethical culture.",Ethics;Big Data;Consequentialist Theory,"Information Systems Department, School of Information Systems, Bina Nusantara University, Jakarta, Indonesia; School of Business & Economics, Universiti Brunei Darussalam, Bandar Seri Begawan, Brunei Darussalam; School of Business & Economics, Universiti Brunei Darussalam, Bandar Seri Begawan, Brunei Darussalam; Faculty of Economics, Indonesia Open University, Jakarta, Indonesia",14 Sep 2021,,,298.0,303.0,,978-1-6654-4937-3,,Ethics;Leadership;Social networking (online);Profitability;Organizations;Big Data applications;Information management,Big Data;ethical aspects;social networking (online),private sector;organizations;ethical challenges;ethical compliance;social media data;ethical decisions;extent Big Data application;business ethics;customer data;big data applications;ethical culture;public sector,,8.0,59.0,IEEE,14 Sep 2021,IEEE,0.1666666666666666,0.0,0.5714285714285714,0.1782551490309195
10,13.0,technology,13.0,13.0,An Overview of Artificial Intelligence Ethics,IEEE Transactions on Artificial Intelligence,4,4.0,10.1109/TAI.2022.3194503,C. Huang; Z. Zhang; B. Mao; X. Yao,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9844014,IEEE Journals,"Artificial intelligence (AI) has profoundly changed and will continue to change our lives. AI is being applied in more and more fields and scenarios such as autonomous driving, medical care, media, finance, industrial robots, and internet services. The widespread application of AI and its deep integration with the economy and society have improved efficiency and produced benefits. At the same time, it will inevitably impact the existing social order and raise ethical concerns. Ethical issues, such as privacy leakage, discrimination, unemployment, and security risks, brought about by AI systems have caused great trouble to people. Therefore, AI ethics, which is a field related to the study of ethical issues in AI, has become not only an important research topic in academia, but also an important topic of common concern for individuals, organizations, countries, and society. This article will give a comprehensive overview of this field by summarizing and analyzing the ethical risks and issues raised by AI, ethical guidelines and principles issued by different organizations, approaches for addressing ethical issues in AI, and methods for evaluating the ethics of AI. Additionally, challenges in implementing ethics in AI and some future perspectives are pointed out. We hope our work will provide a systematic and comprehensive overview of AI ethics for researchers and practitioners in this field, especially the beginners of this research discipline.",Artificial intelligence (AI);AI ethics;ethical issue;ethical theory;ethical principle,"Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, China; Trustworthiness Theory Research Center, Huawei Technologies Company, Ltd., Shenzhen, China; Trustworthiness Theory Research Center, Huawei Technologies Company, Ltd., Shenzhen, China; Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, China",21 Jul 2023,,,799.0,819.0,2691-4581,,Research Institute of Trustworthy Autonomous Systems; Guangdong Provincial Key Laboratory(grant numbers:2020B121201001); Program for Guangdong Introducing Innovative and Enterpreneurial Teams(grant numbers:2017ZT07X386); Shenzhen Science and Technology Program(grant numbers:KQTD2016112514355531); Huawei and Southern University of Science and Technology(grant numbers:FA2019061021); ,Artificial intelligence;Ethics;Guidelines;Privacy;Government;Systematics;Security,artificial intelligence;data privacy;ethical aspects;industrial robots;Internet,AI ethics;AI systems;artificial intelligence ethics;ethical concerns;ethical guidelines;ethical issues;ethical risks,,9.0,155.0,CCBY,28 Jul 2022,IEEE,0.1756756756756756,0.0,0.3333333333333333,0.1707678248066476
11,14.0,technology,14.0,14.0,What Would You do? An Ethical AI Quiz,2023 IEEE/ACM 45th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion),,,10.1109/ICSE-Companion58688.2023.00036,W. Teo; Z. Teoh; D. A. Arabi; M. Aboushadi; K. Lai; Z. Ng; A. Pant; R. Hoda; C. Tantithamthavorn; B. Turhan,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172891,IEEE Conferences,"The resurgence of Artificial Intelligence (AI) has been accompanied by a rise in ethical issues. AI practitioners either face challenges in making ethical choices when designing AI-based systems or are not aware of such challenges in the first place. Increasing the level of awareness and understanding of the perceptions of those who develop AI systems is a critical step toward mitigating ethical issues in AI development. Motivated by these challenges, needs, and the lack of engaging approaches to address these, we developed an interactive, scenario-based ethical AI quiz. It allows AI practitioners, including software engineers who develop AI systems, to self-assess their awareness and perceptions about AI ethics. The experience of taking the quiz, and the feedback it provides, will help AI practitioners understand the gap areas, and improve their overall ethical practice in everyday development scenarios. To demonstrate these expected outcomes and the relevance of our tool, we also share a preliminary user study. The video demo can be found at https://zenodo.org/record/7601169#.Y9xgA-xBxhF.",ethics;AI ethics;AI practitioners;self- assessment tools;ethical AI quiz,"Faculty of Engineering, Monash University, Subang Jaya, Malaysia; Faculty of Engineering, Monash University, Subang Jaya, Malaysia; Faculty of Engineering, Monash University, Subang Jaya, Malaysia; Faculty of Engineering, Monash University, Subang Jaya, Malaysia; Faculty of Engineering, Monash University, Subang Jaya, Malaysia; Faculty of Engineering, Monash University, Subang Jaya, Malaysia; Faculty of IT, Monash University, Melbourne, Australia; Faculty of Engineering, Monash University, Subang Jaya, Malaysia; Faculty of IT, Monash University, Melbourne, Australia; Faculty of Engineering, Monash University, Subang Jaya, Malaysia",12 Jul 2023,,,112.0,116.0,2574-1934,979-8-3503-2263-7,,Ethics;Software;Artificial intelligence;Faces;Software engineering,artificial intelligence;ethical aspects;interactive systems;software engineering,AI development;AI ethics;AI practitioners;AI systems;artificial intelligence;designing AI-based systems;ethical choices;ethical issues;ethical practice;scenario-based ethical AI quiz;software engineers;video demo,,,21.0,IEEE,12 Jul 2023,IEEE,0.1595092024539877,0.1428571428571428,0.5,0.1688835537847686
12,15.0,technology,15.0,15.0,A Case Study of Privacy Protection Challenges and Risks in AI-Enabled Healthcare App,2023 IEEE Conference on Artificial Intelligence (CAI),,,10.1109/CAI54212.2023.00132,P. Wang; H. Zare,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10195065,IEEE Conferences,"Artificial intelligence (AI) is increasingly used in healthcare systems and applications (apps) with questions and debates on ethical issues and privacy risks. This research study explores and discusses the ethical challenges, privacy risks, and possible solutions related to protecting user data privacy in AI-enabled healthcare apps. The study is based on the healthcare app named Charlie in one of the fictional case studies designed by Princeton University to elucidate critical thinking and discussions on emerging ethical issues embracing AI.",AI;healthcare;ethics;privacy;security;risks,"Department of Computer Information Systems, Robert Morris University, Pittsburgh, USA; Bloomberg School of Public Health, Johns Hopkins University, Baltimore, USA",2 Aug 2023,,,296.0,297.0,,979-8-3503-3984-0,National Science Foundation; ,Privacy;Ethics;Data privacy;Medical services;Artificial intelligence;Guidelines,artificial intelligence;data privacy;ethical aspects;health care,AI-enabled healthcare app;artificial intelligence;ethical challenges;ethical issues;fictional case studies;healthcare systems;privacy protection challenges;privacy risks;research study explores;user data privacy,,,14.0,IEEE,2 Aug 2023,IEEE,0.189873417721519,0.0,0.0769230769230769,0.163721735367305
13,16.0,technology,16.0,16.0,"Bridging Industry, Government, and Academia for Socially Responsible AI: The CSEAI Initiative","2023 IEEE International Symposium on Ethics in Engineering, Science, and Technology (ETHICS)",,,10.1109/ETHICS57328.2023.10155071,P. Rivas; J. Ortiz; D. A. Díaz-Pachón; L. N. Montoya,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155071,IEEE Conferences,"The mission of the Center for Standards and Ethics in Artificial Intelligence (CSEAI) is to promote safe, effective, and ethical AI standards through research, outreach, and education in partnership with industry and government. We briefly discuss CSEAI's workforce development plan, including mentoring undergraduate and graduate students and providing continuing education for industry professionals. The CSEAI aims to facilitate the production of standardized, ethical AI products that are safe for users and promote diversity in the field. By underscoring the importance of socially responsible innovation and ethical standards in AI, we show the CSEAI's aims to protect consumers and increase trust in responsible AI products and services.",responsible AI;AI ethics standards,"Industry-University Cooperative Research Center for Standards and Ethics in Artificial Intelligence, Baylor University, Rutgers University, The University of Miami, Accel AI Institute; Industry-University Cooperative Research Center for Standards and Ethics in Artificial Intelligence, Baylor University, Rutgers University, The University of Miami, Accel AI Institute; Industry-University Cooperative Research Center for Standards and Ethics in Artificial Intelligence, Baylor University, Rutgers University, The University of Miami, Accel AI Institute; Industry-University Cooperative Research Center for Standards and Ethics in Artificial Intelligence, Baylor University, Rutgers University, The University of Miami, Accel AI Institute",23 Jun 2023,,,1.0,1.0,,978-1-6654-5713-2,NSF(grant numbers:CNS-2136961); ,Industries;Ethics;Technological innovation;Government;Education;Production;Mentoring,artificial intelligence;ethical aspects;further education;government policies,center for standards and ethics in artificial intelligence;continuing education;CSEAI initiative;CSEAI workforce development plan;ethical AI standard;government;industry professional;socially responsible AI;socially responsible innovation;undergraduate student,,,4.0,IEEE,23 Jun 2023,IEEE,0.1509433962264151,0.5,0.0833333333333333,0.157350042241622
14,17.0,technology,17.0,17.0,A Quantitative Model for the Assessment of Ethics Risks in Information Technology,"2023 IEEE International Symposium on Ethics in Engineering, Science, and Technology (ETHICS)",,,10.1109/ETHICS57328.2023.10155002,G. Rafaiani; G. Barchiesi; L. Ilari; M. Baldi; B. Giovanola,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155002,IEEE Conferences,"The management of sensitive and personal data in the healthcare sector must guarantee the widest respect of patients' fundamental rights. However, some quantitative evaluation framework for assessing the level of ethical compliance of a technology to the most important ethical principles is still missing. In this work, we first provide a model to quantitatively assess constitutive ethics, i.e., the intrinsic ethical compliance of a technology. Secondly, we propose a method for quantitatively assessing circumstantial ethics risks of a technology, when used in some specific context. Our ethics risk assessment model is based on the evaluation of the compliance of the technology to a defined set of controls about some ethical principles and about the robustness of the technological infrastructure underneath. Then, we validate our model by applying it to some recent healthrelated blockchain frameworks, and we compare a qualitative ethical assessment with the quantitative assessment made with the proposed model for constitutive ethics compliance. Through our assessment, we identify some technical choices that achieve the highest ethical scores, such as using a permissioned blockchain, off-chain storage, and encryption of data. Finally, we observe that the principles of privacy and data governance turn out to be the most satisfied ethical principles, contrary to fairness.",Ethics;Risk Assessment;Ethics by design;Privacy;Blockchain;Information Technology,"Department of Information Engineering, Marche Polytechnic University, Ancona, Italy; Department of Information Engineering, Marche Polytechnic University, Ancona, Italy; Department of Political Sciences, Communication, and International Relations, University of Macerata, Macerata, Italy; Department of Information Engineering, Marche Polytechnic University, Ancona, Italy; Department of Political Sciences, Communication, and International Relations, University of Macerata, Macerata, Italy",23 Jun 2023,,,1.0,8.0,,978-1-6654-5713-2,,Ethics;Analytical models;Protocols;Statistical analysis;Organizations;Probability;Data models,blockchains;data privacy;ethical aspects;health care;risk management,assessment model;circumstantial ethics risks;constitutive ethics compliance;data governance;ethical principles;ethical scores;ethics risk assessment model;health-related blockchain frameworks;healthcare sector;information technology;intrinsic ethical compliance;patients;personal data;privacy;qualitative ethical assessment;quantitative assessment;quantitative evaluation framework;technological infrastructure,,,31.0,IEEE,23 Jun 2023,IEEE,0.1625615763546798,0.0,0.1666666666666666,0.1542756012936997
15,18.0,technology,18.0,18.0,AI Ethics: Algorithmic Determinism or Self-Determination? The GPDR Approach,IEEE Access,9,,10.1109/ACCESS.2021.3072782,M. Milossi; E. Alexandropoulou-Egyptiadou; K. E. Psannis,2021.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9400809,IEEE Journals,"Artificial Intelligence (AI) refers to systems designed by humans, interpreting the already collected data and deciding the best action to take, according to the pre-defined parameters, in order to achieve the given goal. Designing, trial and error while using AI, brought ethics to the center of the dialogue between tech giants, enterprises, academic institutions as well as policymakers. Ethical challenges in AI brought ethical AI framework in place in an attempt to regulate people’s lives and interactions, used for the benefit of society, for the human rights’ protection as well as for the respect of individual’s privacy and autonomy. The paper aims to summarize and critically evaluate the basic principles for the use of AI, with emphasis to the General Data Protection Regulation’s (GDPR) approach, concerning data subject’s consent, data protection principles and data subject’s rights in a context of ‘privacy by design’ architecture.",AI;privacy;data protection;ethics;GDPR,"Department of Applied Informatics, School of Information Sciences, University of Macedonia, Thessaloniki, Greece; Department of Applied Informatics, School of Information Sciences, University of Macedonia, Thessaloniki, Greece; Department of Applied Informatics, School of Information Sciences, University of Macedonia, Thessaloniki, Greece",20 Apr 2021,,,58455.0,58466.0,2169-3536,,,Artificial intelligence;Ethics;Tools;Education;Prediction algorithms;Medical services,artificial intelligence;data protection;ethical aspects,ethical AI framework;human rights;General Data Protection Regulation;data protection principles;AI ethics;GPDR approach;artificial intelligence;pre-defined parameters,,5.0,60.0,CCBY,12 Apr 2021,IEEE,0.1458333333333333,0.0,0.3333333333333333,0.1538642789820923
16,19.0,technology,19.0,19.0,AI Ethics: An Empirical Study on the Views of Practitioners and Lawmakers,IEEE Transactions on Computational Social Systems,PP,99.0,10.1109/TCSS.2023.3251729,A. A. Khan; M. A. Akbar; M. Fahmideh; P. Liang; M. Waseem; A. Ahmad; M. Niazi; P. Abrahamsson,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10066257,IEEE Early Access Articles,"Artificial intelligence (AI) solutions and technologies are being increasingly adopted in smart systems contexts; however, such technologies are concerned with ethical uncertainties. Various guidelines, principles, and regulatory frameworks are designed to ensure that AI technologies adhere to ethical well-being. However, the implications of AI ethics principles and guidelines are still being debated. To further explore the significance of AI ethics principles and relevant challenges, we conducted a survey of 99 randomly selected representative AI practitioners and lawmakers (e.g., AI engineers and lawyers) from 20 countries across five continents. To the best of our knowledge, this is the first empirical study that unveils the perceptions of two different types of population (AI practitioners and lawmakers) and the study findings confirm that transparency, accountability, and privacy are the most critical AI ethics principles. On the other hand, lack of ethical knowledge, no legal frameworks, and lacking monitoring bodies are found to be the most common AI ethics challenges. The impact analysis of the challenges across principles reveals that conflict in practice is a highly severe challenge. Moreover, the perceptions of practitioners and lawmakers are statistically correlated with significant differences for particular principles (e.g. fairness and freedom) and challenges (e.g. lacking monitoring bodies and machine distortion). Our findings stimulate further research, particularly empowering existing capability maturity models to support ethics-aware AI systems’ development and quality assessment.",Accountable artificial intelligence;Artificial intelligence (AI);AI ethics;AI ethics principles;challenges;machine ethics,"M3S. Empirical Software Engineering Research Unit, University of Oulu, Oulu, Finland; Software Engineering Department, Lappeenranta-Lahti University of Technology, Lappeenranta, Finland; School of Business, University of Southern Queensland, Toowoomba, QLD, Australia; School of Computer Science, Wuhan University, Wuhan, China; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland; School of Computing and Communications, Lancaster University Leipzig, Leipzig, Germany; Department of Information and Computer Science, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia; Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland",,,,1.0,14.0,2329-924X,,,Artificial intelligence;Ethics;Guidelines;Industries;Instruments;Statistics;Sociology,,,,3.0,,CCBY,10 Mar 2023,IEEE,0.1255605381165919,0.4444444444444444,0.25,0.1517523147007451
17,20.0,technology,20.0,20.0,Imagine a More Ethical AI: Using Stories to Develop Teens' Awareness and Understanding of Artificial Intelligence and its Societal Impacts,"2021 Conference on Research in Equitable and Sustained Participation in Engineering, Computing, and Technology (RESPECT)",,,10.1109/RESPECT51740.2021.9620549,S. Forsyth; B. Dalton; E. H. Foster; B. Walsh; J. Smilack; T. Yeh,2021.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9620549,IEEE Conferences,"Artificial intelligence (AI) tools and technologies are increasingly prevalent in society. Many teens interact with AI devices on a daily basis but often have a limited understanding of how AI works, as well as how it impacts society more broadly. It is critical to develop youths' understanding of AI, cultivate ethical awareness, and support diverse youth in pursuing computer science to help ensure future development of more equitable AI technologies. Here, we share our experiences developing and remotely facilitating an interdisciplinary AI ethics program for secondary students designed to increase teens' awareness and understanding of AI and its societal impacts. Students discussed stories with embedded ethical dilemmas, engaged with AI media and simulations, and created digital products to express their stance on an AI ethics issue. Across four iterations in formal and informal settings, we found students to be engaged in AI stories and invested in learning about AI and its societal impacts. Short stories were effective in raising awareness, focusing discussion and supporting students in developing a more nuanced understanding of AI ethics issues, such as fairness, bias and privacy.",artificial intelligence (AI);machine learning;ethics,"CU Science Discovery, University of Colorado Boulder, Boulder, CO; School of Education, University of Colorado Boulder, Boulder, CO; School of Education, University of Colorado Boulder, Boulder, CO; School of Education, University of Colorado Boulder, Boulder, CO; School of Education, University of Colorado Boulder, Boulder, CO; Department of Computer Science, University of Colorado Boulder, Boulder, CO",30 Nov 2021,,,1.0,2.0,,978-1-6654-4905-2,National Science Foundation(grant numbers:1934151); ,Computer science;Ethics;Privacy;Education;Focusing;Learning (artificial intelligence);Tools,artificial intelligence;ethical aspects;social aspects of automation,ethical AI;artificial intelligence;societal impacts;AI devices;AI works;cultivate ethical awareness;equitable AI technologies;interdisciplinary AI ethics program;embedded ethical dilemmas;AI ethics issue;AI stories;nuanced understanding,,4.0,8.0,IEEE,30 Nov 2021,IEEE,0.149171270718232,0.0,0.2,0.148638601108143
18,21.0,technology,21.0,21.0,The Ethical Approach to AI,Societal Responsibility of Artificial Intelligence: Towards an Ethical and Eco-responsible AI,,,10.1002/9781119831808.ch2,,2021.0,https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9822260.pdf&bkn=9820928&pdfType=chapter,Wiley Data and Cybersecurity eBook Chapters,"The pace of technological innovation and the temporality of its worldwide launch, supported by the digital economy, is clearly outpacing the speed of human awareness. Artificial intelligence (AI) ethics is a branch of digital ethics specific to robots and other artificially intelligent agents. One of the important ethical issues of Big Data concerns their apparent objectivity in illustrating social reality with scientific authority and technical rigor. The emergence of AI is likely to mask the development of a societal project, modeled according to their economic interests and the increase of their vision. The chapter aims to list and define the main ethical criteria that will constitute the basis of a future reference system in order to move toward AI at the service of human intelligence and prevent and anticipate the drifts and possible consequences of the improvement of algorithmic systems.",,,,,,35.0,90.0,,9781119831792,,Ethics;Artificial intelligence;Robots;Reflection;Technological innovation;Regulation;History,,,,,,,12 Jul 2022,Wiley,0.1285714285714285,0.0,0.8,0.1473022685469037
19,22.0,technology,22.0,22.0,"Peer Support Specialists and Service Users’ Perspectives on Privacy, Confidentiality, and Security of Digital Mental Health",IEEE Pervasive Computing,21,2.0,10.1109/MPRV.2022.3141986,M. D. Venegas; J. M. Brooks; A. L. Myers; M. Storm; K. L. Fortuna,2022.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723457,IEEE Magazines,"As the digitalization of mental health systems progresses, the ethical and social debate on the use of these mental health technologies has seldom been explored among end-users. This article explores how service users (e.g., patients and users of mental health services) and peer support specialists understand and perceive issues of privacy, confidentiality, and security of digital mental health interventions. Semi-structured qualitative interviews were conducted among service users (n = 17) and peer support specialists (n = 15) from a convenience sample at an urban community mental health center in the United States. We identified technology ownership and use, lack of technology literacy including limited understanding of privacy, confidentiality, and security as the main barriers to engagement among service users. Peers demonstrated a high level of technology engagement, literacy of digital mental health tools, and a more comprehensive awareness of digital mental health ethics. We recommend peer support specialists as a potential resource to facilitate the ethical engagement of digital mental health interventions for service users. Finally, engaging potential end-users in the development cycle of digital mental health support platforms and increased privacy regulations may lead the field to a better understanding of effective uses of technology for people with mental health conditions. This study contributes to the ongoing debate of digital mental health ethics, data justice, and digital mental health by providing a first-hand experience of digital ethics from end-users’ perspectives.",,"Department of Veterans Affairs GRECC, Bedford, VA, USA; University of Wisconsin-Madison, Madison, WI, USA; Rivier University, Nashua, NH, USA; University of Stavanger, Stavanger, Norway; Dartmouth College, Hanover, NH, USA",7 Jul 2022,,,41.0,50.0,1558-2590,,National Institute of Mental Health(grant numbers:K01MH117496); ,Mental health;Interviews;Privacy;Security;Ethics;Social networking (online);Codes,behavioural sciences computing;data privacy;ethical aspects;health care;medical computing;patient treatment,digital ethics;mental health conditions;digital mental health support platforms;potential end-users;digital mental health ethics;digital mental health tools;technology engagement;urban community mental health center;digital mental health interventions;support specialists understand;mental health services;mental health technologies;mental health systems progresses;digitalization;confidentiality;privacy;service users;peer support specialists,,1.0,31.0,USGov,1 Mar 2022,IEEE,0.1428571428571428,0.0,0.1875,0.1460220255249073
20,24.0,technology,24.0,24.0,"Dealing with Ethics, Privacy, and Security",Reimagining Businesses with AI,,,10.1002/9781119709183.ch12,S. Sinha; K. Al Huraimel,2021.0,https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9821896.pdf&bkn=9820895&pdfType=chapter,Wiley Data and Cybersecurity eBook Chapters,"This chapter broadens the horizon about ethics, data privacy, and cybersecurity in businesses. It gives practical guidance on how to build barriers against threats. In the age of artificial intelligence (AI), ethics has attained a completely different level of significance and debate. The chapter discusses some of the key issues to consider around ethics and AI, including artificial stupidity and data trustworthiness. Privacy starts with data ownership. The General Data Protection Regulation (GDPR) has stringent stipulations around the various rights of individuals around the personal data. It brings personal data into a complex and protective regulatory regime. AI programs have increased vulnerabilities because there are more difficult‐to‐identify places to inject and bury threat vectors. The chapter provides information on cybersecurity assurance practices and industry standards for cybersecurity compliance. AI is also a great tool for identifying cyber‐threats. This is one of the biggest emerging applications of AI techniques.",,NA; NA,,,,193.0,206.0,,9781119709176,,Artificial intelligence;Ethics;Business;Privacy;Economics;Training;Decision making,,,,,,,12 Jul 2022,Wiley,0.1283783783783783,0.0,0.5,0.1427372634824336
21,27.0,technology,27.0,27.0,AI Digital Tool Product Lifecycle Governance Framework through Ethics and Compliance by Design†,2023 IEEE Conference on Artificial Intelligence (CAI),,,10.1109/CAI54212.2023.00155,E. Ortega; M. Tran; G. Bandeen,2023.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10195137,IEEE Conferences,"The acceleration of Artificial Intelligence (AI) has brought forward new digital tools that have had a wide impact across society. However, AI digital tools (such as ChatGPT, midjourney, DALL-E 2) have brought forward legal and ethical concerns. — Internationally, public, and private leaders are introducing regulatory frameworks to address data governance for such these AI digital tools (i.e., Global Data Protection Regulation, the European AI Act, Blueprint for an AI Bill of Rights, NIST Risk Management Framework, etc.). We recognize that these AI digital tools are a vital aspect of future technological development, but they require input from various sectors in addressing ethics and compliance design. We survey the current landscape of published AI-specific regulatory frameworks and known engineering design process methods. Using a product lifecycle approach, we also introduce a trans-disciplinary framework to address AI ethics and compliance via design. This product lifecycle approach considers several principles: a Human-Centered Design for Risk Assessment, Functional Safety and Risk Management Standardization, and Continuous Governance throughout Product Lifecycle. Establishing risk management throughout AI product lifecycles can ensure accountability for AI product use cases. In addition, by utilizing previous Functional Safety considerations we can create safety mechanisms throughout the product lifecycle of AI digital tools. Finally, establishing in-field testing for continuous governance will enable the flexibility for new compliance standards and transparency. We establish this governance framework to aid in new compliance strategies for these emerging issues with AI digital tools.",Ethics;Compliance;AI;Risk Management;Human-Centered-Design;Engineering Design Thinking,"Pratt School of Engineering, Duke University, Durham, NC, USA; The Graduate School, Duke University, Durham, NC, USA; School of Law, Duke University, Durham, NC, USA",2 Aug 2023,,,353.0,356.0,,979-8-3503-3984-0,,Surveys;Ethics;Law;NIST;Regulation;Safety;Risk management,artificial intelligence;data protection;ethical aspects;risk management,AI digital tool Product Lifecycle Governance Framework;AI digital tools;AI ethics;AI product lifecycles;AI product use cases;European AI Act;forward new digital tools;product lifecycle approach;published AI-specific,,,20.0,IEEE,2 Aug 2023,IEEE,0.134453781512605,0.0,0.3846153846153846,0.140872680557676
22,28.0,technology,28.0,28.0,Focusing on the Ethical Challenges of Data Breaches and Applications,2022 IEEE International Conference on Assured Autonomy (ICAA),,,10.1109/ICAA52185.2022.00018,K. Joisten; N. Thiemer; T. Renner; A. Janssen; A. Scheffler,2022.0,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9763591,IEEE Conferences,"Ethical challenges of the human lifeworld that are caused by data breaches and applications are steadily increasing. Therefore, a new ethical concept must be brought into focus: Technoethics for Emerging Digital Systems (TEDS). TEDS is presented as an integrative and innovative approach committed to an interdisciplinary perspective. Thereby, TEDS reflects all social areas of the human lifeworld in their ethical scope. With recourse to phenomenological methods, TEDS helps to address ethical implications which arise from deep interference of autonomous systems with the human lifeworld. The meaning of intentional structures and the problem of appresentations in the phenomenological sense still represents a blank gap in the current ethical discourse on the problem of data breaches. The findings provide methods for dealing with ethical challenges and explain the problem area of an appropriate technoethical use in the lifeworld. In this way, problems can already be avoided in the development process of artificial intelligence systems and their applications by specifically searching for blind spots in a technical and ethical manner. Furthermore, this approach helps to assure a technoethical use of autonomous systems in an appropriate way and ultimately leads to a limitation of damages – which may occur in case of malfunctions and data breaches of artificial intelligence systems – in the lifeworld of humans. Our contribution is to introduce TEDS as a new ethical concept that has not existed before. This new concept focuses on the application of phenomenological methods to detect ethical errors in digital systems.",Technoethics;ethics;phenomenology;application;privacy;security;AI;autonomous systems;physical world/lifeworld,"Department of Philosophy, Technical University of Kaiserslautern, Kaiserslautern, Germany; Department of Philosophy, Technical University of Kaiserslautern, Kaiserslautern, Germany; Department of Philosophy, Technical University of Kaiserslautern, Kaiserslautern, Germany; Department of Philosophy, Technical University of Kaiserslautern, Kaiserslautern, Germany; Faculty of Computer Science, Ruhr University Bochum, Bochum, Germany",29 Apr 2022,,,74.0,82.0,,978-1-6654-8539-5,,Ethics;Data privacy;Autonomous systems;Digital systems;Focusing;Interference;Data breach,artificial intelligence;ethical aspects;security of data;social aspects of automation,ethical challenges;data breaches;human lifeworld;ethical concept;digital systems;TEDS;integrative approach;ethical scope;phenomenological methods;autonomous systems;ethical discourse;problem area;artificial intelligence systems;ethical errors,,2.0,34.0,IEEE,29 Apr 2022,IEEE,0.1387755102040816,0.0,0.4,0.1402330749878724
